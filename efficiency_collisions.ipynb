{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informative-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worldwide-sherman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['321475', '321712', '321730', '321732', '321735', '321755', '321758', '321760', '321774', '321777', '321778', '321780', '321781', '321794', '321813', '321817', '321818', '321820', '321831', '321832', '321833', '321834', '321879', '321880', '321887', '321908', '321909', '321917', '321933', '321961', '321973', '321975', '321988', '321990', '322022', '322068', '322079', '322088', '322106', '322113', '322118', '322179', '322201', '322204', '322222', '322252', '322319', '322322', '322324', '322332', '322348', '322355', '322356', '322381', '322407', '322430', '322431', '322480', '322492', '322599', '322605', '322617', '322625', '322633', '323473', '323474', '323487', '323488', '323493', '323495', '323524', '323525', '323526', '323693', '323696', '323700', '323702', '323725', '323727', '323755', '323775', '323778', '323790', '323841', '323857', '323940', '323980', '323983', '323997', '324021', '324022', '324077', '324078', '324201', '324202', '324205', '324206', '324209', '324237', '324245', '324293', '324315', '324318', '324420', '324729', '324747', '324764', '324765', '324769', '324772', '324785', '324791', '324835', '324841', '324846', '324878', '324897', '324970', '324980', '324997', '324998', '325000', '325001', '325022', '325057', '325099', '325100', '325101', '325117', '325159', '325170', '325172']\n",
      "(63360, 16)\n"
     ]
    }
   ],
   "source": [
    "col_dirs = os.listdir('Collisions/')\n",
    "print(col_dirs)\n",
    "\n",
    "list_of_df = []\n",
    "for col_run in col_dirs:\n",
    "    list_of_df.append(pd.read_csv('Collisions/'+col_run+'/'+col_run+'_final2.csv'))\n",
    "    \n",
    "collisions_data = pd.concat(list_of_df)\n",
    "collisions_data = collisions_data.reset_index(drop=True)\n",
    "print(collisions_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "practical-region",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>chamber</th>\n",
       "      <th>wheel</th>\n",
       "      <th>sector</th>\n",
       "      <th>station</th>\n",
       "      <th>avg_cluster_size</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>avg_bx_dist</th>\n",
       "      <th>avg_no_of_clusters</th>\n",
       "      <th>avg_multiplicity</th>\n",
       "      <th>lumisections</th>\n",
       "      <th>type</th>\n",
       "      <th>avg_efficiency</th>\n",
       "      <th>contains_zero_roll</th>\n",
       "      <th>rolls_count</th>\n",
       "      <th>fid_eff_ch_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321475</td>\n",
       "      <td>W-2_RB1in_S01</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.88926</td>\n",
       "      <td>85729</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>1.00394</td>\n",
       "      <td>1.89670</td>\n",
       "      <td>2091</td>\n",
       "      <td>Col</td>\n",
       "      <td>53.435921</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>96.271114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321475</td>\n",
       "      <td>W-2_RB1out_S01</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.83989</td>\n",
       "      <td>75899</td>\n",
       "      <td>0.006860</td>\n",
       "      <td>1.00387</td>\n",
       "      <td>1.84701</td>\n",
       "      <td>2091</td>\n",
       "      <td>Col</td>\n",
       "      <td>58.874134</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>97.754410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321475</td>\n",
       "      <td>W-2_RB2in_S01</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.99387</td>\n",
       "      <td>91026</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>1.00391</td>\n",
       "      <td>2.00167</td>\n",
       "      <td>2091</td>\n",
       "      <td>Col</td>\n",
       "      <td>81.179764</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>98.231281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321475</td>\n",
       "      <td>W-2_RB2out_S01</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.85097</td>\n",
       "      <td>78148</td>\n",
       "      <td>0.011014</td>\n",
       "      <td>1.00278</td>\n",
       "      <td>1.85611</td>\n",
       "      <td>2091</td>\n",
       "      <td>Col</td>\n",
       "      <td>84.280207</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>98.210457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321475</td>\n",
       "      <td>W-2_RB3+_S01</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.86637</td>\n",
       "      <td>36803</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>1.00107</td>\n",
       "      <td>1.86836</td>\n",
       "      <td>2091</td>\n",
       "      <td>Col</td>\n",
       "      <td>92.292915</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>98.584396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      run         chamber  wheel  sector  station  avg_cluster_size  \\\n",
       "0  321475   W-2_RB1in_S01     -2       1        1           1.88926   \n",
       "1  321475  W-2_RB1out_S01     -2       1        1           1.83989   \n",
       "2  321475   W-2_RB2in_S01     -2       1        2           1.99387   \n",
       "3  321475  W-2_RB2out_S01     -2       1        2           1.85097   \n",
       "4  321475    W-2_RB3+_S01     -2       1        3           1.86637   \n",
       "\n",
       "   occupancy  avg_bx_dist  avg_no_of_clusters  avg_multiplicity  lumisections  \\\n",
       "0      85729     0.006567             1.00394           1.89670          2091   \n",
       "1      75899     0.006860             1.00387           1.84701          2091   \n",
       "2      91026     0.006966             1.00391           2.00167          2091   \n",
       "3      78148     0.011014             1.00278           1.85611          2091   \n",
       "4      36803     0.004361             1.00107           1.86836          2091   \n",
       "\n",
       "  type  avg_efficiency  contains_zero_roll  rolls_count  fid_eff_ch_level  \n",
       "0  Col       53.435921                   0            2         96.271114  \n",
       "1  Col       58.874134                   0            2         97.754410  \n",
       "2  Col       81.179764                   0            2         98.231281  \n",
       "3  Col       84.280207                   0            3         98.210457  \n",
       "4  Col       92.292915                   0            2         98.584396  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collisions_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-concentration",
   "metadata": {},
   "source": [
    "# Analyzing the records with zero fiducial efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "personal-working",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for all the chambers contains approximately 8.4% of records with 0 fiducial efficiency\n",
      "\n",
      "\n",
      "       run       chamber  wheel  sector  station  avg_cluster_size  occupancy  \\\n",
      "7   321475  W-2_RB4-_S01     -2       1        4               0.0          0   \n",
      "12  321475  W-2_RB3+_S02     -2       2        3               0.0          0   \n",
      "\n",
      "    avg_bx_dist  avg_no_of_clusters  avg_multiplicity  lumisections type  \\\n",
      "7           0.0                 0.0               0.0          2091  Col   \n",
      "12          0.0                 0.0               0.0          2091  Col   \n",
      "\n",
      "    avg_efficiency  contains_zero_roll  rolls_count  fid_eff_ch_level  \n",
      "7              0.0                   1            2               0.0  \n",
      "12             0.0                   1            2               0.0  \n"
     ]
    }
   ],
   "source": [
    "zero_fid_rows = collisions_data.loc[collisions_data['fid_eff_ch_level'] == 0]\n",
    "\n",
    "# Calculating the percentage of the zero-efficiency valued records in the dataset\n",
    "data_size = collisions_data.shape[0]\n",
    "zero_data_size = zero_fid_rows.shape[0]\n",
    "zero_percentage = round((zero_data_size/data_size)*100,2)\n",
    "print(\"Dataset for all the chambers contains approximately \"+str(zero_percentage)+\"% of records with 0 fiducial efficiency\\n\\n\")\n",
    "\n",
    "# Records with zero-valued fid efficiency\n",
    "print(zero_fid_rows[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-terrain",
   "metadata": {},
   "source": [
    "### 1. Looking at incorrect zero efficiency valued records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sorted-minneapolis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>chamber</th>\n",
       "      <th>wheel</th>\n",
       "      <th>sector</th>\n",
       "      <th>station</th>\n",
       "      <th>avg_cluster_size</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>avg_bx_dist</th>\n",
       "      <th>avg_no_of_clusters</th>\n",
       "      <th>avg_multiplicity</th>\n",
       "      <th>lumisections</th>\n",
       "      <th>type</th>\n",
       "      <th>avg_efficiency</th>\n",
       "      <th>contains_zero_roll</th>\n",
       "      <th>rolls_count</th>\n",
       "      <th>fid_eff_ch_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>321475</td>\n",
       "      <td>W+2_RB2in_S07</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.03058</td>\n",
       "      <td>87447</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>1.00343</td>\n",
       "      <td>2.03754</td>\n",
       "      <td>2091</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>321475</td>\n",
       "      <td>W+2_RB2out_S07</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.86599</td>\n",
       "      <td>72115</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>1.00218</td>\n",
       "      <td>1.87006</td>\n",
       "      <td>2091</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>321712</td>\n",
       "      <td>W+2_RB2in_S07</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.08088</td>\n",
       "      <td>17417</td>\n",
       "      <td>0.013381</td>\n",
       "      <td>1.00264</td>\n",
       "      <td>2.08637</td>\n",
       "      <td>265</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>321712</td>\n",
       "      <td>W+2_RB2out_S07</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.85333</td>\n",
       "      <td>14013</td>\n",
       "      <td>0.011771</td>\n",
       "      <td>1.00132</td>\n",
       "      <td>1.85578</td>\n",
       "      <td>265</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>321730</td>\n",
       "      <td>W+2_RB2in_S07</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.99378</td>\n",
       "      <td>19565</td>\n",
       "      <td>0.012331</td>\n",
       "      <td>1.00389</td>\n",
       "      <td>2.00153</td>\n",
       "      <td>282</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         run         chamber  wheel  sector  station  avg_cluster_size  \\\n",
       "436   321475   W+2_RB2in_S07      2       7        2           2.03058   \n",
       "437   321475  W+2_RB2out_S07      2       7        2           1.86599   \n",
       "916   321712   W+2_RB2in_S07      2       7        2           2.08088   \n",
       "917   321712  W+2_RB2out_S07      2       7        2           1.85333   \n",
       "1396  321730   W+2_RB2in_S07      2       7        2           1.99378   \n",
       "\n",
       "      occupancy  avg_bx_dist  avg_no_of_clusters  avg_multiplicity  \\\n",
       "436       87447     0.009288             1.00343           2.03754   \n",
       "437       72115     0.007374             1.00218           1.87006   \n",
       "916       17417     0.013381             1.00264           2.08637   \n",
       "917       14013     0.011771             1.00132           1.85578   \n",
       "1396      19565     0.012331             1.00389           2.00153   \n",
       "\n",
       "      lumisections type  avg_efficiency  contains_zero_roll  rolls_count  \\\n",
       "436           2091  Col             0.0                   1            2   \n",
       "437           2091  Col             0.0                   1            3   \n",
       "916            265  Col             0.0                   1            2   \n",
       "917            265  Col             0.0                   1            3   \n",
       "1396           282  Col             0.0                   1            2   \n",
       "\n",
       "      fid_eff_ch_level  \n",
       "436                0.0  \n",
       "437                0.0  \n",
       "916                0.0  \n",
       "917                0.0  \n",
       "1396               0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting records with fiducial efficiency equal to 0 when some \n",
    "# other attributes contains non-zero values. Meaning there are\n",
    "# some discrepancies in efficiency computation since the chamber\n",
    "# contains metrics that would otherwise result in fiducial efficiency\n",
    "# greater than 0.\n",
    "\n",
    "incorrect_zero_efficiency = zero_fid_rows[(zero_fid_rows['avg_cluster_size'] != 0) | (zero_fid_rows['occupancy'] != 0) | (zero_fid_rows['avg_bx_dist'] != 0) | (zero_fid_rows['avg_no_of_clusters'] != 0) | (zero_fid_rows['avg_multiplicity'] != 0)]\n",
    "incorrect_zero_efficiency.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mathematical-usage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chambers of incorrectly computed fiducial efficiency:\n",
      "W+2_RB2in_S07     132\n",
      "W+2_RB2out_S07    132\n",
      "W-1_RB2out_S07      8\n",
      "W-2_RB4-_S05        3\n",
      "W-2_RB4+_S01        2\n",
      "W+2_RB4+_S01        2\n",
      "W+2_RB4-_S01        1\n",
      "W-2_RB3+_S04        1\n",
      "W-1_RB4-_S01        1\n",
      "Name: chamber, dtype: int64\n",
      "\n",
      "\n",
      " The outlier chambers containing fiducial efficiency of 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>chamber</th>\n",
       "      <th>wheel</th>\n",
       "      <th>sector</th>\n",
       "      <th>station</th>\n",
       "      <th>avg_cluster_size</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>avg_bx_dist</th>\n",
       "      <th>avg_no_of_clusters</th>\n",
       "      <th>avg_multiplicity</th>\n",
       "      <th>lumisections</th>\n",
       "      <th>type</th>\n",
       "      <th>avg_efficiency</th>\n",
       "      <th>contains_zero_roll</th>\n",
       "      <th>rolls_count</th>\n",
       "      <th>fid_eff_ch_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14549</th>\n",
       "      <td>321973</td>\n",
       "      <td>W-1_RB2out_S07</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1244</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18389</th>\n",
       "      <td>322106</td>\n",
       "      <td>W-1_RB2out_S07</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>876</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23669</th>\n",
       "      <td>322332</td>\n",
       "      <td>W-1_RB2out_S07</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1079</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27029</th>\n",
       "      <td>322431</td>\n",
       "      <td>W-1_RB2out_S07</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1272</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40469</th>\n",
       "      <td>323857</td>\n",
       "      <td>W-1_RB2out_S07</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>369</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          run         chamber  wheel  sector  station  avg_cluster_size  \\\n",
       "14549  321973  W-1_RB2out_S07     -1       7        2               3.0   \n",
       "18389  322106  W-1_RB2out_S07     -1       7        2               1.0   \n",
       "23669  322332  W-1_RB2out_S07     -1       7        2               7.0   \n",
       "27029  322431  W-1_RB2out_S07     -1       7        2               5.0   \n",
       "40469  323857  W-1_RB2out_S07     -1       7        2               6.0   \n",
       "\n",
       "       occupancy  avg_bx_dist  avg_no_of_clusters  avg_multiplicity  \\\n",
       "14549          3          3.0                 1.0               3.0   \n",
       "18389          1          0.0                 1.0               1.0   \n",
       "23669          7          1.0                 1.0               7.0   \n",
       "27029          5          2.0                 1.0               5.0   \n",
       "40469          6          0.0                 1.0               6.0   \n",
       "\n",
       "       lumisections type  avg_efficiency  contains_zero_roll  rolls_count  \\\n",
       "14549          1244  Col             0.0                   1            2   \n",
       "18389           876  Col             0.0                   1            2   \n",
       "23669          1079  Col             0.0                   1            2   \n",
       "27029          1272  Col             0.0                   1            2   \n",
       "40469           369  Col             0.0                   1            2   \n",
       "\n",
       "       fid_eff_ch_level  \n",
       "14549               0.0  \n",
       "18389               0.0  \n",
       "23669               0.0  \n",
       "27029               0.0  \n",
       "40469               0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As can be seen, almost all of the errors that occurred are\n",
    "# computed of the chamber in the exact same location. It can be\n",
    "# concluded that computation of fiducial efficiency is incorrect \n",
    "# when computing efficiency for Wheel +2, Sector 7, Station 2 IN and OUT\n",
    "# chambers. Thus, needs further investigation, as all of these chambers\n",
    "# for all the runs (20 chambers in total) contains incorrect values.\n",
    "\n",
    "# The values should be probably removed when applying machine learning \n",
    "# models as they are incorrect. However,\n",
    "# all the other records containing 0 fid efficiency seems to be appropriate,\n",
    "# as all the other metrics are also zero.\n",
    "print(\" Chambers of incorrectly computed fiducial efficiency:\")\n",
    "print(incorrect_zero_efficiency['chamber'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# There are also few chambers that seem to have incorrect\n",
    "# data assigned to them, such as values of 41 for avg_cluster size,\n",
    "# occupancy, avg_multiplicity and so on. Can say that it's an \n",
    "# noise in the data that has to be removed as well for further \n",
    "# modeling. \n",
    "print(\"\\n\\n The outlier chambers containing fiducial efficiency of 0:\")\n",
    "incorrect_zero_efficiency[(incorrect_zero_efficiency['wheel'] != 2) | (incorrect_zero_efficiency['sector'] != 7) | (incorrect_zero_efficiency['station'] != 2)].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-finance",
   "metadata": {},
   "source": [
    "### 2. Looking at possibly correct zero efficiency valued records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "manual-guess",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>chamber</th>\n",
       "      <th>wheel</th>\n",
       "      <th>sector</th>\n",
       "      <th>station</th>\n",
       "      <th>avg_cluster_size</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>avg_bx_dist</th>\n",
       "      <th>avg_no_of_clusters</th>\n",
       "      <th>avg_multiplicity</th>\n",
       "      <th>lumisections</th>\n",
       "      <th>type</th>\n",
       "      <th>avg_efficiency</th>\n",
       "      <th>contains_zero_roll</th>\n",
       "      <th>rolls_count</th>\n",
       "      <th>fid_eff_ch_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>321475</td>\n",
       "      <td>W-2_RB4-_S01</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2091</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>321475</td>\n",
       "      <td>W-2_RB3+_S02</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2091</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>321475</td>\n",
       "      <td>W-2_RB3-_S03</td>\n",
       "      <td>-2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2091</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>321475</td>\n",
       "      <td>W-2_RB4-_S04</td>\n",
       "      <td>-2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2091</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>321475</td>\n",
       "      <td>W-2_RB4-_S05</td>\n",
       "      <td>-2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2091</td>\n",
       "      <td>Col</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       run       chamber  wheel  sector  station  avg_cluster_size  occupancy  \\\n",
       "7   321475  W-2_RB4-_S01     -2       1        4               0.0          0   \n",
       "12  321475  W-2_RB3+_S02     -2       2        3               0.0          0   \n",
       "21  321475  W-2_RB3-_S03     -2       3        3               0.0          0   \n",
       "33  321475  W-2_RB4-_S04     -2       4        4               0.0          0   \n",
       "41  321475  W-2_RB4-_S05     -2       5        4               0.0          0   \n",
       "\n",
       "    avg_bx_dist  avg_no_of_clusters  avg_multiplicity  lumisections type  \\\n",
       "7           0.0                 0.0               0.0          2091  Col   \n",
       "12          0.0                 0.0               0.0          2091  Col   \n",
       "21          0.0                 0.0               0.0          2091  Col   \n",
       "33          0.0                 0.0               0.0          2091  Col   \n",
       "41          0.0                 0.0               0.0          2091  Col   \n",
       "\n",
       "    avg_efficiency  contains_zero_roll  rolls_count  fid_eff_ch_level  \n",
       "7              0.0                   1            2               0.0  \n",
       "12             0.0                   1            2               0.0  \n",
       "21             0.0                   1            2               0.0  \n",
       "33             0.0                   1            2               0.0  \n",
       "41             0.0                   1            2               0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting records with fiducial efficiency equal to 0 when all the \n",
    "# other attributes (avg_cluster_size, occupancy, etc.) also contains\n",
    "# zero values. Meaning the fiducial efficiency of zero for such chambers\n",
    "# should be correct.\n",
    "\n",
    "correct_zero_efficiency = zero_fid_rows[(zero_fid_rows['avg_cluster_size'] == 0) & (zero_fid_rows['occupancy'] == 0) & (zero_fid_rows['avg_bx_dist'] == 0) & (zero_fid_rows['avg_no_of_clusters'] == 0) & (zero_fid_rows['avg_multiplicity'] == 0)]\n",
    "correct_zero_efficiency.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hired-estate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stations with zero efficiency distribution:\n",
      "4    3360\n",
      "3    1395\n",
      "2     261\n",
      "1      24\n",
      "Name: station, dtype: int64\n",
      "\n",
      "Sectors with zero efficiency distribution:\n",
      "4     1215\n",
      "1      807\n",
      "7      759\n",
      "8      552\n",
      "5      416\n",
      "12     412\n",
      "2      412\n",
      "11     278\n",
      "3      148\n",
      "9       24\n",
      "10      17\n",
      "Name: sector, dtype: int64\n",
      "\n",
      " Wheels with zero efficiency distribution:\n",
      "-1    2210\n",
      "-2    1103\n",
      " 0     708\n",
      " 1     622\n",
      " 2     397\n",
      "Name: wheel, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# It can be clearly seen that chambers in the outer layers\n",
    "# (station 4 or 3) tend to have more zero valued fiducial\n",
    "# efficiency rather than chambers in the first two Stations\n",
    "# (Probably reasonable? as the detectors are further away\n",
    "# and it's safe to assume they might be detecting less muons)\n",
    "print(\"Stations with zero efficiency distribution:\")\n",
    "print(correct_zero_efficiency['station'].value_counts())\n",
    "\n",
    "# There is no strong correlation between 0 fiducial efficiency\n",
    "# and Sector numbers. However, Sectors 1 and 7 at the top\n",
    "# seems reasonable based on their perpendicular position\n",
    "# in the detector, receiving less cosmic muons?\n",
    "# (however, what about sector 4 with most 0 efficiency records??)\n",
    "print(\"\\nSectors with zero efficiency distribution:\")\n",
    "print(correct_zero_efficiency['sector'].value_counts())\n",
    "\n",
    "\n",
    "# No strong correlation between wheel and 0 fiducial efficiency\n",
    "# whatsoever, except for the negative side of the barrel\n",
    "# containing more 0-efficiency chambers.\n",
    "print(\"\\n Wheels with zero efficiency distribution:\")\n",
    "print(correct_zero_efficiency['wheel'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-drawing",
   "metadata": {},
   "source": [
    "### 3. Conclusion on zero efficiency valued records\n",
    "\n",
    "Assuming that the records analyzed in 1. are damaged and they cannot be used for further computations it is safe to believe that the chamber will have the fiducial efficiency of 0 if and only if all the other attributes of such chamber contain 0 values, as inspected above in 2.\n",
    "\n",
    "\n",
    "Having this in mind, we might consider dropping all the records containing zero fiducial efficiency value as they won't provide us with any relevant information when calculating the efficiency of a chamber, since only the records containing all the attributes (avg_cluster_size, occupancy, avg_bx_dist, avg_no_of_clusters, avg_multiplicity) of value zero will have a final fiducial efficiency equal to 0. \n",
    "\n",
    "Moreover, the data suggests that some actual fiducial efficiency values start at 40 (see cell below), thus, it is possible to assume that the 'correct' records with fiducial efficiency of 0 might be also discrepancies of the detectors, since the other fiducial efficiency values are nowhere close to 0 (closest one to be over 40)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sunset-video",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3765, 16)\n",
      "\n",
      " There are 50 records containing fid efficiency between 0 and 40 in the dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>chamber</th>\n",
       "      <th>wheel</th>\n",
       "      <th>sector</th>\n",
       "      <th>station</th>\n",
       "      <th>avg_cluster_size</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>avg_bx_dist</th>\n",
       "      <th>avg_no_of_clusters</th>\n",
       "      <th>avg_multiplicity</th>\n",
       "      <th>lumisections</th>\n",
       "      <th>type</th>\n",
       "      <th>avg_efficiency</th>\n",
       "      <th>contains_zero_roll</th>\n",
       "      <th>rolls_count</th>\n",
       "      <th>fid_eff_ch_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>321735</td>\n",
       "      <td>W+2_RB4-_S07</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.80559</td>\n",
       "      <td>1551</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>1.00468</td>\n",
       "      <td>1.81404</td>\n",
       "      <td>151</td>\n",
       "      <td>Col</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>33.333336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>321833</td>\n",
       "      <td>W+2_RB4+_S01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.52422</td>\n",
       "      <td>4059</td>\n",
       "      <td>0.009012</td>\n",
       "      <td>1.00150</td>\n",
       "      <td>1.52651</td>\n",
       "      <td>397</td>\n",
       "      <td>Col</td>\n",
       "      <td>41.666666</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11481</th>\n",
       "      <td>321880</td>\n",
       "      <td>W+2_RB4-_S07</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.78810</td>\n",
       "      <td>2945</td>\n",
       "      <td>0.023679</td>\n",
       "      <td>1.00061</td>\n",
       "      <td>1.78919</td>\n",
       "      <td>140</td>\n",
       "      <td>Col</td>\n",
       "      <td>36.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11961</th>\n",
       "      <td>321887</td>\n",
       "      <td>W+2_RB4-_S07</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.81956</td>\n",
       "      <td>20077</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>1.82137</td>\n",
       "      <td>951</td>\n",
       "      <td>Col</td>\n",
       "      <td>56.666666</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13926</th>\n",
       "      <td>321961</td>\n",
       "      <td>W-2_RB4+_S01</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.87192</td>\n",
       "      <td>10479</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>1.00125</td>\n",
       "      <td>1.87426</td>\n",
       "      <td>375</td>\n",
       "      <td>Col</td>\n",
       "      <td>40.789474</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38.461540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          run       chamber  wheel  sector  station  avg_cluster_size  \\\n",
       "2361   321735  W+2_RB4-_S07      2       7        4           1.80559   \n",
       "9990   321833  W+2_RB4+_S01      2       1        4           1.52422   \n",
       "11481  321880  W+2_RB4-_S07      2       7        4           1.78810   \n",
       "11961  321887  W+2_RB4-_S07      2       7        4           1.81956   \n",
       "13926  321961  W-2_RB4+_S01     -2       1        4           1.87192   \n",
       "\n",
       "       occupancy  avg_bx_dist  avg_no_of_clusters  avg_multiplicity  \\\n",
       "2361        1551     0.008149             1.00468           1.81404   \n",
       "9990        4059     0.009012             1.00150           1.52651   \n",
       "11481       2945     0.023679             1.00061           1.78919   \n",
       "11961      20077     0.010332             1.00100           1.82137   \n",
       "13926      10479     0.004109             1.00125           1.87426   \n",
       "\n",
       "       lumisections type  avg_efficiency  contains_zero_roll  rolls_count  \\\n",
       "2361            151  Col       50.000000                   1            2   \n",
       "9990            397  Col       41.666666                   1            2   \n",
       "11481           140  Col       36.111111                   1            2   \n",
       "11961           951  Col       56.666666                   1            2   \n",
       "13926           375  Col       40.789474                   1            2   \n",
       "\n",
       "       fid_eff_ch_level  \n",
       "2361          33.333336  \n",
       "9990          37.500000  \n",
       "11481         25.000000  \n",
       "11961         25.000000  \n",
       "13926         38.461540  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the histograms in EDA_Collisions we can see that the dataset\n",
    "# contains almost no records that have fiducial efficiency greater that 0 \n",
    "# and less than 40. To make sure, we check the exsiting data:\n",
    "\n",
    "\n",
    "eff_0_to_40 = collisions_data[(collisions_data['fid_eff_ch_level']>0)&(collisions_data['fid_eff_ch_level']<40)]\n",
    "\n",
    "print(collisions_data[(collisions_data['fid_eff_ch_level']>=80)&(collisions_data['fid_eff_ch_level']<90)].shape)\n",
    "\n",
    "print(\"\\n There are\",eff_0_to_40.shape[0],\"records containing fid efficiency between 0 and 40 in the dataset\")\n",
    "eff_0_to_40.head(5)\n",
    "\n",
    "# As we can see, there are only 50 records with fid_eff between 0 and 40 for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-mileage",
   "metadata": {},
   "source": [
    "# -------- Problem formulation --------\n",
    "\n",
    "As the problem itself suggests, predicting the efficiency of a chamber makes it a regression problem. As for regression model, it tends to be more difficult to minimize the objective function of such model. Therefore, it is decided to firstly try to solve a classification problem, splitting the dataset into N classes based on the fiducial efficiency into N equal sized buckets and trying out multiple classification models to see what output can be expected. \n",
    "\n",
    "Later on, the data will be used to train the regression models to be able to predict the numerical value for fiducial efficiency for a single chamber. \n",
    "\n",
    "Such model would help to quickly approximate the fiducial efficiency of a chamber after a Collision or a Cosmic run based on the initial metrics collected from the detectors (such as avg_cluster_size, occupancy, etc.). Also, the fiducial efficiency could be approximated for the chambers that were incorrectly assigned with the fiducial efficiency of 0 (such as the records analyzed in 1.) or if the 'correct' zero-valued records (analyzed in 2.) appears to be a discrepancy as well, such chambers could be assigned by a fiducial efficiency approximation of such model.\n",
    "\n",
    "Modeling decisions will be based on the data analysis performed in **EDA_Collisions.ipynb** notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-ethiopia",
   "metadata": {},
   "source": [
    "# Prepare data for classification task (drop unnecessary columns, assign labels, standardize, shuffle, split into train/test/validate.)\n",
    "\n",
    "Some attributes in the dataset are not useful for training the model. Such attributes would be:\n",
    "* run (run number should not be an indicator for the efficiency computation)\n",
    "* chamber (chamber name will be removed as all the chamber location data is stored within wheel, sector, station attributes)\n",
    "* type (all the records used are Collisions type, therefore, the column has to be dropped)\n",
    "* avg_efficiency (this is an efficiency retrieved from DQM system for the chambers, however, the project's aim is to compute a fiducial efficiency, thus, the column will have to be dropped)\n",
    "\n",
    "The data will have to be split into N classes (buckets) based on their fiducial efficiency values to have an equal distribution for each class. \n",
    "For this case we'll try to use the existing data and split it into equal sized buckets based on the efficiency for current data. However, if there are some more substantial ranges of efficiency that could be split into, for example, weak efficiency, medium efficiency, and strong efficiency classes, we could augment data for each range to have an equal distribution. However, at the moment, it will be split into 3 classes by dividing existing data into equally distributed 3 buckets (see below, it gets us ranges (40.7, 91.2] for weak efficiency, (91.2, 97,2] for medium efficiency and (97.2, 100] for strong efficiency). The classes will be assigned with labes 0, 1 and 2 respectively.\n",
    "\n",
    "As mentioned above, the zero valued records will have to be removed so that the model could use only the most correct data to be able to predict the efficiency as best as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "statistical-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(collisions_data['contains_zero_roll'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-vulnerability",
   "metadata": {},
   "source": [
    "### Dropping unnecessary columns and filtering records with non zero efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "settled-indonesia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape: (63360, 17)\n",
      "collisions shape: (63360, 9)\n",
      "dropped shape: (63360, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheel</th>\n",
       "      <th>sector</th>\n",
       "      <th>station</th>\n",
       "      <th>avg_cluster_size</th>\n",
       "      <th>avg_bx_dist</th>\n",
       "      <th>avg_no_of_clusters</th>\n",
       "      <th>avg_multiplicity</th>\n",
       "      <th>fid_eff_ch_level</th>\n",
       "      <th>occupancy_per_LS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.88926</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>1.00394</td>\n",
       "      <td>1.89670</td>\n",
       "      <td>96.271114</td>\n",
       "      <td>40.999044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.83989</td>\n",
       "      <td>0.006860</td>\n",
       "      <td>1.00387</td>\n",
       "      <td>1.84701</td>\n",
       "      <td>97.754410</td>\n",
       "      <td>36.297944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.99387</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>1.00391</td>\n",
       "      <td>2.00167</td>\n",
       "      <td>98.231281</td>\n",
       "      <td>43.532281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.85097</td>\n",
       "      <td>0.011014</td>\n",
       "      <td>1.00278</td>\n",
       "      <td>1.85611</td>\n",
       "      <td>98.210457</td>\n",
       "      <td>37.373505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.86637</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>1.00107</td>\n",
       "      <td>1.86836</td>\n",
       "      <td>98.584396</td>\n",
       "      <td>17.600670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wheel  sector  station  avg_cluster_size  avg_bx_dist  avg_no_of_clusters  \\\n",
       "0     -2       1        1           1.88926     0.006567             1.00394   \n",
       "1     -2       1        1           1.83989     0.006860             1.00387   \n",
       "2     -2       1        2           1.99387     0.006966             1.00391   \n",
       "3     -2       1        2           1.85097     0.011014             1.00278   \n",
       "4     -2       1        3           1.86637     0.004361             1.00107   \n",
       "\n",
       "   avg_multiplicity  fid_eff_ch_level  occupancy_per_LS  \n",
       "0           1.89670         96.271114         40.999044  \n",
       "1           1.84701         97.754410         36.297944  \n",
       "2           2.00167         98.231281         43.532281  \n",
       "3           1.85611         98.210457         37.373505  \n",
       "4           1.86836         98.584396         17.600670  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try change occupancy and lumisection to occupancy_per_ls\n",
    "\n",
    "collisions_data['occupancy_per_LS'] = collisions_data['occupancy'] / collisions_data['lumisections']\n",
    "\n",
    "# Unnecessary columns are dropped. Copy in shaped_data for classification,\n",
    "# collisions_data for regression.\n",
    "\n",
    "print('original shape:',collisions_data.shape)\n",
    "shaped_data = collisions_data.copy()\n",
    "shaped_data.drop(['run', 'chamber', 'type', 'contains_zero_roll', 'rolls_count', 'avg_efficiency', 'occupancy', 'lumisections'], axis=1, inplace=True)\n",
    "\n",
    "collisions_data.drop(['run', 'chamber', 'type', 'contains_zero_roll', 'rolls_count', 'avg_efficiency', 'occupancy', 'lumisections'], axis=1, inplace=True)\n",
    "# shaped_data.drop(['run', 'chamber', 'type', 'contains_zero_roll', 'rolls_count', 'avg_efficiency'], axis=1, inplace=True)\n",
    "\n",
    "print('collisions shape:', collisions_data.shape)\n",
    "print('dropped shape:',shaped_data.shape)\n",
    "shaped_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fourth-inside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58038, 9)\n",
      "(0.033299999999999996, 96.173]    19346\n",
      "(96.173, 97.582]                  19346\n",
      "(97.582, 100.0]                   19346\n",
      "Name: fid_eff_ch_level, dtype: int64\n",
      "Class splitting interval values:  96.173 97.582 100.0\n"
     ]
    }
   ],
   "source": [
    "# The data with unnecessary columns removed will now be filtered to\n",
    "# keep only records that contain the fiducial efficiency greater than 0.\n",
    "\n",
    "data_with_eff = shaped_data.loc[shaped_data['fid_eff_ch_level'] > 0]\n",
    "collisions_data = collisions_data.loc[collisions_data['fid_eff_ch_level']>0]\n",
    "print(data_with_eff.shape)\n",
    "\n",
    "\n",
    "# Get the range of the bins to split the data into three classes based\n",
    "# on their fiducial efficiency values.\n",
    "\n",
    "bins = pd.qcut(data_with_eff['fid_eff_ch_level'],3)\n",
    "print(bins.value_counts())\n",
    "interval_values = bins.cat.categories.right\n",
    "print('Class splitting interval values: ',interval_values[0], interval_values[1], interval_values[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-monitoring",
   "metadata": {},
   "source": [
    "### Labels based on the efficiency value are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "conceptual-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a label column for the dataset, splitting into 3 equally distributed\n",
    "# classes. label 0 - if efficiency is less than or equal to 91.22\n",
    "# label 1 - if efficiency is greater than 91.22 and less than or equal to 97.22\n",
    "# label 2 - if efficiency is greather than 97.22\n",
    "\n",
    "def assign_label(fid_eff_val):\n",
    "    if fid_eff_val <= interval_values[0]:\n",
    "        return 0\n",
    "    elif fid_eff_val <= interval_values[1]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "data_with_eff['label'] = data_with_eff['fid_eff_ch_level'].apply(lambda x: assign_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "harmful-ceremony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58038, 10)\n",
      "2    19364\n",
      "0    19346\n",
      "1    19328\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheel</th>\n",
       "      <th>sector</th>\n",
       "      <th>station</th>\n",
       "      <th>avg_cluster_size</th>\n",
       "      <th>avg_bx_dist</th>\n",
       "      <th>avg_no_of_clusters</th>\n",
       "      <th>avg_multiplicity</th>\n",
       "      <th>fid_eff_ch_level</th>\n",
       "      <th>occupancy_per_LS</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.88926</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>1.00394</td>\n",
       "      <td>1.89670</td>\n",
       "      <td>96.271114</td>\n",
       "      <td>40.999044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.83989</td>\n",
       "      <td>0.006860</td>\n",
       "      <td>1.00387</td>\n",
       "      <td>1.84701</td>\n",
       "      <td>97.754410</td>\n",
       "      <td>36.297944</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.99387</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>1.00391</td>\n",
       "      <td>2.00167</td>\n",
       "      <td>98.231281</td>\n",
       "      <td>43.532281</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.85097</td>\n",
       "      <td>0.011014</td>\n",
       "      <td>1.00278</td>\n",
       "      <td>1.85611</td>\n",
       "      <td>98.210457</td>\n",
       "      <td>37.373505</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.86637</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>1.00107</td>\n",
       "      <td>1.86836</td>\n",
       "      <td>98.584396</td>\n",
       "      <td>17.600670</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wheel  sector  station  avg_cluster_size  avg_bx_dist  avg_no_of_clusters  \\\n",
       "0     -2       1        1           1.88926     0.006567             1.00394   \n",
       "1     -2       1        1           1.83989     0.006860             1.00387   \n",
       "2     -2       1        2           1.99387     0.006966             1.00391   \n",
       "3     -2       1        2           1.85097     0.011014             1.00278   \n",
       "4     -2       1        3           1.86637     0.004361             1.00107   \n",
       "\n",
       "   avg_multiplicity  fid_eff_ch_level  occupancy_per_LS  label  \n",
       "0           1.89670         96.271114         40.999044      1  \n",
       "1           1.84701         97.754410         36.297944      2  \n",
       "2           2.00167         98.231281         43.532281      2  \n",
       "3           1.85611         98.210457         37.373505      2  \n",
       "4           1.86836         98.584396         17.600670      2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_with_eff.shape)\n",
    "print(data_with_eff['label'].value_counts())\n",
    "data_with_eff.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-attendance",
   "metadata": {},
   "source": [
    "### Shuffle and  split data into Train/Validate/Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tight-complaint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheel</th>\n",
       "      <th>sector</th>\n",
       "      <th>station</th>\n",
       "      <th>avg_cluster_size</th>\n",
       "      <th>avg_bx_dist</th>\n",
       "      <th>avg_no_of_clusters</th>\n",
       "      <th>avg_multiplicity</th>\n",
       "      <th>occupancy_per_LS</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8213</th>\n",
       "      <td>-2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.74907</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>1.00186</td>\n",
       "      <td>1.75233</td>\n",
       "      <td>21.162162</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12750</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.91406</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>1.00093</td>\n",
       "      <td>1.91584</td>\n",
       "      <td>21.009639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35969</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.86943</td>\n",
       "      <td>0.004457</td>\n",
       "      <td>1.00105</td>\n",
       "      <td>1.87139</td>\n",
       "      <td>27.423077</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54387</th>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2.01219</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>1.00515</td>\n",
       "      <td>2.02255</td>\n",
       "      <td>56.420700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22357</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1.82853</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>1.00117</td>\n",
       "      <td>1.83066</td>\n",
       "      <td>39.503145</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wheel  sector  station  avg_cluster_size  avg_bx_dist  \\\n",
       "8213      -2       7        2           1.74907     0.006701   \n",
       "12750      0      10        3           1.91406     0.004171   \n",
       "35969      2       8        4           1.86943     0.004457   \n",
       "54387     -1       7        1           2.01219     0.005391   \n",
       "22357      0      11        3           1.82853     0.006405   \n",
       "\n",
       "       avg_no_of_clusters  avg_multiplicity  occupancy_per_LS  label  \n",
       "8213              1.00186           1.75233         21.162162      2  \n",
       "12750             1.00093           1.91584         21.009639      0  \n",
       "35969             1.00105           1.87139         27.423077      2  \n",
       "54387             1.00515           2.02255         56.420700      2  \n",
       "22357             1.00117           1.83066         39.503145      1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Firstly, the column with fid_eff_ch_level will be dropped \n",
    "# since we're firstly training a classifier to predict one of the\n",
    "# three classes that were assgined as labels 0, 1 and 2.\n",
    "data_with_eff.drop(['fid_eff_ch_level'], axis=1, inplace=True)\n",
    "\n",
    "# Also, shuffle the rows in the dataset\n",
    "data_with_eff = shuffle(data_with_eff)\n",
    "collisions_data = shuffle(collisions_data)\n",
    "\n",
    "data_with_eff.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "transparent-poetry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58038, 9)\n",
      "       wheel  sector  station  avg_cluster_size  avg_bx_dist  \\\n",
      "30313     -2      10        1           2.33083     0.003968   \n",
      "26820      2       5        2           1.87865     0.008516   \n",
      "\n",
      "       avg_no_of_clusters  avg_multiplicity  fid_eff_ch_level  \\\n",
      "30313             1.00441           2.34110         96.942020   \n",
      "26820             1.00307           1.88442         97.568707   \n",
      "\n",
      "       occupancy_per_LS  \n",
      "30313         43.937008  \n",
      "26820         54.302564  \n",
      "Index(['wheel', 'sector', 'station', 'avg_cluster_size', 'avg_bx_dist',\n",
      "       'avg_no_of_clusters', 'avg_multiplicity', 'fid_eff_ch_level',\n",
      "       'occupancy_per_LS'],\n",
      "      dtype='object')\n",
      "Index(['wheel', 'sector', 'station', 'avg_cluster_size', 'avg_bx_dist',\n",
      "       'avg_no_of_clusters', 'avg_multiplicity', 'occupancy_per_LS', 'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(collisions_data.shape)\n",
    "print(collisions_data.head(2))\n",
    "col_list = collisions_data.columns\n",
    "print(col_list)\n",
    "print(data_with_eff.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "patient-viewer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Dataset is split into Train/Validate/Test subsets of size:\n",
      "train - 70.00%\n",
      "validate - 15.00%\n",
      "test - 15.00%\n",
      "Regression Dataset is split into Train/Validate/Test subsets of size:\n",
      "train - 70.00%\n",
      "validate - 15.00%\n",
      "test - 15.00%\n"
     ]
    }
   ],
   "source": [
    "# Separate the data into attributes dataFrame and\n",
    "# labels dataFrame. X_data and Y_data\n",
    "\n",
    "y_data = data_with_eff.iloc[:,-1:]\n",
    "x_data = data_with_eff.iloc[:, 0:8]\n",
    "\n",
    "y_data_reg = collisions_data.loc[:, collisions_data.columns == 'fid_eff_ch_level']\n",
    "x_data_reg = collisions_data.loc[:, collisions_data.columns != 'fid_eff_ch_level']\n",
    "\n",
    "\n",
    "# Split the data into Train/Validate/Test datasets.\n",
    "# Train dataset will be used to train models, the data\n",
    "# the models will be learning from. Validation set to be used\n",
    "# for tuning the models, for finding the best hyperparameters. \n",
    "# Whereas Test dataset will be used for final evaluation once the\n",
    "# models are optimized the most.\n",
    "\n",
    "train_ratio = 0.7\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=1-train_ratio, random_state=1)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=1)\n",
    "\n",
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x_data_reg, y_data_reg, test_size=1-train_ratio, random_state=1)\n",
    "x_val_reg, x_test_reg, y_val_reg, y_test_reg = train_test_split(x_test_reg, y_test_reg, test_size=test_ratio/(test_ratio + validation_ratio), random_state=1)\n",
    "\n",
    "print(\"Classification Dataset is split into Train/Validate/Test subsets of size:\")\n",
    "print(\"train - %.2f%%\" % ((x_train.shape[0]/(x_train.shape[0]+x_val.shape[0]+x_test.shape[0]))*100))\n",
    "print(\"validate - %.2f%%\" % ((x_val.shape[0]/(x_train.shape[0]+x_val.shape[0]+x_test.shape[0]))*100))\n",
    "print(\"test - %.2f%%\" % ((x_test.shape[0]/(x_train.shape[0]+x_val.shape[0]+x_test.shape[0]))*100))\n",
    "\n",
    "print(\"Regression Dataset is split into Train/Validate/Test subsets of size:\")\n",
    "print(\"train - %.2f%%\" % ((x_train_reg.shape[0]/(x_train_reg.shape[0]+x_val_reg.shape[0]+x_test_reg.shape[0]))*100))\n",
    "print(\"validate - %.2f%%\" % ((x_val_reg.shape[0]/(x_train_reg.shape[0]+x_val_reg.shape[0]+x_test_reg.shape[0]))*100))\n",
    "print(\"test - %.2f%%\" % ((x_test_reg.shape[0]/(x_train_reg.shape[0]+x_val_reg.shape[0]+x_test_reg.shape[0]))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-barrier",
   "metadata": {},
   "source": [
    "### Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "light-airline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.46758234e-02 6.45699798e+00 2.40803919e+00 1.91925156e+00\n",
      " 1.45527074e-02 1.00275608e+00 1.92477573e+00 6.14639530e+01]\n",
      "[4.46758234e-02 6.45699798e+00 2.40803919e+00 1.91925156e+00\n",
      " 1.45527074e-02 1.00275608e+00 1.92477573e+00 6.14639530e+01]\n"
     ]
    }
   ],
   "source": [
    "# The data will be standardized so that the different\n",
    "# attributes in the dataset will be within the same scale.\n",
    "# So that one attribute would not contain more weight \n",
    "# than other attribute.\n",
    "\n",
    "# Standardization transforms data such that its distribution\n",
    "# whill have mean value of 0 and a standard deviation of 1. \n",
    "# It is performed feature/column wise. \n",
    "# x = (x-μ)/σ\n",
    "\n",
    "# validation and test data will have to be standardized before testing\n",
    "# by using mean and standard deviation of Train dataset.\n",
    "\n",
    "#define scaler\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "print(scaler.mean_)\n",
    "\n",
    "# transform train data\n",
    "x_train = scaler.transform(x_train)\n",
    "\n",
    "\n",
    "# In practice, the scaler is stored in the preprocessing pipeline\n",
    "# and new data arriving to the model will be scaled before\n",
    "# sent into model black box to get prediction. However, right now,\n",
    "# the validation data will be scaled at the same time.\n",
    "\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "\n",
    "\n",
    "reg_scaled = preprocessing.StandardScaler().fit(x_train_reg)\n",
    "print(scaler.mean_)\n",
    "x_train_reg = reg_scaled.transform(x_train_reg)\n",
    "x_val_reg = reg_scaled.transform(x_val_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-teach",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-insured",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "egyptian-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dental-diana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy:  0.7925568573397657\n"
     ]
    }
   ],
   "source": [
    "# First test run is performed on a lazy ML model that \n",
    "# finds the K neareast neighbors in the dataset for a given\n",
    "# sample. The nearest neighbors are computed by calculating\n",
    "# Euclidean distance between the validation sample and \n",
    "# samples in train dataset.\n",
    "\n",
    "# n_neighbors = 1 means that the class will be assigned with \n",
    "# respect to the closest existing smaple in the train dataset.\n",
    "model = KNeighborsClassifier(n_neighbors=7)\n",
    "model.fit(x_train,y_train.values.ravel())\n",
    "\n",
    "knn_pred = model.predict(x_val)\n",
    "knn_accuracy = accuracy_score(y_val, knn_pred)\n",
    "\n",
    "# An initial run on such model gives us an accuracy of \n",
    "# over 75%, meaning, more than 3 out of 4 of the validation\n",
    "# samples are classified correctly based on their metrics\n",
    "print(\"KNN Accuracy: \", knn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "lyric-grass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified samples:\n",
      "1856\n",
      "\n",
      "Number of missclasified samples by true label:\n",
      "{'label0': 403, 'label1': 826, 'label2': 627}\n"
     ]
    }
   ],
   "source": [
    "incorrect_classes = {'label0':0, 'label1':0, 'label2':0}\n",
    "count = 0\n",
    "y_val_list = y_val['label'].tolist()\n",
    "\n",
    "for i in range(len(y_val_list)):\n",
    "    true_y = y_val_list[i]\n",
    "    pred_y = knn_pred[i]\n",
    "    if true_y != pred_y:\n",
    "        count += 1\n",
    "        if true_y == 0:\n",
    "            incorrect_classes['label0'] += 1\n",
    "        elif true_y == 1:\n",
    "            incorrect_classes['label1'] += 1\n",
    "        else:\n",
    "            incorrect_classes['label2'] += 1\n",
    "\n",
    "print(\"Number of misclassified samples:\")\n",
    "print(count)\n",
    "\n",
    "print(\"\\nNumber of missclasified samples by true label:\")\n",
    "print(incorrect_classes)\n",
    "\n",
    "# It is quite obvious that the most missclassfied chambers are\n",
    "# of label 1, since this class is in between two classes in\n",
    "# in a very small range. Therefore, even classes 1 and 2 might\n",
    "# be very similar based on their metrics and efficiency. \n",
    "\n",
    "# It is clear that label 0 was wrongly classified least times\n",
    "# as it contains quite a large range of efficiency, thus, it should\n",
    "# be easily predicting great part of its data. Because some records\n",
    "# should be further away from the label 1 and label 2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "happy-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "# scores = cross_val_score(clf, x_train, y_train.values.ravel(), cv=10)\n",
    "# clf = clf.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# print(\"SVM cross-validation scores:\",scores)\n",
    "# print(\"Expected classification accuracy on test set is:\",(sum(scores)/len(scores)))\n",
    "\n",
    "# clf = SVC(kernel='linear')\n",
    "# clf = clf.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dried-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_100/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5796002756719504\n"
     ]
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)\n",
    "svm_predict = clf.predict(x_val)\n",
    "svm_accuracy = accuracy_score(y_val, svm_predict)\n",
    "print(svm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb9445f",
   "metadata": {},
   "source": [
    "### Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "daa98671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_100/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/sklearn/linear_model/logistic.py:430: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  warnings.warn(\"Default solver will be changed to 'lbfgs' in 0.22. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.41913622788881233\n",
      "RandomForestClassifier 0.795543303468872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression(multi_class='ovr', max_iter=100)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=1000, max_depth=50)\n",
    "# svm_clf = SVC()\n",
    "\n",
    "for clf in (log_clf, rnd_clf):\n",
    "    clf.fit(x_train, y_train.values.ravel())\n",
    "    y_pred = clf.predict(x_val)\n",
    "    print(clf.__class__.__name__,accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4b8a492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 0.7452331725246956\n",
      "GradientBoostingClassifier 0.7969216632207673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "dt_clf.fit(x_train, y_train.values.ravel())\n",
    "y_pred = dt_clf.predict(x_val)\n",
    "print(dt_clf.__class__.__name__,accuracy_score(y_val, y_pred))\n",
    "\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, max_depth=11, random_state=0)\n",
    "gb_clf.fit(x_train, y_train.values.ravel())\n",
    "y_pred = gb_clf.predict(x_val)\n",
    "print(gb_clf.__class__.__name__,accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "697ecc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.8050769584194808\n"
     ]
    }
   ],
   "source": [
    "# Using three classifiers to collect the better overall performance when classifying data.\n",
    "# This makes it an ensemble learning, where the model performance increases when using\n",
    "# multiple classifiers together rather than single one of them separately\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('rf', rnd_clf), ('knn', model), ('gb', gb_clf)], voting='hard')\n",
    "voting_clf.fit(x_train, y_train.values.ravel())\n",
    "y_pred = voting_clf.predict(x_val)\n",
    "print(voting_clf.__class__.__name__,accuracy_score(y_val, y_pred))\n",
    "\n",
    "# However, the performance did not increase as much as could have been expected.\n",
    "\n",
    "# voting_clf = VotingClassifier(estimators=[('rf', rnd_clf), ('dt', dt_clf), ('gb', gb_clf)], voting='hard')\n",
    "# voting_clf.fit(x_train, y_train.values.ravel())\n",
    "# y_pred = voting_clf.predict(x_val)\n",
    "# print(voting_clf.__class__.__name__,accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ca0279a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier 0.589478520560533\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(x_train, y_train.values.ravel())\n",
    "y_pred = xgb_clf.predict(x_val)\n",
    "print(xgb_clf.__class__.__name__,accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e609aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(training) 1.0\n",
      "Accuracy(validation) 0.7452331725246956\n",
      "\n",
      "Criterion: gini\n",
      "\n",
      "depth: 20\n",
      "Accuracy(training) 0.9610348052971004\n",
      "Accuracy(validation) 0.7532736044107512\n",
      "\n",
      "depth: 22\n",
      "Accuracy(training) 0.980751243046325\n",
      "Accuracy(validation) 0.7483344819664599\n",
      "\n",
      "depth: 24\n",
      "Accuracy(training) 0.9921725003692217\n",
      "Accuracy(validation) 0.7476453020905123\n",
      "\n",
      "depth: 26\n",
      "Accuracy(training) 0.9975139073499729\n",
      "Accuracy(validation) 0.7451183092120377\n",
      "\n",
      "Criterion: entropy\n",
      "\n",
      "depth: 20\n",
      "Accuracy(training) 0.9576871953921134\n",
      "Accuracy(validation) 0.7546519641626465\n",
      "\n",
      "depth: 22\n",
      "Accuracy(training) 0.9791758972086841\n",
      "Accuracy(validation) 0.753618194348725\n",
      "\n",
      "depth: 24\n",
      "Accuracy(training) 0.9906709988677201\n",
      "Accuracy(validation) 0.7493682517803814\n",
      "\n",
      "depth: 26\n",
      "Accuracy(training) 0.9965047014227342\n",
      "Accuracy(validation) 0.7455777624626694\n"
     ]
    }
   ],
   "source": [
    "# Some basic hyperparameter tuning. Looking into output of using different values\n",
    "# for criterion and max_depth of DecisionTreeClassifier.\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [20,22,24,26]\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "dt_clf.fit(x_train, y_train.values.ravel())\n",
    "train_pred = dt_clf.predict(x_train)\n",
    "val_pred = dt_clf.predict(x_val)\n",
    "print(\"Accuracy(training)\",accuracy_score(y_train, train_pred))\n",
    "print(\"Accuracy(validation)\",accuracy_score(y_val, val_pred))\n",
    "\n",
    "for crit in criterion:\n",
    "    print(\"\\nCriterion:\", crit)\n",
    "    for depth in max_depth:\n",
    "        print(\"\\ndepth:\", depth)\n",
    "        dt_clf = DecisionTreeClassifier(random_state=0, criterion = crit, max_depth=depth)\n",
    "        dt_clf.fit(x_train, y_train.values.ravel())\n",
    "        train_pred = dt_clf.predict(x_train)\n",
    "        val_pred = dt_clf.predict(x_val)\n",
    "        print(\"Accuracy(training)\",accuracy_score(y_train, train_pred))\n",
    "        print(\"Accuracy(validation)\",accuracy_score(y_val, val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d363d5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier 0.7880771881461062\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=0.1, max_depth=11, random_state=0)\n",
    "gb_clf.fit(x_train, y_train.values.ravel())\n",
    "y_pred = gb_clf.predict(x_val)\n",
    "print(gb_clf.__class__.__name__,accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f9fe8b",
   "metadata": {},
   "source": [
    "## Keras NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8357feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.optimizers import adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a66f9720",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_y = np_utils.to_categorical(y_train)\n",
    "encoded_val_y = np_utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d156e924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40626, 8)\n",
      "Epoch 1/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 1.0101 - accuracy: 0.5082 - val_loss: 0.9582 - val_accuracy: 0.5433\n",
      "Epoch 2/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.9395 - accuracy: 0.5609 - val_loss: 0.8794 - val_accuracy: 0.6029\n",
      "Epoch 3/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.8790 - accuracy: 0.6004 - val_loss: 0.8087 - val_accuracy: 0.6444\n",
      "Epoch 4/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.8236 - accuracy: 0.6345 - val_loss: 0.7497 - val_accuracy: 0.6744\n",
      "Epoch 5/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.7812 - accuracy: 0.6601 - val_loss: 0.7103 - val_accuracy: 0.7041\n",
      "Epoch 6/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.7514 - accuracy: 0.6787 - val_loss: 0.6902 - val_accuracy: 0.7141\n",
      "Epoch 7/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.7288 - accuracy: 0.6926 - val_loss: 0.6494 - val_accuracy: 0.7390\n",
      "Epoch 8/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.7112 - accuracy: 0.7027 - val_loss: 0.6382 - val_accuracy: 0.7516\n",
      "Epoch 9/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.7146 - val_loss: 0.6308 - val_accuracy: 0.7496\n",
      "Epoch 10/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6823 - accuracy: 0.7194 - val_loss: 0.6117 - val_accuracy: 0.7544\n",
      "Epoch 11/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6683 - accuracy: 0.7288 - val_loss: 0.6091 - val_accuracy: 0.7621\n",
      "Epoch 12/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6607 - accuracy: 0.7341 - val_loss: 0.6007 - val_accuracy: 0.7666\n",
      "Epoch 13/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6504 - accuracy: 0.7396 - val_loss: 0.5842 - val_accuracy: 0.7775\n",
      "Epoch 14/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6452 - accuracy: 0.7429 - val_loss: 0.5908 - val_accuracy: 0.7694\n",
      "Epoch 15/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6376 - accuracy: 0.7470 - val_loss: 0.5892 - val_accuracy: 0.7745\n",
      "Epoch 16/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6318 - accuracy: 0.7503 - val_loss: 0.5823 - val_accuracy: 0.7780\n",
      "Epoch 17/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6290 - accuracy: 0.7537 - val_loss: 0.5791 - val_accuracy: 0.7781\n",
      "Epoch 18/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6265 - accuracy: 0.7538 - val_loss: 0.5728 - val_accuracy: 0.7831\n",
      "Epoch 19/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6213 - accuracy: 0.7545 - val_loss: 0.5749 - val_accuracy: 0.7813\n",
      "Epoch 20/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6160 - accuracy: 0.7604 - val_loss: 0.5768 - val_accuracy: 0.7800\n",
      "Epoch 21/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6126 - accuracy: 0.7621 - val_loss: 0.5679 - val_accuracy: 0.7805\n",
      "Epoch 22/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6108 - accuracy: 0.7613 - val_loss: 0.5635 - val_accuracy: 0.7872\n",
      "Epoch 23/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6093 - accuracy: 0.7631 - val_loss: 0.5624 - val_accuracy: 0.7870\n",
      "Epoch 24/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6048 - accuracy: 0.7627 - val_loss: 0.5607 - val_accuracy: 0.7881\n",
      "Epoch 25/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.6006 - accuracy: 0.7669 - val_loss: 0.5560 - val_accuracy: 0.7909\n",
      "Epoch 26/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5961 - accuracy: 0.7694 - val_loss: 0.5557 - val_accuracy: 0.7922\n",
      "Epoch 27/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5967 - accuracy: 0.7696 - val_loss: 0.5608 - val_accuracy: 0.7880\n",
      "Epoch 28/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5903 - accuracy: 0.7688 - val_loss: 0.5493 - val_accuracy: 0.7974\n",
      "Epoch 29/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5917 - accuracy: 0.7701 - val_loss: 0.5528 - val_accuracy: 0.7936\n",
      "Epoch 30/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5873 - accuracy: 0.7748 - val_loss: 0.5531 - val_accuracy: 0.7896\n",
      "Epoch 31/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5848 - accuracy: 0.7742 - val_loss: 0.5512 - val_accuracy: 0.7976\n",
      "Epoch 32/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5845 - accuracy: 0.7746 - val_loss: 0.5547 - val_accuracy: 0.7900\n",
      "Epoch 33/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5819 - accuracy: 0.7748 - val_loss: 0.5501 - val_accuracy: 0.7943\n",
      "Epoch 34/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5808 - accuracy: 0.7757 - val_loss: 0.5466 - val_accuracy: 0.7937\n",
      "Epoch 35/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5794 - accuracy: 0.7767 - val_loss: 0.5463 - val_accuracy: 0.7961\n",
      "Epoch 36/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5771 - accuracy: 0.7774 - val_loss: 0.5448 - val_accuracy: 0.7977\n",
      "Epoch 37/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5774 - accuracy: 0.7777 - val_loss: 0.5431 - val_accuracy: 0.7951\n",
      "Epoch 38/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5742 - accuracy: 0.7806 - val_loss: 0.5439 - val_accuracy: 0.7937\n",
      "Epoch 39/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5739 - accuracy: 0.7800 - val_loss: 0.5400 - val_accuracy: 0.7983\n",
      "Epoch 40/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5721 - accuracy: 0.7808 - val_loss: 0.5428 - val_accuracy: 0.7953\n",
      "Epoch 41/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5720 - accuracy: 0.7830 - val_loss: 0.5405 - val_accuracy: 0.7984\n",
      "Epoch 42/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5709 - accuracy: 0.7798 - val_loss: 0.5488 - val_accuracy: 0.7949\n",
      "Epoch 43/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5694 - accuracy: 0.7814 - val_loss: 0.5403 - val_accuracy: 0.7967\n",
      "Epoch 44/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5694 - accuracy: 0.7811 - val_loss: 0.5380 - val_accuracy: 0.7966\n",
      "Epoch 45/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5650 - accuracy: 0.7819 - val_loss: 0.5386 - val_accuracy: 0.8030\n",
      "Epoch 46/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5684 - accuracy: 0.7821 - val_loss: 0.5362 - val_accuracy: 0.7988\n",
      "Epoch 47/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5644 - accuracy: 0.7819 - val_loss: 0.5460 - val_accuracy: 0.7984\n",
      "Epoch 48/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5628 - accuracy: 0.7855 - val_loss: 0.5346 - val_accuracy: 0.8005\n",
      "Epoch 49/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5618 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7967\n",
      "Epoch 50/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5613 - accuracy: 0.7845 - val_loss: 0.5372 - val_accuracy: 0.7996\n",
      "Epoch 51/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5634 - accuracy: 0.7833 - val_loss: 0.5367 - val_accuracy: 0.7997\n",
      "Epoch 52/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5599 - accuracy: 0.7857 - val_loss: 0.5363 - val_accuracy: 0.7960\n",
      "Epoch 53/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5593 - accuracy: 0.7871 - val_loss: 0.5404 - val_accuracy: 0.7975\n",
      "Epoch 54/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5606 - accuracy: 0.7859 - val_loss: 0.5356 - val_accuracy: 0.7988\n",
      "Epoch 55/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5599 - accuracy: 0.7842 - val_loss: 0.5354 - val_accuracy: 0.7978\n",
      "Epoch 56/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5566 - accuracy: 0.7859 - val_loss: 0.5300 - val_accuracy: 0.8006\n",
      "Epoch 57/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5583 - accuracy: 0.7857 - val_loss: 0.5371 - val_accuracy: 0.7969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5594 - accuracy: 0.7849 - val_loss: 0.5343 - val_accuracy: 0.8006\n",
      "Epoch 59/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5576 - accuracy: 0.7860 - val_loss: 0.5354 - val_accuracy: 0.7984\n",
      "Epoch 60/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5568 - accuracy: 0.7868 - val_loss: 0.5412 - val_accuracy: 0.8007\n",
      "Epoch 61/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5536 - accuracy: 0.7886 - val_loss: 0.5319 - val_accuracy: 0.7990\n",
      "Epoch 62/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5563 - accuracy: 0.7862 - val_loss: 0.5302 - val_accuracy: 0.7999\n",
      "Epoch 63/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5526 - accuracy: 0.7886 - val_loss: 0.5339 - val_accuracy: 0.7978\n",
      "Epoch 64/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5543 - accuracy: 0.7870 - val_loss: 0.5347 - val_accuracy: 0.8047\n",
      "Epoch 65/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5531 - accuracy: 0.7871 - val_loss: 0.5309 - val_accuracy: 0.8011\n",
      "Epoch 66/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5554 - accuracy: 0.7877 - val_loss: 0.5339 - val_accuracy: 0.8016\n",
      "Epoch 67/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5552 - accuracy: 0.7873 - val_loss: 0.5300 - val_accuracy: 0.8007\n",
      "Epoch 68/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5568 - accuracy: 0.7869 - val_loss: 0.5284 - val_accuracy: 0.8020\n",
      "Epoch 69/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5506 - accuracy: 0.7907 - val_loss: 0.5336 - val_accuracy: 0.7981\n",
      "Epoch 70/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5487 - accuracy: 0.7902 - val_loss: 0.5314 - val_accuracy: 0.8000\n",
      "Epoch 71/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5495 - accuracy: 0.7901 - val_loss: 0.5316 - val_accuracy: 0.8000\n",
      "Epoch 72/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5490 - accuracy: 0.7902 - val_loss: 0.5318 - val_accuracy: 0.7982\n",
      "Epoch 73/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5475 - accuracy: 0.7899 - val_loss: 0.5281 - val_accuracy: 0.7993\n",
      "Epoch 74/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5508 - accuracy: 0.7891 - val_loss: 0.5281 - val_accuracy: 0.8027\n",
      "Epoch 75/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5503 - accuracy: 0.7914 - val_loss: 0.5312 - val_accuracy: 0.8029\n",
      "Epoch 76/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5487 - accuracy: 0.7907 - val_loss: 0.5311 - val_accuracy: 0.8004\n",
      "Epoch 77/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5485 - accuracy: 0.7902 - val_loss: 0.5316 - val_accuracy: 0.8035\n",
      "Epoch 78/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5487 - accuracy: 0.7909 - val_loss: 0.5300 - val_accuracy: 0.8037\n",
      "Epoch 79/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5471 - accuracy: 0.7899 - val_loss: 0.5305 - val_accuracy: 0.7997\n",
      "Epoch 80/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5478 - accuracy: 0.7887 - val_loss: 0.5283 - val_accuracy: 0.8012\n",
      "Epoch 81/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5468 - accuracy: 0.7892 - val_loss: 0.5291 - val_accuracy: 0.8003\n",
      "Epoch 82/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5477 - accuracy: 0.7885 - val_loss: 0.5218 - val_accuracy: 0.8048\n",
      "Epoch 83/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5474 - accuracy: 0.7913 - val_loss: 0.5264 - val_accuracy: 0.8024\n",
      "Epoch 84/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5458 - accuracy: 0.7914 - val_loss: 0.5292 - val_accuracy: 0.8003\n",
      "Epoch 85/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5472 - accuracy: 0.7892 - val_loss: 0.5280 - val_accuracy: 0.8030\n",
      "Epoch 86/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5457 - accuracy: 0.7908 - val_loss: 0.5271 - val_accuracy: 0.8016\n",
      "Epoch 87/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5440 - accuracy: 0.7916 - val_loss: 0.5316 - val_accuracy: 0.8021\n",
      "Epoch 88/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5472 - accuracy: 0.7905 - val_loss: 0.5319 - val_accuracy: 0.7988\n",
      "Epoch 89/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5438 - accuracy: 0.7918 - val_loss: 0.5318 - val_accuracy: 0.7996\n",
      "Epoch 90/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5430 - accuracy: 0.7915 - val_loss: 0.5249 - val_accuracy: 0.8030\n",
      "Epoch 91/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5443 - accuracy: 0.7926 - val_loss: 0.5268 - val_accuracy: 0.8039\n",
      "Epoch 92/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5450 - accuracy: 0.7917 - val_loss: 0.5234 - val_accuracy: 0.8034\n",
      "Epoch 93/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5444 - accuracy: 0.7919 - val_loss: 0.5280 - val_accuracy: 0.8011\n",
      "Epoch 94/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5443 - accuracy: 0.7917 - val_loss: 0.5273 - val_accuracy: 0.8024\n",
      "Epoch 95/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5442 - accuracy: 0.7907 - val_loss: 0.5324 - val_accuracy: 0.8019\n",
      "Epoch 96/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5423 - accuracy: 0.7927 - val_loss: 0.5206 - val_accuracy: 0.8040\n",
      "Epoch 97/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5422 - accuracy: 0.7934 - val_loss: 0.5303 - val_accuracy: 0.8015\n",
      "Epoch 98/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5390 - accuracy: 0.7944 - val_loss: 0.5321 - val_accuracy: 0.8020\n",
      "Epoch 99/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5434 - accuracy: 0.7914 - val_loss: 0.5249 - val_accuracy: 0.8005\n",
      "Epoch 100/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5389 - accuracy: 0.7949 - val_loss: 0.5278 - val_accuracy: 0.7992\n",
      "Epoch 101/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5426 - accuracy: 0.7922 - val_loss: 0.5271 - val_accuracy: 0.8016\n",
      "Epoch 102/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5414 - accuracy: 0.7938 - val_loss: 0.5292 - val_accuracy: 0.8020\n",
      "Epoch 103/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5398 - accuracy: 0.7922 - val_loss: 0.5271 - val_accuracy: 0.8007\n",
      "Epoch 104/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5404 - accuracy: 0.7950 - val_loss: 0.5284 - val_accuracy: 0.8024\n",
      "Epoch 105/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5400 - accuracy: 0.7938 - val_loss: 0.5264 - val_accuracy: 0.8023\n",
      "Epoch 106/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5402 - accuracy: 0.7930 - val_loss: 0.5259 - val_accuracy: 0.8030\n",
      "Epoch 107/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5379 - accuracy: 0.7936 - val_loss: 0.5245 - val_accuracy: 0.8055\n",
      "Epoch 108/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5414 - accuracy: 0.7935 - val_loss: 0.5261 - val_accuracy: 0.8021\n",
      "Epoch 109/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5385 - accuracy: 0.7942 - val_loss: 0.5279 - val_accuracy: 0.8013\n",
      "Epoch 110/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5398 - accuracy: 0.7924 - val_loss: 0.5264 - val_accuracy: 0.8042\n",
      "Epoch 111/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5374 - accuracy: 0.7946 - val_loss: 0.5243 - val_accuracy: 0.8031\n",
      "Epoch 112/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5386 - accuracy: 0.7928 - val_loss: 0.5278 - val_accuracy: 0.8048\n",
      "Epoch 113/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5401 - accuracy: 0.7948 - val_loss: 0.5233 - val_accuracy: 0.8043\n",
      "Epoch 114/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5396 - accuracy: 0.7931 - val_loss: 0.5285 - val_accuracy: 0.8028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5403 - accuracy: 0.7930 - val_loss: 0.5245 - val_accuracy: 0.8013\n",
      "Epoch 116/500\n",
      "407/407 [==============================] - 2s 5ms/step - loss: 0.5362 - accuracy: 0.7948 - val_loss: 0.5219 - val_accuracy: 0.8006\n",
      "Epoch 117/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5338 - accuracy: 0.7954 - val_loss: 0.5252 - val_accuracy: 0.8043\n",
      "Epoch 118/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5399 - accuracy: 0.7965 - val_loss: 0.5337 - val_accuracy: 0.8006\n",
      "Epoch 119/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5390 - accuracy: 0.7932 - val_loss: 0.5353 - val_accuracy: 0.8004\n",
      "Epoch 120/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5358 - accuracy: 0.7949 - val_loss: 0.5233 - val_accuracy: 0.8070\n",
      "Epoch 121/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5357 - accuracy: 0.7948 - val_loss: 0.5267 - val_accuracy: 0.8051\n",
      "Epoch 122/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5340 - accuracy: 0.7957 - val_loss: 0.5229 - val_accuracy: 0.8065\n",
      "Epoch 123/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5355 - accuracy: 0.7964 - val_loss: 0.5307 - val_accuracy: 0.8008\n",
      "Epoch 124/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5365 - accuracy: 0.7940 - val_loss: 0.5241 - val_accuracy: 0.8037\n",
      "Epoch 125/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5349 - accuracy: 0.7960 - val_loss: 0.5243 - val_accuracy: 0.8037\n",
      "Epoch 126/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5328 - accuracy: 0.7963 - val_loss: 0.5300 - val_accuracy: 0.8016\n",
      "Epoch 127/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5379 - accuracy: 0.7941 - val_loss: 0.5265 - val_accuracy: 0.8082\n",
      "Epoch 128/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5392 - accuracy: 0.7928 - val_loss: 0.5222 - val_accuracy: 0.8066\n",
      "Epoch 129/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5342 - accuracy: 0.7951 - val_loss: 0.5277 - val_accuracy: 0.7994\n",
      "Epoch 130/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5313 - accuracy: 0.7948 - val_loss: 0.5308 - val_accuracy: 0.8029\n",
      "Epoch 131/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5353 - accuracy: 0.7964 - val_loss: 0.5313 - val_accuracy: 0.8038\n",
      "Epoch 132/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.7967 - val_loss: 0.5290 - val_accuracy: 0.8017\n",
      "Epoch 133/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5367 - accuracy: 0.7948 - val_loss: 0.5237 - val_accuracy: 0.8011\n",
      "Epoch 134/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5342 - accuracy: 0.7951 - val_loss: 0.5278 - val_accuracy: 0.8009\n",
      "Epoch 135/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5327 - accuracy: 0.7952 - val_loss: 0.5268 - val_accuracy: 0.8043\n",
      "Epoch 136/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5350 - accuracy: 0.7953 - val_loss: 0.5256 - val_accuracy: 0.8031\n",
      "Epoch 137/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5345 - accuracy: 0.7955 - val_loss: 0.5273 - val_accuracy: 0.8013\n",
      "Epoch 138/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5333 - accuracy: 0.7952 - val_loss: 0.5239 - val_accuracy: 0.8036\n",
      "Epoch 139/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5365 - accuracy: 0.7950 - val_loss: 0.5197 - val_accuracy: 0.8069\n",
      "Epoch 140/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5319 - accuracy: 0.7968 - val_loss: 0.5240 - val_accuracy: 0.8038\n",
      "Epoch 141/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.7963 - val_loss: 0.5245 - val_accuracy: 0.8076\n",
      "Epoch 142/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5365 - accuracy: 0.7968 - val_loss: 0.5247 - val_accuracy: 0.8037\n",
      "Epoch 143/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5316 - accuracy: 0.7976 - val_loss: 0.5350 - val_accuracy: 0.7993\n",
      "Epoch 144/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5323 - accuracy: 0.7962 - val_loss: 0.5260 - val_accuracy: 0.8043\n",
      "Epoch 145/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5347 - accuracy: 0.7945 - val_loss: 0.5284 - val_accuracy: 0.8023\n",
      "Epoch 146/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5309 - accuracy: 0.7961 - val_loss: 0.5245 - val_accuracy: 0.8029\n",
      "Epoch 147/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5324 - accuracy: 0.7968 - val_loss: 0.5254 - val_accuracy: 0.8028\n",
      "Epoch 148/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5332 - accuracy: 0.7961 - val_loss: 0.5235 - val_accuracy: 0.8069\n",
      "Epoch 149/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.7959 - val_loss: 0.5248 - val_accuracy: 0.8081\n",
      "Epoch 150/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5329 - accuracy: 0.7967 - val_loss: 0.5224 - val_accuracy: 0.8043\n",
      "Epoch 151/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5308 - accuracy: 0.7959 - val_loss: 0.5245 - val_accuracy: 0.8003\n",
      "Epoch 152/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5314 - accuracy: 0.7976 - val_loss: 0.5241 - val_accuracy: 0.8044\n",
      "Epoch 153/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5361 - accuracy: 0.7968 - val_loss: 0.5236 - val_accuracy: 0.8052\n",
      "Epoch 154/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.7972 - val_loss: 0.5235 - val_accuracy: 0.8070\n",
      "Epoch 155/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5319 - accuracy: 0.7979 - val_loss: 0.5237 - val_accuracy: 0.8070\n",
      "Epoch 156/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5314 - accuracy: 0.7970 - val_loss: 0.5203 - val_accuracy: 0.8051\n",
      "Epoch 157/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5333 - accuracy: 0.7946 - val_loss: 0.5168 - val_accuracy: 0.8053\n",
      "Epoch 158/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5312 - accuracy: 0.7981 - val_loss: 0.5194 - val_accuracy: 0.8047\n",
      "Epoch 159/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5309 - accuracy: 0.7967 - val_loss: 0.5215 - val_accuracy: 0.8054\n",
      "Epoch 160/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5305 - accuracy: 0.7963 - val_loss: 0.5219 - val_accuracy: 0.8036\n",
      "Epoch 161/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5296 - accuracy: 0.7977 - val_loss: 0.5211 - val_accuracy: 0.8037\n",
      "Epoch 162/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5291 - accuracy: 0.7992 - val_loss: 0.5184 - val_accuracy: 0.8055\n",
      "Epoch 163/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5292 - accuracy: 0.7975 - val_loss: 0.5226 - val_accuracy: 0.8032\n",
      "Epoch 164/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5311 - accuracy: 0.7953 - val_loss: 0.5173 - val_accuracy: 0.8048\n",
      "Epoch 165/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5286 - accuracy: 0.7990 - val_loss: 0.5220 - val_accuracy: 0.8053\n",
      "Epoch 166/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5277 - accuracy: 0.7983 - val_loss: 0.5212 - val_accuracy: 0.8073\n",
      "Epoch 167/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.7975 - val_loss: 0.5228 - val_accuracy: 0.8055\n",
      "Epoch 168/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5301 - accuracy: 0.7991 - val_loss: 0.5237 - val_accuracy: 0.8028\n",
      "Epoch 169/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5305 - accuracy: 0.7987 - val_loss: 0.5269 - val_accuracy: 0.8039\n",
      "Epoch 170/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5305 - accuracy: 0.7982 - val_loss: 0.5214 - val_accuracy: 0.8048\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5293 - accuracy: 0.7968 - val_loss: 0.5225 - val_accuracy: 0.8005\n",
      "Epoch 172/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5291 - accuracy: 0.7964 - val_loss: 0.5155 - val_accuracy: 0.8059\n",
      "Epoch 173/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5301 - accuracy: 0.7983 - val_loss: 0.5169 - val_accuracy: 0.8075\n",
      "Epoch 174/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5292 - accuracy: 0.7962 - val_loss: 0.5193 - val_accuracy: 0.8057\n",
      "Epoch 175/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5304 - accuracy: 0.7974 - val_loss: 0.5187 - val_accuracy: 0.8085\n",
      "Epoch 176/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5284 - accuracy: 0.7976 - val_loss: 0.5197 - val_accuracy: 0.8065\n",
      "Epoch 177/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5286 - accuracy: 0.7988 - val_loss: 0.5244 - val_accuracy: 0.8025\n",
      "Epoch 178/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5303 - accuracy: 0.7969 - val_loss: 0.5178 - val_accuracy: 0.8086\n",
      "Epoch 179/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5286 - accuracy: 0.7983 - val_loss: 0.5209 - val_accuracy: 0.8081\n",
      "Epoch 180/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5292 - accuracy: 0.7969 - val_loss: 0.5236 - val_accuracy: 0.8055\n",
      "Epoch 181/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5304 - accuracy: 0.7976 - val_loss: 0.5248 - val_accuracy: 0.8025\n",
      "Epoch 182/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5307 - accuracy: 0.7972 - val_loss: 0.5219 - val_accuracy: 0.7996\n",
      "Epoch 183/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5301 - accuracy: 0.7986 - val_loss: 0.5211 - val_accuracy: 0.8086\n",
      "Epoch 184/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5297 - accuracy: 0.7969 - val_loss: 0.5197 - val_accuracy: 0.8069\n",
      "Epoch 185/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5296 - accuracy: 0.7972 - val_loss: 0.5207 - val_accuracy: 0.8040\n",
      "Epoch 186/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5262 - accuracy: 0.7990 - val_loss: 0.5205 - val_accuracy: 0.8009\n",
      "Epoch 187/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5291 - accuracy: 0.7972 - val_loss: 0.5235 - val_accuracy: 0.8066\n",
      "Epoch 188/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5282 - accuracy: 0.7990 - val_loss: 0.5205 - val_accuracy: 0.8050\n",
      "Epoch 189/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5284 - accuracy: 0.7985 - val_loss: 0.5245 - val_accuracy: 0.8019\n",
      "Epoch 190/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5277 - accuracy: 0.7971 - val_loss: 0.5166 - val_accuracy: 0.8083\n",
      "Epoch 191/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5260 - accuracy: 0.7995 - val_loss: 0.5221 - val_accuracy: 0.8027\n",
      "Epoch 192/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5299 - accuracy: 0.7978 - val_loss: 0.5195 - val_accuracy: 0.8073\n",
      "Epoch 193/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5249 - accuracy: 0.8004 - val_loss: 0.5219 - val_accuracy: 0.8016\n",
      "Epoch 194/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5287 - accuracy: 0.7974 - val_loss: 0.5244 - val_accuracy: 0.8030\n",
      "Epoch 195/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5283 - accuracy: 0.7969 - val_loss: 0.5225 - val_accuracy: 0.8054\n",
      "Epoch 196/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5292 - accuracy: 0.7978 - val_loss: 0.5197 - val_accuracy: 0.8035\n",
      "Epoch 197/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5256 - accuracy: 0.7984 - val_loss: 0.5187 - val_accuracy: 0.8082\n",
      "Epoch 198/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5255 - accuracy: 0.7997 - val_loss: 0.5212 - val_accuracy: 0.8070\n",
      "Epoch 199/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5277 - accuracy: 0.7990 - val_loss: 0.5216 - val_accuracy: 0.8070\n",
      "Epoch 200/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5253 - accuracy: 0.7993 - val_loss: 0.5203 - val_accuracy: 0.8057\n",
      "Epoch 201/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5284 - accuracy: 0.7978 - val_loss: 0.5245 - val_accuracy: 0.8042\n",
      "Epoch 202/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5280 - accuracy: 0.7990 - val_loss: 0.5124 - val_accuracy: 0.8061\n",
      "Epoch 203/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5288 - accuracy: 0.7974 - val_loss: 0.5187 - val_accuracy: 0.8104\n",
      "Epoch 204/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5277 - accuracy: 0.7998 - val_loss: 0.5177 - val_accuracy: 0.8061\n",
      "Epoch 205/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5276 - accuracy: 0.7971 - val_loss: 0.5188 - val_accuracy: 0.8045\n",
      "Epoch 206/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5277 - accuracy: 0.7980 - val_loss: 0.5188 - val_accuracy: 0.8073\n",
      "Epoch 207/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5258 - accuracy: 0.7984 - val_loss: 0.5216 - val_accuracy: 0.8039\n",
      "Epoch 208/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5262 - accuracy: 0.7985 - val_loss: 0.5222 - val_accuracy: 0.8059\n",
      "Epoch 209/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5251 - accuracy: 0.8002 - val_loss: 0.5169 - val_accuracy: 0.8069\n",
      "Epoch 210/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5264 - accuracy: 0.7990 - val_loss: 0.5234 - val_accuracy: 0.8015\n",
      "Epoch 211/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5247 - accuracy: 0.7994 - val_loss: 0.5189 - val_accuracy: 0.8063\n",
      "Epoch 212/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5297 - accuracy: 0.7971 - val_loss: 0.5197 - val_accuracy: 0.8057\n",
      "Epoch 213/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5259 - accuracy: 0.7998 - val_loss: 0.5181 - val_accuracy: 0.8048\n",
      "Epoch 214/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5251 - accuracy: 0.8003 - val_loss: 0.5174 - val_accuracy: 0.8062\n",
      "Epoch 215/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5223 - accuracy: 0.8003 - val_loss: 0.5227 - val_accuracy: 0.8053\n",
      "Epoch 216/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5257 - accuracy: 0.7999 - val_loss: 0.5220 - val_accuracy: 0.8076\n",
      "Epoch 217/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5259 - accuracy: 0.7985 - val_loss: 0.5231 - val_accuracy: 0.8066\n",
      "Epoch 218/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5250 - accuracy: 0.8001 - val_loss: 0.5210 - val_accuracy: 0.8034\n",
      "Epoch 219/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5234 - accuracy: 0.8000 - val_loss: 0.5180 - val_accuracy: 0.8088\n",
      "Epoch 220/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5260 - accuracy: 0.7981 - val_loss: 0.5194 - val_accuracy: 0.8071\n",
      "Epoch 221/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5229 - accuracy: 0.7984 - val_loss: 0.5219 - val_accuracy: 0.8053\n",
      "Epoch 222/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5259 - accuracy: 0.7999 - val_loss: 0.5219 - val_accuracy: 0.8071\n",
      "Epoch 223/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5234 - accuracy: 0.8005 - val_loss: 0.5216 - val_accuracy: 0.8053\n",
      "Epoch 224/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5268 - accuracy: 0.7978 - val_loss: 0.5192 - val_accuracy: 0.8086\n",
      "Epoch 225/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5248 - accuracy: 0.7999 - val_loss: 0.5198 - val_accuracy: 0.8055\n",
      "Epoch 226/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5248 - accuracy: 0.7989 - val_loss: 0.5192 - val_accuracy: 0.8065\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5261 - accuracy: 0.7986 - val_loss: 0.5168 - val_accuracy: 0.8043\n",
      "Epoch 228/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5248 - accuracy: 0.8004 - val_loss: 0.5232 - val_accuracy: 0.8019\n",
      "Epoch 229/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5252 - accuracy: 0.7992 - val_loss: 0.5214 - val_accuracy: 0.8066\n",
      "Epoch 230/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5244 - accuracy: 0.7995 - val_loss: 0.5192 - val_accuracy: 0.8057\n",
      "Epoch 231/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5235 - accuracy: 0.8002 - val_loss: 0.5234 - val_accuracy: 0.8069\n",
      "Epoch 232/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5260 - accuracy: 0.7994 - val_loss: 0.5187 - val_accuracy: 0.8065\n",
      "Epoch 233/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5233 - accuracy: 0.8008 - val_loss: 0.5211 - val_accuracy: 0.8076\n",
      "Epoch 234/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5245 - accuracy: 0.7991 - val_loss: 0.5164 - val_accuracy: 0.8097\n",
      "Epoch 235/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5242 - accuracy: 0.8000 - val_loss: 0.5208 - val_accuracy: 0.8070\n",
      "Epoch 236/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5247 - accuracy: 0.8000 - val_loss: 0.5148 - val_accuracy: 0.8079\n",
      "Epoch 237/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5245 - accuracy: 0.7997 - val_loss: 0.5217 - val_accuracy: 0.8044\n",
      "Epoch 238/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5244 - accuracy: 0.7999 - val_loss: 0.5205 - val_accuracy: 0.8078\n",
      "Epoch 239/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5243 - accuracy: 0.8007 - val_loss: 0.5244 - val_accuracy: 0.8030\n",
      "Epoch 240/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5269 - accuracy: 0.8001 - val_loss: 0.5207 - val_accuracy: 0.8074\n",
      "Epoch 241/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5269 - accuracy: 0.7982 - val_loss: 0.5206 - val_accuracy: 0.8067\n",
      "Epoch 242/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5229 - accuracy: 0.7996 - val_loss: 0.5204 - val_accuracy: 0.8065\n",
      "Epoch 243/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5233 - accuracy: 0.8010 - val_loss: 0.5197 - val_accuracy: 0.8094\n",
      "Epoch 244/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5253 - accuracy: 0.7995 - val_loss: 0.5164 - val_accuracy: 0.8065\n",
      "Epoch 245/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5236 - accuracy: 0.8003 - val_loss: 0.5221 - val_accuracy: 0.8052\n",
      "Epoch 246/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5220 - accuracy: 0.7998 - val_loss: 0.5208 - val_accuracy: 0.8040\n",
      "Epoch 247/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5240 - accuracy: 0.7978 - val_loss: 0.5230 - val_accuracy: 0.8053\n",
      "Epoch 248/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5244 - accuracy: 0.7999 - val_loss: 0.5215 - val_accuracy: 0.8045\n",
      "Epoch 249/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5229 - accuracy: 0.7994 - val_loss: 0.5159 - val_accuracy: 0.8067\n",
      "Epoch 250/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5206 - accuracy: 0.8002 - val_loss: 0.5254 - val_accuracy: 0.8067\n",
      "Epoch 251/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5229 - accuracy: 0.8009 - val_loss: 0.5256 - val_accuracy: 0.8088\n",
      "Epoch 252/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5251 - accuracy: 0.7999 - val_loss: 0.5221 - val_accuracy: 0.8021\n",
      "Epoch 253/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5223 - accuracy: 0.8009 - val_loss: 0.5251 - val_accuracy: 0.8061\n",
      "Epoch 254/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5242 - accuracy: 0.8003 - val_loss: 0.5176 - val_accuracy: 0.8052\n",
      "Epoch 255/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5218 - accuracy: 0.8042 - val_loss: 0.5209 - val_accuracy: 0.8083\n",
      "Epoch 256/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5233 - accuracy: 0.8006 - val_loss: 0.5206 - val_accuracy: 0.8062\n",
      "Epoch 257/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5249 - accuracy: 0.7996 - val_loss: 0.5192 - val_accuracy: 0.8062\n",
      "Epoch 258/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5237 - accuracy: 0.7991 - val_loss: 0.5253 - val_accuracy: 0.8076\n",
      "Epoch 259/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5246 - accuracy: 0.7989 - val_loss: 0.5235 - val_accuracy: 0.8053\n",
      "Epoch 260/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5215 - accuracy: 0.7988 - val_loss: 0.5199 - val_accuracy: 0.8046\n",
      "Epoch 261/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5245 - accuracy: 0.7981 - val_loss: 0.5225 - val_accuracy: 0.8078\n",
      "Epoch 262/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5249 - accuracy: 0.7988 - val_loss: 0.5196 - val_accuracy: 0.8052\n",
      "Epoch 263/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5240 - accuracy: 0.8018 - val_loss: 0.5234 - val_accuracy: 0.8038\n",
      "Epoch 264/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5225 - accuracy: 0.8010 - val_loss: 0.5174 - val_accuracy: 0.8077\n",
      "Epoch 265/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5225 - accuracy: 0.8001 - val_loss: 0.5208 - val_accuracy: 0.8069\n",
      "Epoch 266/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5210 - accuracy: 0.8019 - val_loss: 0.5178 - val_accuracy: 0.8091\n",
      "Epoch 267/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5243 - accuracy: 0.8001 - val_loss: 0.5173 - val_accuracy: 0.8094\n",
      "Epoch 268/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5212 - accuracy: 0.8015 - val_loss: 0.5175 - val_accuracy: 0.8105\n",
      "Epoch 269/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5234 - accuracy: 0.8001 - val_loss: 0.5166 - val_accuracy: 0.8038\n",
      "Epoch 270/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5225 - accuracy: 0.8005 - val_loss: 0.5236 - val_accuracy: 0.8076\n",
      "Epoch 271/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5268 - accuracy: 0.8005 - val_loss: 0.5218 - val_accuracy: 0.8061\n",
      "Epoch 272/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5233 - accuracy: 0.7990 - val_loss: 0.5175 - val_accuracy: 0.8063\n",
      "Epoch 273/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5208 - accuracy: 0.8009 - val_loss: 0.5291 - val_accuracy: 0.8059\n",
      "Epoch 274/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5183 - accuracy: 0.8029 - val_loss: 0.5247 - val_accuracy: 0.8028\n",
      "Epoch 275/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5237 - accuracy: 0.7996 - val_loss: 0.5183 - val_accuracy: 0.8053\n",
      "Epoch 276/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5216 - accuracy: 0.8014 - val_loss: 0.5174 - val_accuracy: 0.8098\n",
      "Epoch 277/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5217 - accuracy: 0.8000 - val_loss: 0.5200 - val_accuracy: 0.8038\n",
      "Epoch 278/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5239 - accuracy: 0.7994 - val_loss: 0.5195 - val_accuracy: 0.8066\n",
      "Epoch 279/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5277 - accuracy: 0.7970 - val_loss: 0.5175 - val_accuracy: 0.8067\n",
      "Epoch 280/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5211 - accuracy: 0.8024 - val_loss: 0.5213 - val_accuracy: 0.8042\n",
      "Epoch 281/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5196 - accuracy: 0.8013 - val_loss: 0.5209 - val_accuracy: 0.8053\n",
      "Epoch 282/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5237 - accuracy: 0.8015 - val_loss: 0.5208 - val_accuracy: 0.8027\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5200 - accuracy: 0.8016 - val_loss: 0.5210 - val_accuracy: 0.8066\n",
      "Epoch 284/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5211 - accuracy: 0.8017 - val_loss: 0.5212 - val_accuracy: 0.8057\n",
      "Epoch 285/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5206 - accuracy: 0.8019 - val_loss: 0.5173 - val_accuracy: 0.8061\n",
      "Epoch 286/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5166 - accuracy: 0.8012 - val_loss: 0.5253 - val_accuracy: 0.8035\n",
      "Epoch 287/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5218 - accuracy: 0.8013 - val_loss: 0.5168 - val_accuracy: 0.8067\n",
      "Epoch 288/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5221 - accuracy: 0.8000 - val_loss: 0.5205 - val_accuracy: 0.8065\n",
      "Epoch 289/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5262 - accuracy: 0.7987 - val_loss: 0.5244 - val_accuracy: 0.8063\n",
      "Epoch 290/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5222 - accuracy: 0.8023 - val_loss: 0.5183 - val_accuracy: 0.8094\n",
      "Epoch 291/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5236 - accuracy: 0.7994 - val_loss: 0.5198 - val_accuracy: 0.8057\n",
      "Epoch 292/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5205 - accuracy: 0.7998 - val_loss: 0.5209 - val_accuracy: 0.8077\n",
      "Epoch 293/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5222 - accuracy: 0.8008 - val_loss: 0.5181 - val_accuracy: 0.8092\n",
      "Epoch 294/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5216 - accuracy: 0.8001 - val_loss: 0.5201 - val_accuracy: 0.8083\n",
      "Epoch 295/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5222 - accuracy: 0.8020 - val_loss: 0.5262 - val_accuracy: 0.8039\n",
      "Epoch 296/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5214 - accuracy: 0.8012 - val_loss: 0.5227 - val_accuracy: 0.8050\n",
      "Epoch 297/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5230 - accuracy: 0.7998 - val_loss: 0.5195 - val_accuracy: 0.8093\n",
      "Epoch 298/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5225 - accuracy: 0.8015 - val_loss: 0.5230 - val_accuracy: 0.8050\n",
      "Epoch 299/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5207 - accuracy: 0.8001 - val_loss: 0.5166 - val_accuracy: 0.8081\n",
      "Epoch 300/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5193 - accuracy: 0.8025 - val_loss: 0.5197 - val_accuracy: 0.8078\n",
      "Epoch 301/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5195 - accuracy: 0.8019 - val_loss: 0.5254 - val_accuracy: 0.8042\n",
      "Epoch 302/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5211 - accuracy: 0.8007 - val_loss: 0.5231 - val_accuracy: 0.8059\n",
      "Epoch 303/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5197 - accuracy: 0.8012 - val_loss: 0.5175 - val_accuracy: 0.8101\n",
      "Epoch 304/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5208 - accuracy: 0.8005 - val_loss: 0.5205 - val_accuracy: 0.8104\n",
      "Epoch 305/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5231 - accuracy: 0.8024 - val_loss: 0.5161 - val_accuracy: 0.8053\n",
      "Epoch 306/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5240 - accuracy: 0.7996 - val_loss: 0.5216 - val_accuracy: 0.8059\n",
      "Epoch 307/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5204 - accuracy: 0.8024 - val_loss: 0.5204 - val_accuracy: 0.8089\n",
      "Epoch 308/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5205 - accuracy: 0.8007 - val_loss: 0.5170 - val_accuracy: 0.8059\n",
      "Epoch 309/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5220 - accuracy: 0.8001 - val_loss: 0.5200 - val_accuracy: 0.8078\n",
      "Epoch 310/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5211 - accuracy: 0.8012 - val_loss: 0.5182 - val_accuracy: 0.8061\n",
      "Epoch 311/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5198 - accuracy: 0.8002 - val_loss: 0.5167 - val_accuracy: 0.8078\n",
      "Epoch 312/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5233 - accuracy: 0.8011 - val_loss: 0.5171 - val_accuracy: 0.8075\n",
      "Epoch 313/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5214 - accuracy: 0.8029 - val_loss: 0.5173 - val_accuracy: 0.8102\n",
      "Epoch 314/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5217 - accuracy: 0.8009 - val_loss: 0.5162 - val_accuracy: 0.8085\n",
      "Epoch 315/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5230 - accuracy: 0.7990 - val_loss: 0.5172 - val_accuracy: 0.8098\n",
      "Epoch 316/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5189 - accuracy: 0.8016 - val_loss: 0.5199 - val_accuracy: 0.8055\n",
      "Epoch 317/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5196 - accuracy: 0.8024 - val_loss: 0.5195 - val_accuracy: 0.8070\n",
      "Epoch 318/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5208 - accuracy: 0.8000 - val_loss: 0.5150 - val_accuracy: 0.8074\n",
      "Epoch 319/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5184 - accuracy: 0.8031 - val_loss: 0.5208 - val_accuracy: 0.8065\n",
      "Epoch 320/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5218 - accuracy: 0.8013 - val_loss: 0.5209 - val_accuracy: 0.8051\n",
      "Epoch 321/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5189 - accuracy: 0.8032 - val_loss: 0.5216 - val_accuracy: 0.8063\n",
      "Epoch 322/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5211 - accuracy: 0.8016 - val_loss: 0.5200 - val_accuracy: 0.8065\n",
      "Epoch 323/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5185 - accuracy: 0.8016 - val_loss: 0.5148 - val_accuracy: 0.8096\n",
      "Epoch 324/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5181 - accuracy: 0.8024 - val_loss: 0.5126 - val_accuracy: 0.8092\n",
      "Epoch 325/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5209 - accuracy: 0.8022 - val_loss: 0.5135 - val_accuracy: 0.8092\n",
      "Epoch 326/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5209 - accuracy: 0.8010 - val_loss: 0.5211 - val_accuracy: 0.8068\n",
      "Epoch 327/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5200 - accuracy: 0.8002 - val_loss: 0.5157 - val_accuracy: 0.8068\n",
      "Epoch 328/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5207 - accuracy: 0.7999 - val_loss: 0.5188 - val_accuracy: 0.8081\n",
      "Epoch 329/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5242 - accuracy: 0.7986 - val_loss: 0.5193 - val_accuracy: 0.8051\n",
      "Epoch 330/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5208 - accuracy: 0.8012 - val_loss: 0.5214 - val_accuracy: 0.8062\n",
      "Epoch 331/500\n",
      "407/407 [==============================] - 3s 9ms/step - loss: 0.5202 - accuracy: 0.8017 - val_loss: 0.5159 - val_accuracy: 0.8091\n",
      "Epoch 332/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5192 - accuracy: 0.8018 - val_loss: 0.5185 - val_accuracy: 0.8115\n",
      "Epoch 333/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5213 - accuracy: 0.8009 - val_loss: 0.5181 - val_accuracy: 0.8081\n",
      "Epoch 334/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5197 - accuracy: 0.8010 - val_loss: 0.5117 - val_accuracy: 0.8084\n",
      "Epoch 335/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5193 - accuracy: 0.8002 - val_loss: 0.5140 - val_accuracy: 0.8082\n",
      "Epoch 336/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5229 - accuracy: 0.8018 - val_loss: 0.5166 - val_accuracy: 0.8084\n",
      "Epoch 337/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5215 - accuracy: 0.8002 - val_loss: 0.5193 - val_accuracy: 0.8030\n",
      "Epoch 338/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5210 - accuracy: 0.8009 - val_loss: 0.5169 - val_accuracy: 0.8100\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5193 - accuracy: 0.7995 - val_loss: 0.5169 - val_accuracy: 0.8034\n",
      "Epoch 340/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5214 - accuracy: 0.8019 - val_loss: 0.5177 - val_accuracy: 0.8069\n",
      "Epoch 341/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5175 - accuracy: 0.8037 - val_loss: 0.5204 - val_accuracy: 0.8050\n",
      "Epoch 342/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5191 - accuracy: 0.8016 - val_loss: 0.5215 - val_accuracy: 0.8081\n",
      "Epoch 343/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5187 - accuracy: 0.8020 - val_loss: 0.5181 - val_accuracy: 0.8098\n",
      "Epoch 344/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5199 - accuracy: 0.8028 - val_loss: 0.5189 - val_accuracy: 0.8065\n",
      "Epoch 345/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5199 - accuracy: 0.8027 - val_loss: 0.5278 - val_accuracy: 0.8039\n",
      "Epoch 346/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5203 - accuracy: 0.8012 - val_loss: 0.5163 - val_accuracy: 0.8097\n",
      "Epoch 347/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5219 - accuracy: 0.8026 - val_loss: 0.5200 - val_accuracy: 0.8048\n",
      "Epoch 348/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5184 - accuracy: 0.8016 - val_loss: 0.5216 - val_accuracy: 0.8054\n",
      "Epoch 349/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5177 - accuracy: 0.8025 - val_loss: 0.5179 - val_accuracy: 0.8048\n",
      "Epoch 350/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5200 - accuracy: 0.8016 - val_loss: 0.5208 - val_accuracy: 0.8085\n",
      "Epoch 351/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5191 - accuracy: 0.8026 - val_loss: 0.5275 - val_accuracy: 0.8040\n",
      "Epoch 352/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5179 - accuracy: 0.8019 - val_loss: 0.5169 - val_accuracy: 0.8073\n",
      "Epoch 353/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5194 - accuracy: 0.8010 - val_loss: 0.5211 - val_accuracy: 0.8051\n",
      "Epoch 354/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5198 - accuracy: 0.8024 - val_loss: 0.5181 - val_accuracy: 0.8071\n",
      "Epoch 355/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5201 - accuracy: 0.8023 - val_loss: 0.5180 - val_accuracy: 0.8076\n",
      "Epoch 356/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5196 - accuracy: 0.8015 - val_loss: 0.5126 - val_accuracy: 0.8085\n",
      "Epoch 357/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5207 - accuracy: 0.8010 - val_loss: 0.5164 - val_accuracy: 0.8070\n",
      "Epoch 358/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5189 - accuracy: 0.8038 - val_loss: 0.5139 - val_accuracy: 0.8088\n",
      "Epoch 359/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5186 - accuracy: 0.8004 - val_loss: 0.5189 - val_accuracy: 0.8074\n",
      "Epoch 360/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5191 - accuracy: 0.8014 - val_loss: 0.5150 - val_accuracy: 0.8083\n",
      "Epoch 361/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5183 - accuracy: 0.8020 - val_loss: 0.5198 - val_accuracy: 0.8067\n",
      "Epoch 362/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5179 - accuracy: 0.8017 - val_loss: 0.5136 - val_accuracy: 0.8082\n",
      "Epoch 363/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5186 - accuracy: 0.8020 - val_loss: 0.5189 - val_accuracy: 0.8099\n",
      "Epoch 364/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5188 - accuracy: 0.8014 - val_loss: 0.5178 - val_accuracy: 0.8025\n",
      "Epoch 365/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5191 - accuracy: 0.8013 - val_loss: 0.5189 - val_accuracy: 0.8085\n",
      "Epoch 366/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5155 - accuracy: 0.8043 - val_loss: 0.5229 - val_accuracy: 0.8075\n",
      "Epoch 367/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5208 - accuracy: 0.8021 - val_loss: 0.5214 - val_accuracy: 0.8065\n",
      "Epoch 368/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5182 - accuracy: 0.8014 - val_loss: 0.5222 - val_accuracy: 0.8076\n",
      "Epoch 369/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5203 - accuracy: 0.8002 - val_loss: 0.5182 - val_accuracy: 0.8045\n",
      "Epoch 370/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.8028 - val_loss: 0.5198 - val_accuracy: 0.8094\n",
      "Epoch 371/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5189 - accuracy: 0.8028 - val_loss: 0.5185 - val_accuracy: 0.8069\n",
      "Epoch 372/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5178 - accuracy: 0.8021 - val_loss: 0.5189 - val_accuracy: 0.8068\n",
      "Epoch 373/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5189 - accuracy: 0.8024 - val_loss: 0.5158 - val_accuracy: 0.8088\n",
      "Epoch 374/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5192 - accuracy: 0.8035 - val_loss: 0.5172 - val_accuracy: 0.8077\n",
      "Epoch 375/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5208 - accuracy: 0.8000 - val_loss: 0.5193 - val_accuracy: 0.8088\n",
      "Epoch 376/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5173 - accuracy: 0.8016 - val_loss: 0.5183 - val_accuracy: 0.8074\n",
      "Epoch 377/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5195 - accuracy: 0.8038 - val_loss: 0.5168 - val_accuracy: 0.8089\n",
      "Epoch 378/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5177 - accuracy: 0.8029 - val_loss: 0.5171 - val_accuracy: 0.8068\n",
      "Epoch 379/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5194 - accuracy: 0.8027 - val_loss: 0.5182 - val_accuracy: 0.8100\n",
      "Epoch 380/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5213 - accuracy: 0.8024 - val_loss: 0.5121 - val_accuracy: 0.8123\n",
      "Epoch 381/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5169 - accuracy: 0.8044 - val_loss: 0.5144 - val_accuracy: 0.8061\n",
      "Epoch 382/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5183 - accuracy: 0.8028 - val_loss: 0.5171 - val_accuracy: 0.8110\n",
      "Epoch 383/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.8039 - val_loss: 0.5177 - val_accuracy: 0.8084\n",
      "Epoch 384/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5190 - accuracy: 0.8023 - val_loss: 0.5177 - val_accuracy: 0.8073\n",
      "Epoch 385/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5199 - accuracy: 0.8009 - val_loss: 0.5185 - val_accuracy: 0.8097\n",
      "Epoch 386/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5159 - accuracy: 0.8029 - val_loss: 0.5158 - val_accuracy: 0.8074\n",
      "Epoch 387/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5182 - accuracy: 0.8028 - val_loss: 0.5173 - val_accuracy: 0.8075\n",
      "Epoch 388/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.8021 - val_loss: 0.5226 - val_accuracy: 0.8079\n",
      "Epoch 389/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5179 - accuracy: 0.8034 - val_loss: 0.5193 - val_accuracy: 0.8088\n",
      "Epoch 390/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5181 - accuracy: 0.8042 - val_loss: 0.5170 - val_accuracy: 0.8069\n",
      "Epoch 391/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5208 - accuracy: 0.8013 - val_loss: 0.5146 - val_accuracy: 0.8086\n",
      "Epoch 392/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5200 - accuracy: 0.8005 - val_loss: 0.5185 - val_accuracy: 0.8076\n",
      "Epoch 393/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5190 - accuracy: 0.8001 - val_loss: 0.5213 - val_accuracy: 0.8065\n",
      "Epoch 394/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5205 - accuracy: 0.8001 - val_loss: 0.5166 - val_accuracy: 0.8102\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5183 - accuracy: 0.8030 - val_loss: 0.5199 - val_accuracy: 0.8058\n",
      "Epoch 396/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5160 - accuracy: 0.8030 - val_loss: 0.5167 - val_accuracy: 0.8097\n",
      "Epoch 397/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5155 - accuracy: 0.8029 - val_loss: 0.5131 - val_accuracy: 0.8088\n",
      "Epoch 398/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5159 - accuracy: 0.8033 - val_loss: 0.5207 - val_accuracy: 0.8085\n",
      "Epoch 399/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5154 - accuracy: 0.8023 - val_loss: 0.5244 - val_accuracy: 0.8051\n",
      "Epoch 400/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5182 - accuracy: 0.8013 - val_loss: 0.5165 - val_accuracy: 0.8078\n",
      "Epoch 401/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5184 - accuracy: 0.8039 - val_loss: 0.5173 - val_accuracy: 0.8098\n",
      "Epoch 402/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5194 - accuracy: 0.8018 - val_loss: 0.5229 - val_accuracy: 0.8071\n",
      "Epoch 403/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5206 - accuracy: 0.8024 - val_loss: 0.5167 - val_accuracy: 0.8077\n",
      "Epoch 404/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5179 - accuracy: 0.8019 - val_loss: 0.5232 - val_accuracy: 0.8069\n",
      "Epoch 405/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5145 - accuracy: 0.8053 - val_loss: 0.5227 - val_accuracy: 0.8069\n",
      "Epoch 406/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5182 - accuracy: 0.8022 - val_loss: 0.5178 - val_accuracy: 0.8044\n",
      "Epoch 407/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5173 - accuracy: 0.8031 - val_loss: 0.5191 - val_accuracy: 0.8082\n",
      "Epoch 408/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5212 - accuracy: 0.8013 - val_loss: 0.5205 - val_accuracy: 0.8052\n",
      "Epoch 409/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5173 - accuracy: 0.8031 - val_loss: 0.5187 - val_accuracy: 0.8070\n",
      "Epoch 410/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5157 - accuracy: 0.8042 - val_loss: 0.5164 - val_accuracy: 0.8067\n",
      "Epoch 411/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5162 - accuracy: 0.8030 - val_loss: 0.5191 - val_accuracy: 0.8074\n",
      "Epoch 412/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.8024 - val_loss: 0.5154 - val_accuracy: 0.8094\n",
      "Epoch 413/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5150 - accuracy: 0.8053 - val_loss: 0.5213 - val_accuracy: 0.8060\n",
      "Epoch 414/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5189 - accuracy: 0.8029 - val_loss: 0.5163 - val_accuracy: 0.8091\n",
      "Epoch 415/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5164 - accuracy: 0.8034 - val_loss: 0.5196 - val_accuracy: 0.8108\n",
      "Epoch 416/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5190 - accuracy: 0.8036 - val_loss: 0.5152 - val_accuracy: 0.8077\n",
      "Epoch 417/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5178 - accuracy: 0.8032 - val_loss: 0.5193 - val_accuracy: 0.8063\n",
      "Epoch 418/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5187 - accuracy: 0.8010 - val_loss: 0.5148 - val_accuracy: 0.8091\n",
      "Epoch 419/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5200 - accuracy: 0.8036 - val_loss: 0.5174 - val_accuracy: 0.8063\n",
      "Epoch 420/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5175 - accuracy: 0.8032 - val_loss: 0.5138 - val_accuracy: 0.8085\n",
      "Epoch 421/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5155 - accuracy: 0.8020 - val_loss: 0.5203 - val_accuracy: 0.8053\n",
      "Epoch 422/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5165 - accuracy: 0.8019 - val_loss: 0.5214 - val_accuracy: 0.8066\n",
      "Epoch 423/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5191 - accuracy: 0.8023 - val_loss: 0.5137 - val_accuracy: 0.8090\n",
      "Epoch 424/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5165 - accuracy: 0.8032 - val_loss: 0.5127 - val_accuracy: 0.8102\n",
      "Epoch 425/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5174 - accuracy: 0.8036 - val_loss: 0.5156 - val_accuracy: 0.8055\n",
      "Epoch 426/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5169 - accuracy: 0.8026 - val_loss: 0.5203 - val_accuracy: 0.8069\n",
      "Epoch 427/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5191 - accuracy: 0.8046 - val_loss: 0.5139 - val_accuracy: 0.8093\n",
      "Epoch 428/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5179 - accuracy: 0.8020 - val_loss: 0.5158 - val_accuracy: 0.8060\n",
      "Epoch 429/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.8018 - val_loss: 0.5167 - val_accuracy: 0.8082\n",
      "Epoch 430/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5191 - accuracy: 0.8019 - val_loss: 0.5133 - val_accuracy: 0.8098\n",
      "Epoch 431/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5167 - accuracy: 0.8051 - val_loss: 0.5206 - val_accuracy: 0.8099\n",
      "Epoch 432/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5148 - accuracy: 0.8034 - val_loss: 0.5177 - val_accuracy: 0.8081\n",
      "Epoch 433/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5176 - accuracy: 0.8021 - val_loss: 0.5193 - val_accuracy: 0.8104\n",
      "Epoch 434/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5177 - accuracy: 0.8033 - val_loss: 0.5168 - val_accuracy: 0.8110\n",
      "Epoch 435/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5167 - accuracy: 0.8044 - val_loss: 0.5181 - val_accuracy: 0.8089\n",
      "Epoch 436/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5171 - accuracy: 0.8048 - val_loss: 0.5198 - val_accuracy: 0.8043\n",
      "Epoch 437/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5186 - accuracy: 0.8021 - val_loss: 0.5171 - val_accuracy: 0.8092\n",
      "Epoch 438/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5168 - accuracy: 0.8029 - val_loss: 0.5174 - val_accuracy: 0.8090\n",
      "Epoch 439/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5160 - accuracy: 0.8034 - val_loss: 0.5254 - val_accuracy: 0.8079\n",
      "Epoch 440/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5161 - accuracy: 0.8060 - val_loss: 0.5190 - val_accuracy: 0.8089\n",
      "Epoch 441/500\n",
      "407/407 [==============================] - 1s 4ms/step - loss: 0.5165 - accuracy: 0.8023 - val_loss: 0.5180 - val_accuracy: 0.8054\n",
      "Epoch 442/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5193 - accuracy: 0.8027 - val_loss: 0.5187 - val_accuracy: 0.8082\n",
      "Epoch 443/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.8042 - val_loss: 0.5175 - val_accuracy: 0.8068\n",
      "Epoch 444/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5148 - accuracy: 0.8028 - val_loss: 0.5171 - val_accuracy: 0.8105\n",
      "Epoch 445/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5156 - accuracy: 0.8045 - val_loss: 0.5177 - val_accuracy: 0.8088\n",
      "Epoch 446/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5177 - accuracy: 0.8036 - val_loss: 0.5171 - val_accuracy: 0.8094\n",
      "Epoch 447/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5135 - accuracy: 0.8027 - val_loss: 0.5185 - val_accuracy: 0.8065\n",
      "Epoch 448/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5162 - accuracy: 0.8030 - val_loss: 0.5173 - val_accuracy: 0.8086\n",
      "Epoch 449/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5181 - accuracy: 0.8023 - val_loss: 0.5217 - val_accuracy: 0.8086\n",
      "Epoch 450/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5170 - accuracy: 0.8033 - val_loss: 0.5220 - val_accuracy: 0.8074\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5172 - accuracy: 0.8029 - val_loss: 0.5187 - val_accuracy: 0.8051\n",
      "Epoch 452/500\n",
      "407/407 [==============================] - 1s 4ms/step - loss: 0.5166 - accuracy: 0.8040 - val_loss: 0.5156 - val_accuracy: 0.8097\n",
      "Epoch 453/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5165 - accuracy: 0.8022 - val_loss: 0.5157 - val_accuracy: 0.8074\n",
      "Epoch 454/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5169 - accuracy: 0.8038 - val_loss: 0.5195 - val_accuracy: 0.8078\n",
      "Epoch 455/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5181 - accuracy: 0.8025 - val_loss: 0.5142 - val_accuracy: 0.8112\n",
      "Epoch 456/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5163 - accuracy: 0.8041 - val_loss: 0.5195 - val_accuracy: 0.8061\n",
      "Epoch 457/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5202 - accuracy: 0.8032 - val_loss: 0.5184 - val_accuracy: 0.8079\n",
      "Epoch 458/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5150 - accuracy: 0.8028 - val_loss: 0.5172 - val_accuracy: 0.8086\n",
      "Epoch 459/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5136 - accuracy: 0.8044 - val_loss: 0.5198 - val_accuracy: 0.8055\n",
      "Epoch 460/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5170 - accuracy: 0.8023 - val_loss: 0.5225 - val_accuracy: 0.8067\n",
      "Epoch 461/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5174 - accuracy: 0.8010 - val_loss: 0.5164 - val_accuracy: 0.8084\n",
      "Epoch 462/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5183 - accuracy: 0.8023 - val_loss: 0.5185 - val_accuracy: 0.8075\n",
      "Epoch 463/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5168 - accuracy: 0.8025 - val_loss: 0.5229 - val_accuracy: 0.8069\n",
      "Epoch 464/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5158 - accuracy: 0.8043 - val_loss: 0.5186 - val_accuracy: 0.8082\n",
      "Epoch 465/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5155 - accuracy: 0.8032 - val_loss: 0.5203 - val_accuracy: 0.8105\n",
      "Epoch 466/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5168 - accuracy: 0.8033 - val_loss: 0.5208 - val_accuracy: 0.8086\n",
      "Epoch 467/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5152 - accuracy: 0.8024 - val_loss: 0.5166 - val_accuracy: 0.8081\n",
      "Epoch 468/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5162 - accuracy: 0.8023 - val_loss: 0.5219 - val_accuracy: 0.8100\n",
      "Epoch 469/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5157 - accuracy: 0.8015 - val_loss: 0.5199 - val_accuracy: 0.8073\n",
      "Epoch 470/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5196 - accuracy: 0.8018 - val_loss: 0.5205 - val_accuracy: 0.8048\n",
      "Epoch 471/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5205 - accuracy: 0.8000 - val_loss: 0.5143 - val_accuracy: 0.8082\n",
      "Epoch 472/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5181 - accuracy: 0.8025 - val_loss: 0.5165 - val_accuracy: 0.8078\n",
      "Epoch 473/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5154 - accuracy: 0.8026 - val_loss: 0.5184 - val_accuracy: 0.8071\n",
      "Epoch 474/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.8032 - val_loss: 0.5175 - val_accuracy: 0.8075\n",
      "Epoch 475/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5135 - accuracy: 0.8028 - val_loss: 0.5188 - val_accuracy: 0.8055\n",
      "Epoch 476/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5162 - accuracy: 0.8048 - val_loss: 0.5219 - val_accuracy: 0.8063\n",
      "Epoch 477/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5168 - accuracy: 0.8027 - val_loss: 0.5197 - val_accuracy: 0.8078\n",
      "Epoch 478/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5175 - accuracy: 0.8034 - val_loss: 0.5166 - val_accuracy: 0.8094\n",
      "Epoch 479/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5145 - accuracy: 0.8045 - val_loss: 0.5192 - val_accuracy: 0.8076\n",
      "Epoch 480/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5138 - accuracy: 0.8026 - val_loss: 0.5190 - val_accuracy: 0.8047\n",
      "Epoch 481/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5165 - accuracy: 0.8025 - val_loss: 0.5189 - val_accuracy: 0.8077\n",
      "Epoch 482/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5178 - accuracy: 0.8019 - val_loss: 0.5177 - val_accuracy: 0.8094\n",
      "Epoch 483/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5164 - accuracy: 0.8030 - val_loss: 0.5204 - val_accuracy: 0.8074\n",
      "Epoch 484/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5134 - accuracy: 0.8029 - val_loss: 0.5233 - val_accuracy: 0.8076\n",
      "Epoch 485/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5164 - accuracy: 0.8022 - val_loss: 0.5189 - val_accuracy: 0.8083\n",
      "Epoch 486/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5160 - accuracy: 0.8029 - val_loss: 0.5156 - val_accuracy: 0.8073\n",
      "Epoch 487/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5157 - accuracy: 0.8050 - val_loss: 0.5197 - val_accuracy: 0.8060\n",
      "Epoch 488/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5151 - accuracy: 0.8035 - val_loss: 0.5140 - val_accuracy: 0.8075\n",
      "Epoch 489/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5183 - accuracy: 0.8026 - val_loss: 0.5200 - val_accuracy: 0.8070\n",
      "Epoch 490/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5151 - accuracy: 0.8045 - val_loss: 0.5222 - val_accuracy: 0.8050\n",
      "Epoch 491/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5179 - accuracy: 0.8034 - val_loss: 0.5190 - val_accuracy: 0.8078\n",
      "Epoch 492/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5152 - accuracy: 0.8034 - val_loss: 0.5212 - val_accuracy: 0.8084\n",
      "Epoch 493/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5150 - accuracy: 0.8023 - val_loss: 0.5172 - val_accuracy: 0.8107\n",
      "Epoch 494/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5160 - accuracy: 0.8053 - val_loss: 0.5149 - val_accuracy: 0.8089\n",
      "Epoch 495/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5174 - accuracy: 0.8020 - val_loss: 0.5154 - val_accuracy: 0.8084\n",
      "Epoch 496/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5144 - accuracy: 0.8044 - val_loss: 0.5146 - val_accuracy: 0.8116\n",
      "Epoch 497/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5172 - accuracy: 0.8036 - val_loss: 0.5128 - val_accuracy: 0.8115\n",
      "Epoch 498/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5132 - accuracy: 0.8035 - val_loss: 0.5188 - val_accuracy: 0.8091\n",
      "Epoch 499/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5151 - accuracy: 0.8047 - val_loss: 0.5156 - val_accuracy: 0.8078\n",
      "Epoch 500/500\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.5167 - accuracy: 0.8042 - val_loss: 0.5178 - val_accuracy: 0.8078\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "model = tf.keras.Sequential()\n",
    "# kernel_regularizer=regularizers.l2(0.0005)\n",
    "model.add(Dense(128, input_dim=8, activation='relu', kernel_regularizer=regularizers.l2(0.00007)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.00007)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.00007)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.00007)))\n",
    "model.add(Dropout(0.1))\n",
    "# model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.00002)))\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# learning_rate = 0.1\n",
    "# global_step = tf.Variable(0, trainable=False)\n",
    "# decayed_lr = tf.train.exponential_decay(learning_rate, global_step, 2, 0.99, staircase=True)\n",
    "optim = tf.keras.optimizers.Adam(0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "history = model.fit(x_train, encoded_train_y, epochs=500, batch_size=100, validation_data = (x_val, encoded_val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b2ac097",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f1e33020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 51,075\n",
      "Trainable params: 51,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "273/273 [==============================] - 0s 855us/step - loss: 0.5178 - accuracy: 0.8078\n",
      "Accuracy: 80.78%\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "_, accuracy = model.evaluate(x_val, encoded_val_y)\n",
    "print('Accuracy: %.2f' % (accuracy*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-length",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1956732b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[ -0.11154779  -0.45409909   1.31122243 -61.84156159  -0.33043453\n",
      "   -1.88890682  64.11250977   0.10850876]]\n",
      "Mean squared error Validation: 55.05\n",
      "Coefficient of determination (R2) Validation: 0.0549\n",
      "Mean squared error Train: 49.99\n",
      "Coefficient of determination (R2) Train: 0.0506\n",
      "====Polynomial\n",
      "Mean squared error Validation: 46.12\n",
      "Coefficient of determination (R2) Validation: 0.2083\n",
      "Mean squared error Train: 39.90\n",
      "Coefficient of determination (R2) Train: 0.2423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train_reg, y_train_reg)\n",
    "\n",
    "print('Coefficients: \\n', lin_reg.coef_)\n",
    "\n",
    "val_y_pred = lin_reg.predict(x_val_reg)\n",
    "print('Mean squared error Validation: %.2f' % mean_squared_error(y_val_reg, val_y_pred))\n",
    "# print('Coefficient of determination Validation: %.2f' % r2_score(y_val_reg, val_y_pred))\n",
    "print('Coefficient of determination (R2) Validation: %.4f' % lin_reg.score(x_val_reg,y_val_reg))\n",
    "\n",
    "\n",
    "train_y_pred = lin_reg.predict(x_train_reg)\n",
    "print('Mean squared error Train: %.2f' % mean_squared_error(y_train_reg, train_y_pred))\n",
    "# print('Coefficient of determination Train: %.2f' % r2_score(y_train_reg, train_y_pred))\n",
    "print('Coefficient of determination (R2) Train: %.4f' % lin_reg.score(x_train_reg, y_train_reg))\n",
    "\n",
    "\n",
    "print(\"====Polynomial\")\n",
    "# Linear regression with polynomial transformation of attributes. best result is received \n",
    "# within the polynomial of degree 3, as degree 4 starts to overfit.\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "x_train_trans = poly.fit_transform(x_train_reg)\n",
    "x_val_trans = poly.fit_transform(x_val_reg)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(x_train_trans, y_train_reg)\n",
    "\n",
    "# print('Coefficients: \\n', clf.coef_)\n",
    "\n",
    "val_y_pred = clf.predict(x_val_trans)\n",
    "print('Mean squared error Validation: %.2f' % mean_squared_error(y_val_reg, val_y_pred))\n",
    "# print('Coefficient of determination Validation: %.2f' % r2_score(y_val_reg, val_y_pred))\n",
    "print('Coefficient of determination (R2) Validation: %.4f' % clf.score(x_val_trans,y_val_reg))\n",
    "\n",
    "\n",
    "train_y_pred = clf.predict(x_train_trans)\n",
    "print('Mean squared error Train: %.2f' % mean_squared_error(y_train_reg, train_y_pred))\n",
    "# print('Coefficient of determination Train: %.2f' % r2_score(y_train_reg, train_y_pred))\n",
    "print('Coefficient of determination (R2) Train: %.4f' % clf.score(x_train_trans, y_train_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b335f4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[-0.11221821 -0.46415644  1.33016167 -2.39170504 -0.32978879  1.0147617\n",
      "   4.1897377   0.10983794]]\n",
      "Mean squared error Validation: 55.05\n",
      "Coefficient of determination (R2) Validation: 0.0549\n",
      "Mean squared error Train: 50.00\n",
      "Coefficient of determination (R2) Train: 0.0504\n",
      "===========Polynomial Ridge\n",
      "Mean squared error Validation: 47.23\n",
      "Coefficient of determination (R2) Validation: 0.1892\n",
      "Mean squared error Train: 40.54\n",
      "Coefficient of determination (R2) Train: 0.2302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "ridg_reg = Ridge()\n",
    "ridg_reg.fit(x_train_reg, y_train_reg)\n",
    "\n",
    "print('Coefficients: \\n', ridg_reg.coef_)\n",
    "\n",
    "val_y_pred = ridg_reg.predict(x_val_reg)\n",
    "print('Mean squared error Validation: %.2f' % mean_squared_error(y_val_reg, val_y_pred))\n",
    "# print('Coefficient of determination Validation: %.2f' % r2_score(y_val_reg, val_y_pred))\n",
    "print('Coefficient of determination (R2) Validation: %.4f' % ridg_reg.score(x_val_reg,y_val_reg))\n",
    "\n",
    "train_y_pred = ridg_reg.predict(x_train_reg)\n",
    "print('Mean squared error Train: %.2f' % mean_squared_error(y_train_reg, train_y_pred))\n",
    "# print('Coefficient of determination Train: %.2f' % r2_score(y_train_reg, train_y_pred))\n",
    "print('Coefficient of determination (R2) Train: %.4f' % ridg_reg.score(x_train_reg, y_train_reg))\n",
    "\n",
    "print(\"===========Polynomial Ridge\")\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "x_train_trans = poly.fit_transform(x_train_reg)\n",
    "x_val_trans = poly.fit_transform(x_val_reg)\n",
    "clf = Ridge()\n",
    "clf.fit(x_train_trans, y_train_reg)\n",
    "\n",
    "# print('Coefficients: \\n', clf.coef_)\n",
    "\n",
    "val_y_pred = clf.predict(x_val_trans)\n",
    "print('Mean squared error Validation: %.2f' % mean_squared_error(y_val_reg, val_y_pred))\n",
    "# print('Coefficient of determination Validation: %.2f' % r2_score(y_val_reg, val_y_pred))\n",
    "print('Coefficient of determination (R2) Validation: %.4f' % clf.score(x_val_trans,y_val_reg))\n",
    "\n",
    "\n",
    "train_y_pred = clf.predict(x_train_trans)\n",
    "print('Mean squared error Train: %.2f' % mean_squared_error(y_train_reg, train_y_pred))\n",
    "# print('Coefficient of determination Train: %.2f' % r2_score(y_train_reg, train_y_pred))\n",
    "print('Coefficient of determination (R2) Train: %.4f' % clf.score(x_train_trans, y_train_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f33e272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [-0.       -0.        0.        0.250944 -0.        0.        0.\n",
      "  0.      ]\n",
      "Mean squared error Validation: 57.66\n",
      "Coefficient of determination (R2) Validation: 0.0101\n",
      "Mean squared error Train: 52.09\n",
      "Coefficient of determination (R2) Train: 0.0107\n"
     ]
    }
   ],
   "source": [
    "lasso_reg = Lasso()\n",
    "lasso_reg.fit(x_train_reg, y_train_reg)\n",
    "\n",
    "print('Coefficients: \\n', lasso_reg.coef_)\n",
    "\n",
    "val_y_pred = lasso_reg.predict(x_val_reg)\n",
    "print('Mean squared error Validation: %.2f' % mean_squared_error(y_val_reg, val_y_pred))\n",
    "# print('Coefficient of determination Validation: %.2f' % r2_score(y_val_reg, val_y_pred))\n",
    "print('Coefficient of determination (R2) Validation: %.4f' % lasso_reg.score(x_val_reg,y_val_reg))\n",
    "\n",
    "train_y_pred = lasso_reg.predict(x_train_reg)\n",
    "print('Mean squared error Train: %.2f' % mean_squared_error(y_train_reg, train_y_pred))\n",
    "# print('Coefficient of determination Train: %.2f' % r2_score(y_train_reg, train_y_pred))\n",
    "print('Coefficient of determination (R2) Train: %.4f' % lasso_reg.score(x_train_reg, y_train_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8cc87dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40626, 8)\n",
      "Epoch 1/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 881.4963 - mean_squared_error: 881.4741 - val_loss: 84.7417 - val_mean_squared_error: 84.7194\n",
      "Epoch 2/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 112.7473 - mean_squared_error: 112.7251 - val_loss: 52.1959 - val_mean_squared_error: 52.1737\n",
      "Epoch 3/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 92.1609 - mean_squared_error: 92.1387 - val_loss: 45.7713 - val_mean_squared_error: 45.7489\n",
      "Epoch 4/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 83.1078 - mean_squared_error: 83.0854 - val_loss: 44.7298 - val_mean_squared_error: 44.7072\n",
      "Epoch 5/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 77.0774 - mean_squared_error: 77.0547 - val_loss: 39.9540 - val_mean_squared_error: 39.9313\n",
      "Epoch 6/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 72.7170 - mean_squared_error: 72.6941 - val_loss: 47.6161 - val_mean_squared_error: 47.5931\n",
      "Epoch 7/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 69.5615 - mean_squared_error: 69.5383 - val_loss: 35.4240 - val_mean_squared_error: 35.4006\n",
      "Epoch 8/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 66.5038 - mean_squared_error: 66.4803 - val_loss: 34.6786 - val_mean_squared_error: 34.6548\n",
      "Epoch 9/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 62.3493 - mean_squared_error: 62.3253 - val_loss: 29.8299 - val_mean_squared_error: 29.8057\n",
      "Epoch 10/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 59.8509 - mean_squared_error: 59.8266 - val_loss: 30.8697 - val_mean_squared_error: 30.8451\n",
      "Epoch 11/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 59.5550 - mean_squared_error: 59.5303 - val_loss: 27.4833 - val_mean_squared_error: 27.4584\n",
      "Epoch 12/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 57.1285 - mean_squared_error: 57.1036 - val_loss: 28.4284 - val_mean_squared_error: 28.4035\n",
      "Epoch 13/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 55.2898 - mean_squared_error: 55.2649 - val_loss: 26.3120 - val_mean_squared_error: 26.2869\n",
      "Epoch 14/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 55.0352 - mean_squared_error: 55.0101 - val_loss: 27.3265 - val_mean_squared_error: 27.3014\n",
      "Epoch 15/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 55.0981 - mean_squared_error: 55.0729 - val_loss: 28.5760 - val_mean_squared_error: 28.5507\n",
      "Epoch 16/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 52.8419 - mean_squared_error: 52.8166 - val_loss: 25.5204 - val_mean_squared_error: 25.4950\n",
      "Epoch 17/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 52.2112 - mean_squared_error: 52.1859 - val_loss: 26.5646 - val_mean_squared_error: 26.5392\n",
      "Epoch 18/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 50.9427 - mean_squared_error: 50.9172 - val_loss: 26.6611 - val_mean_squared_error: 26.6356\n",
      "Epoch 19/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 50.7878 - mean_squared_error: 50.7623 - val_loss: 25.2737 - val_mean_squared_error: 25.2481\n",
      "Epoch 20/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 49.8762 - mean_squared_error: 49.8506 - val_loss: 24.0773 - val_mean_squared_error: 24.0517\n",
      "Epoch 21/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 48.3101 - mean_squared_error: 48.2844 - val_loss: 25.4884 - val_mean_squared_error: 25.4626\n",
      "Epoch 22/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 47.9550 - mean_squared_error: 47.9291 - val_loss: 22.9871 - val_mean_squared_error: 22.9611\n",
      "Epoch 23/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 45.5626 - mean_squared_error: 45.5363 - val_loss: 20.8327 - val_mean_squared_error: 20.8060\n",
      "Epoch 24/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 44.0076 - mean_squared_error: 43.9805 - val_loss: 22.8502 - val_mean_squared_error: 22.8228\n",
      "Epoch 25/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 42.2465 - mean_squared_error: 42.2186 - val_loss: 22.6975 - val_mean_squared_error: 22.6692\n",
      "Epoch 26/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 40.9431 - mean_squared_error: 40.9143 - val_loss: 18.4450 - val_mean_squared_error: 18.4155\n",
      "Epoch 27/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 39.3204 - mean_squared_error: 39.2904 - val_loss: 21.2417 - val_mean_squared_error: 21.2113\n",
      "Epoch 28/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 39.0665 - mean_squared_error: 39.0356 - val_loss: 18.6237 - val_mean_squared_error: 18.5922\n",
      "Epoch 29/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 38.5485 - mean_squared_error: 38.5165 - val_loss: 16.4111 - val_mean_squared_error: 16.3787\n",
      "Epoch 30/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 37.4502 - mean_squared_error: 37.4175 - val_loss: 16.1684 - val_mean_squared_error: 16.1355\n",
      "Epoch 31/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 37.0709 - mean_squared_error: 37.0375 - val_loss: 16.5201 - val_mean_squared_error: 16.4863\n",
      "Epoch 32/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 36.6979 - mean_squared_error: 36.6638 - val_loss: 16.7212 - val_mean_squared_error: 16.6867\n",
      "Epoch 33/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 36.9592 - mean_squared_error: 36.9244 - val_loss: 17.3705 - val_mean_squared_error: 17.3349\n",
      "Epoch 34/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 36.1863 - mean_squared_error: 36.1503 - val_loss: 16.0109 - val_mean_squared_error: 15.9744\n",
      "Epoch 35/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 35.4888 - mean_squared_error: 35.4520 - val_loss: 15.5971 - val_mean_squared_error: 15.5598\n",
      "Epoch 36/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 34.8624 - mean_squared_error: 34.8247 - val_loss: 15.0721 - val_mean_squared_error: 15.0338\n",
      "Epoch 37/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 34.4310 - mean_squared_error: 34.3925 - val_loss: 17.5022 - val_mean_squared_error: 17.4634\n",
      "Epoch 38/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 34.5970 - mean_squared_error: 34.5578 - val_loss: 17.3393 - val_mean_squared_error: 17.2997\n",
      "Epoch 39/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 33.1444 - mean_squared_error: 33.1044 - val_loss: 15.4153 - val_mean_squared_error: 15.3749\n",
      "Epoch 40/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 32.7882 - mean_squared_error: 32.7474 - val_loss: 14.9892 - val_mean_squared_error: 14.9481\n",
      "Epoch 41/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 33.0247 - mean_squared_error: 32.9832 - val_loss: 13.7046 - val_mean_squared_error: 13.6628\n",
      "Epoch 42/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 32.3584 - mean_squared_error: 32.3162 - val_loss: 14.4401 - val_mean_squared_error: 14.3975\n",
      "Epoch 43/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 32.4561 - mean_squared_error: 32.4132 - val_loss: 15.1487 - val_mean_squared_error: 15.1054\n",
      "Epoch 44/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 31.9582 - mean_squared_error: 31.9145 - val_loss: 14.0731 - val_mean_squared_error: 14.0291\n",
      "Epoch 45/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 31.7228 - mean_squared_error: 31.6784 - val_loss: 14.5736 - val_mean_squared_error: 14.5289\n",
      "Epoch 46/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 30.5976 - mean_squared_error: 30.5527 - val_loss: 13.5257 - val_mean_squared_error: 13.4804\n",
      "Epoch 47/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 30.2833 - mean_squared_error: 30.2379 - val_loss: 13.3749 - val_mean_squared_error: 13.3290\n",
      "Epoch 48/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 30.4526 - mean_squared_error: 30.4063 - val_loss: 13.4289 - val_mean_squared_error: 13.3821\n",
      "Epoch 49/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 30.4195 - mean_squared_error: 30.3725 - val_loss: 15.2269 - val_mean_squared_error: 15.1798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 29.9236 - mean_squared_error: 29.8761 - val_loss: 13.2468 - val_mean_squared_error: 13.1989\n",
      "Epoch 51/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 29.2377 - mean_squared_error: 29.1895 - val_loss: 13.2370 - val_mean_squared_error: 13.1885\n",
      "Epoch 52/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 29.1438 - mean_squared_error: 29.0950 - val_loss: 12.5881 - val_mean_squared_error: 12.5389\n",
      "Epoch 53/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 28.7620 - mean_squared_error: 28.7123 - val_loss: 15.4200 - val_mean_squared_error: 15.3700\n",
      "Epoch 54/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 28.8114 - mean_squared_error: 28.7609 - val_loss: 13.5409 - val_mean_squared_error: 13.4901\n",
      "Epoch 55/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 28.3780 - mean_squared_error: 28.3268 - val_loss: 13.1364 - val_mean_squared_error: 13.0848\n",
      "Epoch 56/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 27.7729 - mean_squared_error: 27.7209 - val_loss: 13.2459 - val_mean_squared_error: 13.1936\n",
      "Epoch 57/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 28.0332 - mean_squared_error: 27.9804 - val_loss: 13.4894 - val_mean_squared_error: 13.4361\n",
      "Epoch 58/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 27.5887 - mean_squared_error: 27.5350 - val_loss: 12.9028 - val_mean_squared_error: 12.8488\n",
      "Epoch 59/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 27.4894 - mean_squared_error: 27.4352 - val_loss: 14.5550 - val_mean_squared_error: 14.5004\n",
      "Epoch 60/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 27.7090 - mean_squared_error: 27.6539 - val_loss: 12.8994 - val_mean_squared_error: 12.8438\n",
      "Epoch 61/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 27.0967 - mean_squared_error: 27.0408 - val_loss: 12.9593 - val_mean_squared_error: 12.9030\n",
      "Epoch 62/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 27.3199 - mean_squared_error: 27.2631 - val_loss: 12.2890 - val_mean_squared_error: 12.2316\n",
      "Epoch 63/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 26.8723 - mean_squared_error: 26.8145 - val_loss: 12.1496 - val_mean_squared_error: 12.0915\n",
      "Epoch 64/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 26.5004 - mean_squared_error: 26.4418 - val_loss: 11.7317 - val_mean_squared_error: 11.6727\n",
      "Epoch 65/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 26.8486 - mean_squared_error: 26.7892 - val_loss: 12.3007 - val_mean_squared_error: 12.2407\n",
      "Epoch 66/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 26.2952 - mean_squared_error: 26.2348 - val_loss: 12.8898 - val_mean_squared_error: 12.8290\n",
      "Epoch 67/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 26.3536 - mean_squared_error: 26.2922 - val_loss: 12.3634 - val_mean_squared_error: 12.3015\n",
      "Epoch 68/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 26.0565 - mean_squared_error: 25.9943 - val_loss: 12.4036 - val_mean_squared_error: 12.3408\n",
      "Epoch 69/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 25.5228 - mean_squared_error: 25.4596 - val_loss: 13.3059 - val_mean_squared_error: 13.2422\n",
      "Epoch 70/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 25.5906 - mean_squared_error: 25.5264 - val_loss: 12.1737 - val_mean_squared_error: 12.1091\n",
      "Epoch 71/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 25.6098 - mean_squared_error: 25.5445 - val_loss: 12.7039 - val_mean_squared_error: 12.6379\n",
      "Epoch 72/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 25.5622 - mean_squared_error: 25.4956 - val_loss: 14.4722 - val_mean_squared_error: 14.4051\n",
      "Epoch 73/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 25.9090 - mean_squared_error: 25.8415 - val_loss: 13.1136 - val_mean_squared_error: 13.0457\n",
      "Epoch 74/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 25.4978 - mean_squared_error: 25.4295 - val_loss: 12.7659 - val_mean_squared_error: 12.6970\n",
      "Epoch 75/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 24.9987 - mean_squared_error: 24.9294 - val_loss: 13.1491 - val_mean_squared_error: 13.0794\n",
      "Epoch 76/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 25.0570 - mean_squared_error: 24.9870 - val_loss: 12.3103 - val_mean_squared_error: 12.2399\n",
      "Epoch 77/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 25.1049 - mean_squared_error: 25.0342 - val_loss: 12.3587 - val_mean_squared_error: 12.2873\n",
      "Epoch 78/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 25.0749 - mean_squared_error: 25.0031 - val_loss: 13.5947 - val_mean_squared_error: 13.5222\n",
      "Epoch 79/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 24.8098 - mean_squared_error: 24.7370 - val_loss: 11.5324 - val_mean_squared_error: 11.4592\n",
      "Epoch 80/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 24.7232 - mean_squared_error: 24.6496 - val_loss: 12.3967 - val_mean_squared_error: 12.3226\n",
      "Epoch 81/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 24.8721 - mean_squared_error: 24.7974 - val_loss: 11.9241 - val_mean_squared_error: 11.8490\n",
      "Epoch 82/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 24.2327 - mean_squared_error: 24.1572 - val_loss: 12.5756 - val_mean_squared_error: 12.4996\n",
      "Epoch 83/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 24.6800 - mean_squared_error: 24.6036 - val_loss: 11.4015 - val_mean_squared_error: 11.3245\n",
      "Epoch 84/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 25.0673 - mean_squared_error: 24.9899 - val_loss: 12.2640 - val_mean_squared_error: 12.1862\n",
      "Epoch 85/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 24.4574 - mean_squared_error: 24.3791 - val_loss: 12.0354 - val_mean_squared_error: 11.9568\n",
      "Epoch 86/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 24.3586 - mean_squared_error: 24.2795 - val_loss: 11.3051 - val_mean_squared_error: 11.2256\n",
      "Epoch 87/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 24.0575 - mean_squared_error: 23.9776 - val_loss: 11.5405 - val_mean_squared_error: 11.4602\n",
      "Epoch 88/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.9976 - mean_squared_error: 23.9168 - val_loss: 11.4830 - val_mean_squared_error: 11.4018\n",
      "Epoch 89/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 24.4875 - mean_squared_error: 24.4059 - val_loss: 11.5209 - val_mean_squared_error: 11.4389\n",
      "Epoch 90/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 24.0753 - mean_squared_error: 23.9930 - val_loss: 11.2409 - val_mean_squared_error: 11.1582\n",
      "Epoch 91/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 24.0401 - mean_squared_error: 23.9569 - val_loss: 11.7484 - val_mean_squared_error: 11.6647\n",
      "Epoch 92/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 24.3949 - mean_squared_error: 24.3107 - val_loss: 11.7440 - val_mean_squared_error: 11.6593\n",
      "Epoch 93/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 24.0395 - mean_squared_error: 23.9546 - val_loss: 11.9449 - val_mean_squared_error: 11.8595\n",
      "Epoch 94/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.8339 - mean_squared_error: 23.7480 - val_loss: 11.2721 - val_mean_squared_error: 11.1859\n",
      "Epoch 95/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.8369 - mean_squared_error: 23.7503 - val_loss: 11.5291 - val_mean_squared_error: 11.4422\n",
      "Epoch 96/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.6024 - mean_squared_error: 23.5152 - val_loss: 11.2976 - val_mean_squared_error: 11.2100\n",
      "Epoch 97/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.8495 - mean_squared_error: 23.7616 - val_loss: 11.3318 - val_mean_squared_error: 11.2433\n",
      "Epoch 98/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.7494 - mean_squared_error: 23.6605 - val_loss: 11.3457 - val_mean_squared_error: 11.2565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.8393 - mean_squared_error: 23.7497 - val_loss: 11.0013 - val_mean_squared_error: 10.9112\n",
      "Epoch 100/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.6556 - mean_squared_error: 23.5650 - val_loss: 10.8357 - val_mean_squared_error: 10.7448\n",
      "Epoch 101/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.5694 - mean_squared_error: 23.4783 - val_loss: 11.0105 - val_mean_squared_error: 10.9189\n",
      "Epoch 102/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.3341 - mean_squared_error: 23.2421 - val_loss: 10.7972 - val_mean_squared_error: 10.7046\n",
      "Epoch 103/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.4866 - mean_squared_error: 23.3935 - val_loss: 12.0507 - val_mean_squared_error: 11.9571\n",
      "Epoch 104/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.0801 - mean_squared_error: 22.9859 - val_loss: 11.5445 - val_mean_squared_error: 11.4498\n",
      "Epoch 105/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.1612 - mean_squared_error: 23.0662 - val_loss: 12.9377 - val_mean_squared_error: 12.8423\n",
      "Epoch 106/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.2411 - mean_squared_error: 23.1451 - val_loss: 11.5327 - val_mean_squared_error: 11.4362\n",
      "Epoch 107/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.1170 - mean_squared_error: 23.0201 - val_loss: 10.7009 - val_mean_squared_error: 10.6035\n",
      "Epoch 108/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.0570 - mean_squared_error: 22.9594 - val_loss: 10.5157 - val_mean_squared_error: 10.4179\n",
      "Epoch 109/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.8989 - mean_squared_error: 22.8006 - val_loss: 11.4146 - val_mean_squared_error: 11.3158\n",
      "Epoch 110/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.8386 - mean_squared_error: 22.7395 - val_loss: 10.6894 - val_mean_squared_error: 10.5900\n",
      "Epoch 111/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 23.5762 - mean_squared_error: 23.4765 - val_loss: 10.2467 - val_mean_squared_error: 10.1467\n",
      "Epoch 112/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.9496 - mean_squared_error: 22.8490 - val_loss: 10.1622 - val_mean_squared_error: 10.0613\n",
      "Epoch 113/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.7623 - mean_squared_error: 22.6610 - val_loss: 10.7538 - val_mean_squared_error: 10.6520\n",
      "Epoch 114/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.3882 - mean_squared_error: 22.2859 - val_loss: 11.0734 - val_mean_squared_error: 10.9709\n",
      "Epoch 115/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.7254 - mean_squared_error: 22.6225 - val_loss: 10.5521 - val_mean_squared_error: 10.4486\n",
      "Epoch 116/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.5918 - mean_squared_error: 22.4880 - val_loss: 11.2265 - val_mean_squared_error: 11.1223\n",
      "Epoch 117/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.8031 - mean_squared_error: 22.6986 - val_loss: 11.2128 - val_mean_squared_error: 11.1078\n",
      "Epoch 118/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.6650 - mean_squared_error: 22.5595 - val_loss: 10.8225 - val_mean_squared_error: 10.7166\n",
      "Epoch 119/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.4626 - mean_squared_error: 22.3564 - val_loss: 10.9768 - val_mean_squared_error: 10.8703\n",
      "Epoch 120/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.4720 - mean_squared_error: 22.3652 - val_loss: 10.8267 - val_mean_squared_error: 10.7195\n",
      "Epoch 121/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.2423 - mean_squared_error: 22.1349 - val_loss: 10.8150 - val_mean_squared_error: 10.7073\n",
      "Epoch 122/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.5287 - mean_squared_error: 22.4204 - val_loss: 15.3510 - val_mean_squared_error: 15.2423\n",
      "Epoch 123/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.2307 - mean_squared_error: 22.1216 - val_loss: 10.8693 - val_mean_squared_error: 10.7599\n",
      "Epoch 124/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.2142 - mean_squared_error: 22.1045 - val_loss: 10.2072 - val_mean_squared_error: 10.0970\n",
      "Epoch 125/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.2678 - mean_squared_error: 22.1574 - val_loss: 10.9144 - val_mean_squared_error: 10.8037\n",
      "Epoch 126/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.2133 - mean_squared_error: 22.1022 - val_loss: 10.1962 - val_mean_squared_error: 10.0848\n",
      "Epoch 127/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.8265 - mean_squared_error: 21.7149 - val_loss: 11.5699 - val_mean_squared_error: 11.4580\n",
      "Epoch 128/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.2046 - mean_squared_error: 22.0922 - val_loss: 11.3479 - val_mean_squared_error: 11.2352\n",
      "Epoch 129/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.2342 - mean_squared_error: 22.1211 - val_loss: 10.1605 - val_mean_squared_error: 10.0468\n",
      "Epoch 130/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.4202 - mean_squared_error: 22.3063 - val_loss: 11.3402 - val_mean_squared_error: 11.2260\n",
      "Epoch 131/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.8956 - mean_squared_error: 21.7810 - val_loss: 10.5372 - val_mean_squared_error: 10.4222\n",
      "Epoch 132/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.7402 - mean_squared_error: 21.6249 - val_loss: 10.6714 - val_mean_squared_error: 10.5557\n",
      "Epoch 133/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.2880 - mean_squared_error: 21.1721 - val_loss: 11.6647 - val_mean_squared_error: 11.5486\n",
      "Epoch 134/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.1160 - mean_squared_error: 21.9996 - val_loss: 10.5428 - val_mean_squared_error: 10.4262\n",
      "Epoch 135/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.5042 - mean_squared_error: 21.3872 - val_loss: 10.2477 - val_mean_squared_error: 10.1302\n",
      "Epoch 136/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 22.0134 - mean_squared_error: 21.8956 - val_loss: 10.8149 - val_mean_squared_error: 10.6967\n",
      "Epoch 137/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.4264 - mean_squared_error: 21.3079 - val_loss: 11.1428 - val_mean_squared_error: 11.0241\n",
      "Epoch 138/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.5118 - mean_squared_error: 21.3927 - val_loss: 11.1820 - val_mean_squared_error: 11.0626\n",
      "Epoch 139/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.3253 - mean_squared_error: 21.2054 - val_loss: 10.4175 - val_mean_squared_error: 10.2974\n",
      "Epoch 140/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.2786 - mean_squared_error: 21.1579 - val_loss: 10.6478 - val_mean_squared_error: 10.5266\n",
      "Epoch 141/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.4678 - mean_squared_error: 21.3460 - val_loss: 10.3343 - val_mean_squared_error: 10.2121\n",
      "Epoch 142/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.6670 - mean_squared_error: 21.5445 - val_loss: 11.7039 - val_mean_squared_error: 11.5811\n",
      "Epoch 143/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.5022 - mean_squared_error: 21.3790 - val_loss: 10.6160 - val_mean_squared_error: 10.4926\n",
      "Epoch 144/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.4093 - mean_squared_error: 21.2854 - val_loss: 10.7121 - val_mean_squared_error: 10.5881\n",
      "Epoch 145/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.2041 - mean_squared_error: 21.0796 - val_loss: 10.2908 - val_mean_squared_error: 10.1659\n",
      "Epoch 146/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.4674 - mean_squared_error: 21.3421 - val_loss: 10.4995 - val_mean_squared_error: 10.3739\n",
      "Epoch 147/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 1s 3ms/step - loss: 21.1588 - mean_squared_error: 21.0329 - val_loss: 10.1764 - val_mean_squared_error: 10.0503\n",
      "Epoch 148/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.3935 - mean_squared_error: 21.2671 - val_loss: 10.0250 - val_mean_squared_error: 9.8984\n",
      "Epoch 149/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.5244 - mean_squared_error: 21.3976 - val_loss: 11.0630 - val_mean_squared_error: 10.9360\n",
      "Epoch 150/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.0726 - mean_squared_error: 20.9451 - val_loss: 10.1569 - val_mean_squared_error: 10.0289\n",
      "Epoch 151/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.6420 - mean_squared_error: 20.5138 - val_loss: 10.1676 - val_mean_squared_error: 10.0392\n",
      "Epoch 152/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.8397 - mean_squared_error: 20.7109 - val_loss: 10.2134 - val_mean_squared_error: 10.0842\n",
      "Epoch 153/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.6069 - mean_squared_error: 21.4772 - val_loss: 9.9585 - val_mean_squared_error: 9.8282\n",
      "Epoch 154/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.0782 - mean_squared_error: 20.9475 - val_loss: 10.6260 - val_mean_squared_error: 10.4948\n",
      "Epoch 155/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 21.0866 - mean_squared_error: 20.9551 - val_loss: 10.6281 - val_mean_squared_error: 10.4963\n",
      "Epoch 156/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.5308 - mean_squared_error: 20.3988 - val_loss: 10.7688 - val_mean_squared_error: 10.6364\n",
      "Epoch 157/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.7156 - mean_squared_error: 20.5830 - val_loss: 11.3164 - val_mean_squared_error: 11.1838\n",
      "Epoch 158/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.6712 - mean_squared_error: 20.5380 - val_loss: 10.3450 - val_mean_squared_error: 10.2114\n",
      "Epoch 159/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.3898 - mean_squared_error: 20.2560 - val_loss: 10.0770 - val_mean_squared_error: 9.9429\n",
      "Epoch 160/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.7290 - mean_squared_error: 20.5946 - val_loss: 10.5889 - val_mean_squared_error: 10.4543\n",
      "Epoch 161/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.6210 - mean_squared_error: 20.4861 - val_loss: 10.2288 - val_mean_squared_error: 10.0937\n",
      "Epoch 162/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.4548 - mean_squared_error: 20.3194 - val_loss: 10.4907 - val_mean_squared_error: 10.3550\n",
      "Epoch 163/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.4217 - mean_squared_error: 20.2856 - val_loss: 11.1385 - val_mean_squared_error: 11.0020\n",
      "Epoch 164/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.6173 - mean_squared_error: 20.4805 - val_loss: 10.4770 - val_mean_squared_error: 10.3400\n",
      "Epoch 165/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.6417 - mean_squared_error: 20.5042 - val_loss: 10.3715 - val_mean_squared_error: 10.2336\n",
      "Epoch 166/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.2840 - mean_squared_error: 20.1459 - val_loss: 10.5627 - val_mean_squared_error: 10.4244\n",
      "Epoch 167/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.5503 - mean_squared_error: 20.4116 - val_loss: 10.3953 - val_mean_squared_error: 10.2565\n",
      "Epoch 168/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.0983 - mean_squared_error: 19.9592 - val_loss: 10.6818 - val_mean_squared_error: 10.5424\n",
      "Epoch 169/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.9453 - mean_squared_error: 19.8055 - val_loss: 10.3978 - val_mean_squared_error: 10.2576\n",
      "Epoch 170/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.0727 - mean_squared_error: 19.9322 - val_loss: 11.2671 - val_mean_squared_error: 11.1262\n",
      "Epoch 171/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.2750 - mean_squared_error: 20.1341 - val_loss: 10.4809 - val_mean_squared_error: 10.3396\n",
      "Epoch 172/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.4642 - mean_squared_error: 20.3227 - val_loss: 11.1091 - val_mean_squared_error: 10.9671\n",
      "Epoch 173/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.3155 - mean_squared_error: 20.1733 - val_loss: 11.0530 - val_mean_squared_error: 10.9105\n",
      "Epoch 174/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.1728 - mean_squared_error: 20.0302 - val_loss: 11.0326 - val_mean_squared_error: 10.8898\n",
      "Epoch 175/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.1328 - mean_squared_error: 19.9896 - val_loss: 10.8034 - val_mean_squared_error: 10.6597\n",
      "Epoch 176/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.1023 - mean_squared_error: 19.9583 - val_loss: 10.9838 - val_mean_squared_error: 10.8394\n",
      "Epoch 177/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.7882 - mean_squared_error: 19.6433 - val_loss: 10.2258 - val_mean_squared_error: 10.0806\n",
      "Epoch 178/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.7580 - mean_squared_error: 19.6126 - val_loss: 10.2034 - val_mean_squared_error: 10.0579\n",
      "Epoch 179/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.9874 - mean_squared_error: 19.8414 - val_loss: 10.4953 - val_mean_squared_error: 10.3490\n",
      "Epoch 180/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.9335 - mean_squared_error: 19.7868 - val_loss: 10.8263 - val_mean_squared_error: 10.6794\n",
      "Epoch 181/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.2437 - mean_squared_error: 20.0965 - val_loss: 10.9514 - val_mean_squared_error: 10.8040\n",
      "Epoch 182/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.9517 - mean_squared_error: 19.8042 - val_loss: 11.1992 - val_mean_squared_error: 11.0515\n",
      "Epoch 183/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 20.5038 - mean_squared_error: 20.3558 - val_loss: 10.4680 - val_mean_squared_error: 10.3198\n",
      "Epoch 184/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.8302 - mean_squared_error: 19.6816 - val_loss: 10.4572 - val_mean_squared_error: 10.3083\n",
      "Epoch 185/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.4314 - mean_squared_error: 19.2821 - val_loss: 10.8073 - val_mean_squared_error: 10.6577\n",
      "Epoch 186/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.9260 - mean_squared_error: 19.7762 - val_loss: 10.4913 - val_mean_squared_error: 10.3414\n",
      "Epoch 187/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.4928 - mean_squared_error: 19.3426 - val_loss: 10.3226 - val_mean_squared_error: 10.1721\n",
      "Epoch 188/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.9728 - mean_squared_error: 19.8219 - val_loss: 10.0601 - val_mean_squared_error: 9.9087\n",
      "Epoch 189/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.9092 - mean_squared_error: 19.7577 - val_loss: 10.4232 - val_mean_squared_error: 10.2715\n",
      "Epoch 190/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.6708 - mean_squared_error: 19.5190 - val_loss: 10.3146 - val_mean_squared_error: 10.1627\n",
      "Epoch 191/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.6889 - mean_squared_error: 19.5367 - val_loss: 10.0656 - val_mean_squared_error: 9.9129\n",
      "Epoch 192/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.0312 - mean_squared_error: 18.8783 - val_loss: 10.2544 - val_mean_squared_error: 10.1014\n",
      "Epoch 193/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.3430 - mean_squared_error: 19.1896 - val_loss: 9.8314 - val_mean_squared_error: 9.6778\n",
      "Epoch 194/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.4528 - mean_squared_error: 19.2989 - val_loss: 10.2844 - val_mean_squared_error: 10.1302\n",
      "Epoch 195/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 1s 3ms/step - loss: 19.6523 - mean_squared_error: 19.4976 - val_loss: 10.2122 - val_mean_squared_error: 10.0573\n",
      "Epoch 196/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.1936 - mean_squared_error: 19.0384 - val_loss: 10.3891 - val_mean_squared_error: 10.2338\n",
      "Epoch 197/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.3030 - mean_squared_error: 19.1474 - val_loss: 9.5283 - val_mean_squared_error: 9.3723\n",
      "Epoch 198/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.2934 - mean_squared_error: 19.1372 - val_loss: 10.3419 - val_mean_squared_error: 10.1853\n",
      "Epoch 199/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.4393 - mean_squared_error: 19.2822 - val_loss: 9.9754 - val_mean_squared_error: 9.8182\n",
      "Epoch 200/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.4886 - mean_squared_error: 19.3311 - val_loss: 10.9729 - val_mean_squared_error: 10.8151\n",
      "Epoch 201/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.1934 - mean_squared_error: 19.0354 - val_loss: 10.5611 - val_mean_squared_error: 10.4028\n",
      "Epoch 202/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.3097 - mean_squared_error: 19.1513 - val_loss: 10.3265 - val_mean_squared_error: 10.1681\n",
      "Epoch 203/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.2665 - mean_squared_error: 19.1077 - val_loss: 10.2554 - val_mean_squared_error: 10.0965\n",
      "Epoch 204/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.8024 - mean_squared_error: 18.6434 - val_loss: 9.9752 - val_mean_squared_error: 9.8160\n",
      "Epoch 205/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.6086 - mean_squared_error: 19.4491 - val_loss: 10.1362 - val_mean_squared_error: 9.9765\n",
      "Epoch 206/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.4181 - mean_squared_error: 19.2581 - val_loss: 10.5973 - val_mean_squared_error: 10.4369\n",
      "Epoch 207/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.4807 - mean_squared_error: 19.3200 - val_loss: 10.2723 - val_mean_squared_error: 10.1116\n",
      "Epoch 208/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.9484 - mean_squared_error: 18.7876 - val_loss: 9.7017 - val_mean_squared_error: 9.5408\n",
      "Epoch 209/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.9742 - mean_squared_error: 18.8127 - val_loss: 12.2017 - val_mean_squared_error: 12.0401\n",
      "Epoch 210/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.3251 - mean_squared_error: 19.1632 - val_loss: 10.2383 - val_mean_squared_error: 10.0761\n",
      "Epoch 211/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.8377 - mean_squared_error: 18.6751 - val_loss: 10.0352 - val_mean_squared_error: 9.8723\n",
      "Epoch 212/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.8574 - mean_squared_error: 18.6945 - val_loss: 10.2063 - val_mean_squared_error: 10.0433\n",
      "Epoch 213/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.0731 - mean_squared_error: 18.9098 - val_loss: 10.1832 - val_mean_squared_error: 10.0197\n",
      "Epoch 214/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.7685 - mean_squared_error: 18.6047 - val_loss: 10.2334 - val_mean_squared_error: 10.0693\n",
      "Epoch 215/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.4803 - mean_squared_error: 18.3160 - val_loss: 10.1924 - val_mean_squared_error: 10.0278\n",
      "Epoch 216/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.6269 - mean_squared_error: 18.4619 - val_loss: 10.6531 - val_mean_squared_error: 10.4878\n",
      "Epoch 217/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.1369 - mean_squared_error: 18.9713 - val_loss: 10.5390 - val_mean_squared_error: 10.3730\n",
      "Epoch 218/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.6001 - mean_squared_error: 18.4341 - val_loss: 9.9744 - val_mean_squared_error: 9.8081\n",
      "Epoch 219/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.8058 - mean_squared_error: 18.6395 - val_loss: 10.8389 - val_mean_squared_error: 10.6723\n",
      "Epoch 220/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 19.0767 - mean_squared_error: 18.9098 - val_loss: 10.4701 - val_mean_squared_error: 10.3028\n",
      "Epoch 221/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.6437 - mean_squared_error: 18.4762 - val_loss: 10.3618 - val_mean_squared_error: 10.1940\n",
      "Epoch 222/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.6738 - mean_squared_error: 18.5056 - val_loss: 10.3066 - val_mean_squared_error: 10.1381\n",
      "Epoch 223/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.6340 - mean_squared_error: 18.4652 - val_loss: 10.4477 - val_mean_squared_error: 10.2786\n",
      "Epoch 224/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.5271 - mean_squared_error: 18.3577 - val_loss: 9.9939 - val_mean_squared_error: 9.8241\n",
      "Epoch 225/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.2909 - mean_squared_error: 18.1210 - val_loss: 10.1225 - val_mean_squared_error: 9.9526\n",
      "Epoch 226/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.8085 - mean_squared_error: 17.6384 - val_loss: 10.2563 - val_mean_squared_error: 10.0859\n",
      "Epoch 227/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.6615 - mean_squared_error: 18.4911 - val_loss: 10.6234 - val_mean_squared_error: 10.4528\n",
      "Epoch 228/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.6530 - mean_squared_error: 18.4822 - val_loss: 10.5904 - val_mean_squared_error: 10.4193\n",
      "Epoch 229/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.1016 - mean_squared_error: 17.9304 - val_loss: 10.7368 - val_mean_squared_error: 10.5654\n",
      "Epoch 230/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.6298 - mean_squared_error: 18.4580 - val_loss: 10.2701 - val_mean_squared_error: 10.0979\n",
      "Epoch 231/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.4984 - mean_squared_error: 18.3261 - val_loss: 9.7189 - val_mean_squared_error: 9.5465\n",
      "Epoch 232/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.6638 - mean_squared_error: 18.4911 - val_loss: 9.9712 - val_mean_squared_error: 9.7982\n",
      "Epoch 233/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.3347 - mean_squared_error: 18.1615 - val_loss: 9.8239 - val_mean_squared_error: 9.6504\n",
      "Epoch 234/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.0336 - mean_squared_error: 17.8599 - val_loss: 10.1107 - val_mean_squared_error: 9.9368\n",
      "Epoch 235/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.1215 - mean_squared_error: 17.9472 - val_loss: 9.8030 - val_mean_squared_error: 9.6284\n",
      "Epoch 236/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.8377 - mean_squared_error: 17.6632 - val_loss: 10.1449 - val_mean_squared_error: 9.9703\n",
      "Epoch 237/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.2414 - mean_squared_error: 18.0668 - val_loss: 10.2005 - val_mean_squared_error: 10.0255\n",
      "Epoch 238/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.1600 - mean_squared_error: 17.9848 - val_loss: 9.6420 - val_mean_squared_error: 9.4667\n",
      "Epoch 239/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.9953 - mean_squared_error: 17.8195 - val_loss: 10.0066 - val_mean_squared_error: 9.8304\n",
      "Epoch 240/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.8739 - mean_squared_error: 17.6975 - val_loss: 9.8438 - val_mean_squared_error: 9.6671\n",
      "Epoch 241/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.8314 - mean_squared_error: 17.6544 - val_loss: 9.6956 - val_mean_squared_error: 9.5185\n",
      "Epoch 242/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.9609 - mean_squared_error: 17.7837 - val_loss: 10.1765 - val_mean_squared_error: 9.9990\n",
      "Epoch 243/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.7529 - mean_squared_error: 17.5752 - val_loss: 10.1712 - val_mean_squared_error: 9.9933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.2278 - mean_squared_error: 18.0497 - val_loss: 9.9984 - val_mean_squared_error: 9.8201\n",
      "Epoch 245/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.8089 - mean_squared_error: 17.6305 - val_loss: 9.8306 - val_mean_squared_error: 9.6520\n",
      "Epoch 246/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.7857 - mean_squared_error: 17.6068 - val_loss: 9.9836 - val_mean_squared_error: 9.8046\n",
      "Epoch 247/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 18.0374 - mean_squared_error: 17.8582 - val_loss: 10.2230 - val_mean_squared_error: 10.0435\n",
      "Epoch 248/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.8482 - mean_squared_error: 17.6686 - val_loss: 9.9920 - val_mean_squared_error: 9.8125\n",
      "Epoch 249/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.6838 - mean_squared_error: 17.5041 - val_loss: 10.4500 - val_mean_squared_error: 10.2701\n",
      "Epoch 250/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.5133 - mean_squared_error: 17.3332 - val_loss: 10.7189 - val_mean_squared_error: 10.5387\n",
      "Epoch 251/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.7024 - mean_squared_error: 17.5219 - val_loss: 10.2228 - val_mean_squared_error: 10.0420\n",
      "Epoch 252/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.9087 - mean_squared_error: 17.7277 - val_loss: 9.9027 - val_mean_squared_error: 9.7214\n",
      "Epoch 253/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.1697 - mean_squared_error: 16.9881 - val_loss: 9.9068 - val_mean_squared_error: 9.7249\n",
      "Epoch 254/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.4568 - mean_squared_error: 17.2747 - val_loss: 9.7898 - val_mean_squared_error: 9.6078\n",
      "Epoch 255/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.6250 - mean_squared_error: 17.4427 - val_loss: 10.2411 - val_mean_squared_error: 10.0585\n",
      "Epoch 256/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.8070 - mean_squared_error: 17.6242 - val_loss: 10.1176 - val_mean_squared_error: 9.9345\n",
      "Epoch 257/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.5166 - mean_squared_error: 17.3333 - val_loss: 10.4843 - val_mean_squared_error: 10.3010\n",
      "Epoch 258/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.5108 - mean_squared_error: 17.3273 - val_loss: 10.1370 - val_mean_squared_error: 9.9531\n",
      "Epoch 259/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.6361 - mean_squared_error: 17.4522 - val_loss: 9.8969 - val_mean_squared_error: 9.7127\n",
      "Epoch 260/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.5518 - mean_squared_error: 17.3674 - val_loss: 9.8181 - val_mean_squared_error: 9.6337\n",
      "Epoch 261/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.8458 - mean_squared_error: 17.6611 - val_loss: 10.1606 - val_mean_squared_error: 9.9757\n",
      "Epoch 262/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.5514 - mean_squared_error: 17.3667 - val_loss: 10.0574 - val_mean_squared_error: 9.8725\n",
      "Epoch 263/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.3195 - mean_squared_error: 17.1341 - val_loss: 10.1821 - val_mean_squared_error: 9.9962\n",
      "Epoch 264/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.2159 - mean_squared_error: 17.0299 - val_loss: 10.2822 - val_mean_squared_error: 10.0960\n",
      "Epoch 265/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.3929 - mean_squared_error: 17.2066 - val_loss: 9.9467 - val_mean_squared_error: 9.7601\n",
      "Epoch 266/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.2606 - mean_squared_error: 17.0739 - val_loss: 10.1661 - val_mean_squared_error: 9.9793\n",
      "Epoch 267/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.2498 - mean_squared_error: 17.0628 - val_loss: 10.3959 - val_mean_squared_error: 10.2087\n",
      "Epoch 268/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.2837 - mean_squared_error: 17.0962 - val_loss: 10.1129 - val_mean_squared_error: 9.9249\n",
      "Epoch 269/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.2306 - mean_squared_error: 17.0423 - val_loss: 11.0667 - val_mean_squared_error: 10.8784\n",
      "Epoch 270/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.0884 - mean_squared_error: 16.9001 - val_loss: 10.0703 - val_mean_squared_error: 9.8816\n",
      "Epoch 271/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.9392 - mean_squared_error: 16.7505 - val_loss: 10.2181 - val_mean_squared_error: 10.0291\n",
      "Epoch 272/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.2296 - mean_squared_error: 17.0404 - val_loss: 10.9388 - val_mean_squared_error: 10.7495\n",
      "Epoch 273/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.4454 - mean_squared_error: 17.2560 - val_loss: 10.5519 - val_mean_squared_error: 10.3623\n",
      "Epoch 274/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.0629 - mean_squared_error: 16.8732 - val_loss: 9.9616 - val_mean_squared_error: 9.7716\n",
      "Epoch 275/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.4119 - mean_squared_error: 17.2216 - val_loss: 10.1369 - val_mean_squared_error: 9.9463\n",
      "Epoch 276/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.3864 - mean_squared_error: 17.1958 - val_loss: 9.8025 - val_mean_squared_error: 9.6116\n",
      "Epoch 277/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.9650 - mean_squared_error: 16.7737 - val_loss: 10.4128 - val_mean_squared_error: 10.2213\n",
      "Epoch 278/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.8391 - mean_squared_error: 16.6475 - val_loss: 10.1241 - val_mean_squared_error: 9.9323\n",
      "Epoch 279/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.9303 - mean_squared_error: 16.7384 - val_loss: 10.2057 - val_mean_squared_error: 10.0136\n",
      "Epoch 280/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.8728 - mean_squared_error: 16.6805 - val_loss: 10.6814 - val_mean_squared_error: 10.4888\n",
      "Epoch 281/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 17.0852 - mean_squared_error: 16.8925 - val_loss: 9.7942 - val_mean_squared_error: 9.6015\n",
      "Epoch 282/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.7886 - mean_squared_error: 16.5958 - val_loss: 10.2563 - val_mean_squared_error: 10.0633\n",
      "Epoch 283/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.5471 - mean_squared_error: 16.3540 - val_loss: 9.8146 - val_mean_squared_error: 9.6212\n",
      "Epoch 284/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.9341 - mean_squared_error: 16.7408 - val_loss: 10.5018 - val_mean_squared_error: 10.3084\n",
      "Epoch 285/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.6812 - mean_squared_error: 16.4877 - val_loss: 10.4817 - val_mean_squared_error: 10.2879\n",
      "Epoch 286/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.6701 - mean_squared_error: 16.4761 - val_loss: 10.5406 - val_mean_squared_error: 10.3465\n",
      "Epoch 287/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.7899 - mean_squared_error: 16.5954 - val_loss: 10.4867 - val_mean_squared_error: 10.2918\n",
      "Epoch 288/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.7451 - mean_squared_error: 16.5501 - val_loss: 10.9630 - val_mean_squared_error: 10.7678\n",
      "Epoch 289/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.7924 - mean_squared_error: 16.5970 - val_loss: 9.8723 - val_mean_squared_error: 9.6768\n",
      "Epoch 290/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.8632 - mean_squared_error: 16.6676 - val_loss: 10.7850 - val_mean_squared_error: 10.5891\n",
      "Epoch 291/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.2505 - mean_squared_error: 16.0544 - val_loss: 10.2275 - val_mean_squared_error: 10.0311\n",
      "Epoch 292/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.6135 - mean_squared_error: 16.4169 - val_loss: 10.3293 - val_mean_squared_error: 10.1327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.3694 - mean_squared_error: 16.1726 - val_loss: 10.3014 - val_mean_squared_error: 10.1045\n",
      "Epoch 294/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.4035 - mean_squared_error: 16.2065 - val_loss: 10.1511 - val_mean_squared_error: 9.9539\n",
      "Epoch 295/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.3589 - mean_squared_error: 16.1616 - val_loss: 10.1569 - val_mean_squared_error: 9.9595\n",
      "Epoch 296/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.3628 - mean_squared_error: 16.1651 - val_loss: 10.0782 - val_mean_squared_error: 9.8802\n",
      "Epoch 297/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.2743 - mean_squared_error: 16.0763 - val_loss: 10.0358 - val_mean_squared_error: 9.8375\n",
      "Epoch 298/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.2208 - mean_squared_error: 16.0223 - val_loss: 10.8092 - val_mean_squared_error: 10.6106\n",
      "Epoch 299/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.2595 - mean_squared_error: 16.0607 - val_loss: 10.1720 - val_mean_squared_error: 9.9731\n",
      "Epoch 300/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.4946 - mean_squared_error: 16.2955 - val_loss: 10.0792 - val_mean_squared_error: 9.8795\n",
      "Epoch 301/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.3055 - mean_squared_error: 16.1055 - val_loss: 9.9999 - val_mean_squared_error: 9.7995\n",
      "Epoch 302/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.6224 - mean_squared_error: 16.4219 - val_loss: 10.1680 - val_mean_squared_error: 9.9671\n",
      "Epoch 303/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.5187 - mean_squared_error: 16.3176 - val_loss: 10.0717 - val_mean_squared_error: 9.8703\n",
      "Epoch 304/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.3224 - mean_squared_error: 16.1208 - val_loss: 9.7933 - val_mean_squared_error: 9.5915\n",
      "Epoch 305/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.8992 - mean_squared_error: 15.6972 - val_loss: 10.4402 - val_mean_squared_error: 10.2380\n",
      "Epoch 306/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.4925 - mean_squared_error: 16.2902 - val_loss: 10.1127 - val_mean_squared_error: 9.9102\n",
      "Epoch 307/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.4216 - mean_squared_error: 16.2189 - val_loss: 10.0768 - val_mean_squared_error: 9.8739\n",
      "Epoch 308/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.8713 - mean_squared_error: 15.6684 - val_loss: 10.1040 - val_mean_squared_error: 9.9010\n",
      "Epoch 309/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.9187 - mean_squared_error: 15.7156 - val_loss: 9.7606 - val_mean_squared_error: 9.5574\n",
      "Epoch 310/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.2585 - mean_squared_error: 16.0551 - val_loss: 9.9052 - val_mean_squared_error: 9.7015\n",
      "Epoch 311/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.6133 - mean_squared_error: 16.4093 - val_loss: 9.6291 - val_mean_squared_error: 9.4250\n",
      "Epoch 312/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.2492 - mean_squared_error: 16.0447 - val_loss: 10.2862 - val_mean_squared_error: 10.0816\n",
      "Epoch 313/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.9582 - mean_squared_error: 15.7533 - val_loss: 10.5061 - val_mean_squared_error: 10.3011\n",
      "Epoch 314/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.8243 - mean_squared_error: 15.6191 - val_loss: 10.1750 - val_mean_squared_error: 9.9697\n",
      "Epoch 315/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.7191 - mean_squared_error: 15.5137 - val_loss: 10.2001 - val_mean_squared_error: 9.9946\n",
      "Epoch 316/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.7125 - mean_squared_error: 15.5066 - val_loss: 10.4760 - val_mean_squared_error: 10.2699\n",
      "Epoch 317/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.2194 - mean_squared_error: 16.0133 - val_loss: 10.8471 - val_mean_squared_error: 10.6410\n",
      "Epoch 318/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.8808 - mean_squared_error: 15.6745 - val_loss: 10.1616 - val_mean_squared_error: 9.9552\n",
      "Epoch 319/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.4448 - mean_squared_error: 16.2381 - val_loss: 10.3077 - val_mean_squared_error: 10.1006\n",
      "Epoch 320/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.7925 - mean_squared_error: 15.5852 - val_loss: 9.6056 - val_mean_squared_error: 9.3982\n",
      "Epoch 321/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.6357 - mean_squared_error: 15.4282 - val_loss: 9.9258 - val_mean_squared_error: 9.7183\n",
      "Epoch 322/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.7293 - mean_squared_error: 15.5216 - val_loss: 10.0418 - val_mean_squared_error: 9.8339\n",
      "Epoch 323/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.5849 - mean_squared_error: 15.3769 - val_loss: 9.8477 - val_mean_squared_error: 9.6393\n",
      "Epoch 324/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.8311 - mean_squared_error: 15.6225 - val_loss: 10.1913 - val_mean_squared_error: 9.9824\n",
      "Epoch 325/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.2182 - mean_squared_error: 16.0092 - val_loss: 10.8272 - val_mean_squared_error: 10.6180\n",
      "Epoch 326/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.7965 - mean_squared_error: 15.5870 - val_loss: 9.8890 - val_mean_squared_error: 9.6794\n",
      "Epoch 327/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.6957 - mean_squared_error: 15.4860 - val_loss: 10.0409 - val_mean_squared_error: 9.8311\n",
      "Epoch 328/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.0927 - mean_squared_error: 15.8826 - val_loss: 9.9232 - val_mean_squared_error: 9.7130\n",
      "Epoch 329/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.6891 - mean_squared_error: 15.4786 - val_loss: 9.8261 - val_mean_squared_error: 9.6154\n",
      "Epoch 330/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.0030 - mean_squared_error: 15.7919 - val_loss: 9.9150 - val_mean_squared_error: 9.7036\n",
      "Epoch 331/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.5228 - mean_squared_error: 15.3114 - val_loss: 9.8211 - val_mean_squared_error: 9.6095\n",
      "Epoch 332/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.3279 - mean_squared_error: 15.1162 - val_loss: 9.4280 - val_mean_squared_error: 9.2162\n",
      "Epoch 333/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.7422 - mean_squared_error: 15.5302 - val_loss: 10.0568 - val_mean_squared_error: 9.8446\n",
      "Epoch 334/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.3090 - mean_squared_error: 15.0967 - val_loss: 10.4490 - val_mean_squared_error: 10.2365\n",
      "Epoch 335/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.6913 - mean_squared_error: 15.4788 - val_loss: 10.5496 - val_mean_squared_error: 10.3368\n",
      "Epoch 336/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.5713 - mean_squared_error: 15.3582 - val_loss: 10.2692 - val_mean_squared_error: 10.0557\n",
      "Epoch 337/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.4680 - mean_squared_error: 15.2544 - val_loss: 10.7133 - val_mean_squared_error: 10.4997\n",
      "Epoch 338/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.9798 - mean_squared_error: 15.7660 - val_loss: 11.4204 - val_mean_squared_error: 11.2061\n",
      "Epoch 339/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 16.4025 - mean_squared_error: 16.1880 - val_loss: 10.2638 - val_mean_squared_error: 10.0491\n",
      "Epoch 340/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.5127 - mean_squared_error: 15.2981 - val_loss: 10.3661 - val_mean_squared_error: 10.1514\n",
      "Epoch 341/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.5897 - mean_squared_error: 15.3749 - val_loss: 9.8150 - val_mean_squared_error: 9.6002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.1992 - mean_squared_error: 14.9840 - val_loss: 9.6197 - val_mean_squared_error: 9.4044\n",
      "Epoch 343/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.3322 - mean_squared_error: 15.1167 - val_loss: 10.1330 - val_mean_squared_error: 9.9171\n",
      "Epoch 344/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.3282 - mean_squared_error: 15.1122 - val_loss: 9.8634 - val_mean_squared_error: 9.6473\n",
      "Epoch 345/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.6449 - mean_squared_error: 15.4287 - val_loss: 10.2463 - val_mean_squared_error: 10.0298\n",
      "Epoch 346/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.2485 - mean_squared_error: 15.0318 - val_loss: 10.2792 - val_mean_squared_error: 10.0625\n",
      "Epoch 347/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.1702 - mean_squared_error: 14.9533 - val_loss: 10.1249 - val_mean_squared_error: 9.9078\n",
      "Epoch 348/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.3705 - mean_squared_error: 15.1533 - val_loss: 10.7277 - val_mean_squared_error: 10.5103\n",
      "Epoch 349/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.2027 - mean_squared_error: 14.9850 - val_loss: 10.0290 - val_mean_squared_error: 9.8111\n",
      "Epoch 350/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.3433 - mean_squared_error: 15.1251 - val_loss: 9.9484 - val_mean_squared_error: 9.7299\n",
      "Epoch 351/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.2005 - mean_squared_error: 14.9820 - val_loss: 9.6480 - val_mean_squared_error: 9.4295\n",
      "Epoch 352/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.2907 - mean_squared_error: 15.0718 - val_loss: 10.0290 - val_mean_squared_error: 9.8099\n",
      "Epoch 353/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.0172 - mean_squared_error: 14.7980 - val_loss: 10.5620 - val_mean_squared_error: 10.3425\n",
      "Epoch 354/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.8423 - mean_squared_error: 14.6226 - val_loss: 10.3075 - val_mean_squared_error: 10.0875\n",
      "Epoch 355/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.8852 - mean_squared_error: 14.6649 - val_loss: 9.4417 - val_mean_squared_error: 9.2215\n",
      "Epoch 356/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.4761 - mean_squared_error: 15.2557 - val_loss: 10.1974 - val_mean_squared_error: 9.9767\n",
      "Epoch 357/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.7666 - mean_squared_error: 14.5457 - val_loss: 12.2913 - val_mean_squared_error: 12.0703\n",
      "Epoch 358/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.1524 - mean_squared_error: 14.9314 - val_loss: 9.5487 - val_mean_squared_error: 9.3276\n",
      "Epoch 359/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.0493 - mean_squared_error: 14.8279 - val_loss: 9.9875 - val_mean_squared_error: 9.7659\n",
      "Epoch 360/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.2103 - mean_squared_error: 14.9885 - val_loss: 9.9187 - val_mean_squared_error: 9.6967\n",
      "Epoch 361/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.0457 - mean_squared_error: 14.8234 - val_loss: 9.7090 - val_mean_squared_error: 9.4865\n",
      "Epoch 362/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.7729 - mean_squared_error: 14.5503 - val_loss: 9.9482 - val_mean_squared_error: 9.7255\n",
      "Epoch 363/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.8853 - mean_squared_error: 14.6623 - val_loss: 9.8857 - val_mean_squared_error: 9.6626\n",
      "Epoch 364/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.0708 - mean_squared_error: 14.8473 - val_loss: 9.8419 - val_mean_squared_error: 9.6183\n",
      "Epoch 365/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.0356 - mean_squared_error: 14.8117 - val_loss: 10.9790 - val_mean_squared_error: 10.7547\n",
      "Epoch 366/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.8999 - mean_squared_error: 14.6755 - val_loss: 10.4466 - val_mean_squared_error: 10.2220\n",
      "Epoch 367/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.8954 - mean_squared_error: 14.6707 - val_loss: 9.6885 - val_mean_squared_error: 9.4637\n",
      "Epoch 368/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.7613 - mean_squared_error: 14.5365 - val_loss: 9.5879 - val_mean_squared_error: 9.3630\n",
      "Epoch 369/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.9317 - mean_squared_error: 14.7066 - val_loss: 10.0391 - val_mean_squared_error: 9.8140\n",
      "Epoch 370/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.8728 - mean_squared_error: 14.6476 - val_loss: 9.8080 - val_mean_squared_error: 9.5827\n",
      "Epoch 371/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.1247 - mean_squared_error: 14.8991 - val_loss: 10.4487 - val_mean_squared_error: 10.2229\n",
      "Epoch 372/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.6109 - mean_squared_error: 14.3852 - val_loss: 10.7640 - val_mean_squared_error: 10.5380\n",
      "Epoch 373/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.5207 - mean_squared_error: 14.2947 - val_loss: 10.0839 - val_mean_squared_error: 9.8579\n",
      "Epoch 374/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.3837 - mean_squared_error: 14.1577 - val_loss: 10.0643 - val_mean_squared_error: 9.8380\n",
      "Epoch 375/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.7547 - mean_squared_error: 14.5284 - val_loss: 9.7302 - val_mean_squared_error: 9.5038\n",
      "Epoch 376/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.6713 - mean_squared_error: 14.4447 - val_loss: 9.8265 - val_mean_squared_error: 9.5998\n",
      "Epoch 377/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.6217 - mean_squared_error: 14.3949 - val_loss: 9.7781 - val_mean_squared_error: 9.5510\n",
      "Epoch 378/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.5986 - mean_squared_error: 14.3715 - val_loss: 10.5742 - val_mean_squared_error: 10.3470\n",
      "Epoch 379/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.3566 - mean_squared_error: 14.1291 - val_loss: 10.0994 - val_mean_squared_error: 9.8716\n",
      "Epoch 380/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 15.0990 - mean_squared_error: 14.8712 - val_loss: 9.9187 - val_mean_squared_error: 9.6909\n",
      "Epoch 381/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.3658 - mean_squared_error: 14.1378 - val_loss: 10.6618 - val_mean_squared_error: 10.4337\n",
      "Epoch 382/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.7799 - mean_squared_error: 14.5517 - val_loss: 10.4918 - val_mean_squared_error: 10.2635\n",
      "Epoch 383/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.4473 - mean_squared_error: 14.2188 - val_loss: 10.3104 - val_mean_squared_error: 10.0817\n",
      "Epoch 384/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.1880 - mean_squared_error: 13.9594 - val_loss: 9.7262 - val_mean_squared_error: 9.4975\n",
      "Epoch 385/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.3845 - mean_squared_error: 14.1556 - val_loss: 10.3700 - val_mean_squared_error: 10.1408\n",
      "Epoch 386/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.4935 - mean_squared_error: 14.2641 - val_loss: 10.0615 - val_mean_squared_error: 9.8317\n",
      "Epoch 387/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.2195 - mean_squared_error: 13.9897 - val_loss: 9.4996 - val_mean_squared_error: 9.2696\n",
      "Epoch 388/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.4579 - mean_squared_error: 14.2279 - val_loss: 9.9050 - val_mean_squared_error: 9.6750\n",
      "Epoch 389/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.2578 - mean_squared_error: 14.0276 - val_loss: 10.5135 - val_mean_squared_error: 10.2833\n",
      "Epoch 390/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.6356 - mean_squared_error: 14.4053 - val_loss: 9.8427 - val_mean_squared_error: 9.6122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.0324 - mean_squared_error: 13.8018 - val_loss: 10.8237 - val_mean_squared_error: 10.5929\n",
      "Epoch 392/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.4348 - mean_squared_error: 14.2037 - val_loss: 10.6982 - val_mean_squared_error: 10.4667\n",
      "Epoch 393/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.8683 - mean_squared_error: 13.6367 - val_loss: 10.1343 - val_mean_squared_error: 9.9026\n",
      "Epoch 394/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.1306 - mean_squared_error: 13.8988 - val_loss: 9.6938 - val_mean_squared_error: 9.4620\n",
      "Epoch 395/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.1083 - mean_squared_error: 13.8763 - val_loss: 10.2048 - val_mean_squared_error: 9.9727\n",
      "Epoch 396/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.3293 - mean_squared_error: 14.0972 - val_loss: 10.4925 - val_mean_squared_error: 10.2605\n",
      "Epoch 397/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.0957 - mean_squared_error: 13.8633 - val_loss: 10.2079 - val_mean_squared_error: 9.9753\n",
      "Epoch 398/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.2144 - mean_squared_error: 13.9818 - val_loss: 10.1843 - val_mean_squared_error: 9.9516\n",
      "Epoch 399/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.5147 - mean_squared_error: 14.2820 - val_loss: 9.6504 - val_mean_squared_error: 9.4176\n",
      "Epoch 400/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.3645 - mean_squared_error: 14.1317 - val_loss: 9.8094 - val_mean_squared_error: 9.5765\n",
      "Epoch 401/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.0302 - mean_squared_error: 13.7971 - val_loss: 9.7942 - val_mean_squared_error: 9.5611\n",
      "Epoch 402/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.2526 - mean_squared_error: 14.0189 - val_loss: 10.3998 - val_mean_squared_error: 10.1658\n",
      "Epoch 403/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.7942 - mean_squared_error: 13.5603 - val_loss: 9.9108 - val_mean_squared_error: 9.6768\n",
      "Epoch 404/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.6526 - mean_squared_error: 13.4184 - val_loss: 10.2995 - val_mean_squared_error: 10.0654\n",
      "Epoch 405/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.9758 - mean_squared_error: 13.7417 - val_loss: 9.8926 - val_mean_squared_error: 9.6585\n",
      "Epoch 406/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.9620 - mean_squared_error: 13.7277 - val_loss: 10.2439 - val_mean_squared_error: 10.0093\n",
      "Epoch 407/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.9684 - mean_squared_error: 13.7334 - val_loss: 9.5456 - val_mean_squared_error: 9.3102\n",
      "Epoch 408/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.9362 - mean_squared_error: 13.7009 - val_loss: 9.9441 - val_mean_squared_error: 9.7085\n",
      "Epoch 409/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.7492 - mean_squared_error: 13.5134 - val_loss: 9.6462 - val_mean_squared_error: 9.4103\n",
      "Epoch 410/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.6463 - mean_squared_error: 13.4104 - val_loss: 10.3815 - val_mean_squared_error: 10.1455\n",
      "Epoch 411/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.9312 - mean_squared_error: 13.6948 - val_loss: 9.9914 - val_mean_squared_error: 9.7548\n",
      "Epoch 412/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.8024 - mean_squared_error: 13.5659 - val_loss: 10.4019 - val_mean_squared_error: 10.1654\n",
      "Epoch 413/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.0646 - mean_squared_error: 13.8281 - val_loss: 10.2870 - val_mean_squared_error: 10.0505\n",
      "Epoch 414/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.0797 - mean_squared_error: 13.8430 - val_loss: 9.6769 - val_mean_squared_error: 9.4401\n",
      "Epoch 415/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.6274 - mean_squared_error: 13.3902 - val_loss: 9.6292 - val_mean_squared_error: 9.3917\n",
      "Epoch 416/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.9685 - mean_squared_error: 13.7306 - val_loss: 9.9296 - val_mean_squared_error: 9.6917\n",
      "Epoch 417/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.6105 - mean_squared_error: 13.3724 - val_loss: 10.6474 - val_mean_squared_error: 10.4092\n",
      "Epoch 418/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.6055 - mean_squared_error: 13.3670 - val_loss: 9.6740 - val_mean_squared_error: 9.4354\n",
      "Epoch 419/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.1083 - mean_squared_error: 13.8697 - val_loss: 9.8325 - val_mean_squared_error: 9.5937\n",
      "Epoch 420/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.7576 - mean_squared_error: 13.5186 - val_loss: 9.9347 - val_mean_squared_error: 9.6955\n",
      "Epoch 421/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.7000 - mean_squared_error: 13.4606 - val_loss: 10.0907 - val_mean_squared_error: 9.8513\n",
      "Epoch 422/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.6130 - mean_squared_error: 13.3737 - val_loss: 9.8114 - val_mean_squared_error: 9.5718\n",
      "Epoch 423/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.4024 - mean_squared_error: 13.1628 - val_loss: 10.1961 - val_mean_squared_error: 9.9564\n",
      "Epoch 424/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 14.0018 - mean_squared_error: 13.7621 - val_loss: 10.0556 - val_mean_squared_error: 9.8158\n",
      "Epoch 425/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.2407 - mean_squared_error: 13.0005 - val_loss: 9.6860 - val_mean_squared_error: 9.4456\n",
      "Epoch 426/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.7257 - mean_squared_error: 13.4852 - val_loss: 10.1305 - val_mean_squared_error: 9.8899\n",
      "Epoch 427/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.6430 - mean_squared_error: 13.4022 - val_loss: 10.0444 - val_mean_squared_error: 9.8033\n",
      "Epoch 428/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.5332 - mean_squared_error: 13.2922 - val_loss: 10.4974 - val_mean_squared_error: 10.2563\n",
      "Epoch 429/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.5816 - mean_squared_error: 13.3405 - val_loss: 9.9545 - val_mean_squared_error: 9.7134\n",
      "Epoch 430/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.7536 - mean_squared_error: 13.5124 - val_loss: 9.4984 - val_mean_squared_error: 9.2573\n",
      "Epoch 431/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.6221 - mean_squared_error: 13.3807 - val_loss: 11.8886 - val_mean_squared_error: 11.6472\n",
      "Epoch 432/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.6013 - mean_squared_error: 13.3593 - val_loss: 10.5118 - val_mean_squared_error: 10.2695\n",
      "Epoch 433/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.6965 - mean_squared_error: 13.4542 - val_loss: 9.7263 - val_mean_squared_error: 9.4837\n",
      "Epoch 434/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.6639 - mean_squared_error: 13.4213 - val_loss: 10.0263 - val_mean_squared_error: 9.7836\n",
      "Epoch 435/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.5854 - mean_squared_error: 13.3424 - val_loss: 10.0194 - val_mean_squared_error: 9.7763\n",
      "Epoch 436/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.4635 - mean_squared_error: 13.2203 - val_loss: 9.8690 - val_mean_squared_error: 9.6254\n",
      "Epoch 437/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.5920 - mean_squared_error: 13.3482 - val_loss: 9.8958 - val_mean_squared_error: 9.6519\n",
      "Epoch 438/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.5850 - mean_squared_error: 13.3408 - val_loss: 9.8334 - val_mean_squared_error: 9.5890\n",
      "Epoch 439/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.1711 - mean_squared_error: 12.9266 - val_loss: 10.2395 - val_mean_squared_error: 9.9949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.5872 - mean_squared_error: 13.3423 - val_loss: 9.3744 - val_mean_squared_error: 9.1294\n",
      "Epoch 441/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.5579 - mean_squared_error: 13.3126 - val_loss: 9.2542 - val_mean_squared_error: 9.0090\n",
      "Epoch 442/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.3594 - mean_squared_error: 13.1140 - val_loss: 9.5544 - val_mean_squared_error: 9.3089\n",
      "Epoch 443/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.6595 - mean_squared_error: 13.4139 - val_loss: 9.6997 - val_mean_squared_error: 9.4539\n",
      "Epoch 444/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.0380 - mean_squared_error: 12.7919 - val_loss: 10.0212 - val_mean_squared_error: 9.7748\n",
      "Epoch 445/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.1610 - mean_squared_error: 12.9145 - val_loss: 9.6235 - val_mean_squared_error: 9.3770\n",
      "Epoch 446/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.0362 - mean_squared_error: 12.7895 - val_loss: 9.5763 - val_mean_squared_error: 9.3294\n",
      "Epoch 447/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.3084 - mean_squared_error: 13.0616 - val_loss: 9.6293 - val_mean_squared_error: 9.3825\n",
      "Epoch 448/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.0473 - mean_squared_error: 12.8001 - val_loss: 9.4510 - val_mean_squared_error: 9.2035\n",
      "Epoch 449/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.7802 - mean_squared_error: 12.5325 - val_loss: 9.5371 - val_mean_squared_error: 9.2893\n",
      "Epoch 450/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.0538 - mean_squared_error: 12.8060 - val_loss: 9.4103 - val_mean_squared_error: 9.1623\n",
      "Epoch 451/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.0294 - mean_squared_error: 12.7813 - val_loss: 9.7040 - val_mean_squared_error: 9.4556\n",
      "Epoch 452/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.0382 - mean_squared_error: 12.7897 - val_loss: 9.6998 - val_mean_squared_error: 9.4512\n",
      "Epoch 453/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.9631 - mean_squared_error: 12.7142 - val_loss: 9.9908 - val_mean_squared_error: 9.7419\n",
      "Epoch 454/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.0800 - mean_squared_error: 12.8312 - val_loss: 9.9109 - val_mean_squared_error: 9.6619\n",
      "Epoch 455/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.4690 - mean_squared_error: 13.2196 - val_loss: 9.8347 - val_mean_squared_error: 9.5850\n",
      "Epoch 456/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.2487 - mean_squared_error: 12.9989 - val_loss: 9.7078 - val_mean_squared_error: 9.4578\n",
      "Epoch 457/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.0712 - mean_squared_error: 12.8211 - val_loss: 9.5390 - val_mean_squared_error: 9.2888\n",
      "Epoch 458/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.0265 - mean_squared_error: 12.7761 - val_loss: 9.9247 - val_mean_squared_error: 9.6742\n",
      "Epoch 459/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.0919 - mean_squared_error: 12.8412 - val_loss: 9.9061 - val_mean_squared_error: 9.6553\n",
      "Epoch 460/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.1268 - mean_squared_error: 12.8759 - val_loss: 9.7850 - val_mean_squared_error: 9.5340\n",
      "Epoch 461/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.0555 - mean_squared_error: 12.8044 - val_loss: 10.0276 - val_mean_squared_error: 9.7765\n",
      "Epoch 462/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.2136 - mean_squared_error: 12.9623 - val_loss: 9.7016 - val_mean_squared_error: 9.4504\n",
      "Epoch 463/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.9370 - mean_squared_error: 12.6854 - val_loss: 9.6918 - val_mean_squared_error: 9.4401\n",
      "Epoch 464/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.6176 - mean_squared_error: 12.3657 - val_loss: 9.9923 - val_mean_squared_error: 9.7402\n",
      "Epoch 465/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.9921 - mean_squared_error: 12.7400 - val_loss: 10.2698 - val_mean_squared_error: 10.0177\n",
      "Epoch 466/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.9745 - mean_squared_error: 12.7223 - val_loss: 9.8040 - val_mean_squared_error: 9.5518\n",
      "Epoch 467/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.8144 - mean_squared_error: 12.5621 - val_loss: 9.7825 - val_mean_squared_error: 9.5300\n",
      "Epoch 468/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.7822 - mean_squared_error: 12.5296 - val_loss: 9.5691 - val_mean_squared_error: 9.3164\n",
      "Epoch 469/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.8116 - mean_squared_error: 12.5586 - val_loss: 10.6061 - val_mean_squared_error: 10.3529\n",
      "Epoch 470/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.8498 - mean_squared_error: 12.5964 - val_loss: 10.1419 - val_mean_squared_error: 9.8883\n",
      "Epoch 471/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.2078 - mean_squared_error: 12.9540 - val_loss: 9.6130 - val_mean_squared_error: 9.3590\n",
      "Epoch 472/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.9828 - mean_squared_error: 12.7288 - val_loss: 9.7095 - val_mean_squared_error: 9.4555\n",
      "Epoch 473/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.7910 - mean_squared_error: 12.5368 - val_loss: 9.8844 - val_mean_squared_error: 9.6302\n",
      "Epoch 474/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 13.0296 - mean_squared_error: 12.7753 - val_loss: 10.0963 - val_mean_squared_error: 9.8418\n",
      "Epoch 475/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.5177 - mean_squared_error: 12.2629 - val_loss: 10.3738 - val_mean_squared_error: 10.1189\n",
      "Epoch 476/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.4671 - mean_squared_error: 12.2117 - val_loss: 10.1130 - val_mean_squared_error: 9.8574\n",
      "Epoch 477/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.5102 - mean_squared_error: 12.2545 - val_loss: 9.9142 - val_mean_squared_error: 9.6585\n",
      "Epoch 478/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.4066 - mean_squared_error: 12.1507 - val_loss: 9.9055 - val_mean_squared_error: 9.6496\n",
      "Epoch 479/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.8147 - mean_squared_error: 12.5586 - val_loss: 10.3771 - val_mean_squared_error: 10.1210\n",
      "Epoch 480/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.5684 - mean_squared_error: 12.3123 - val_loss: 10.0444 - val_mean_squared_error: 9.7881\n",
      "Epoch 481/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.6998 - mean_squared_error: 12.4433 - val_loss: 10.6699 - val_mean_squared_error: 10.4131\n",
      "Epoch 482/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.9454 - mean_squared_error: 12.6885 - val_loss: 9.9421 - val_mean_squared_error: 9.6848\n",
      "Epoch 483/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.5305 - mean_squared_error: 12.2730 - val_loss: 9.8890 - val_mean_squared_error: 9.6312\n",
      "Epoch 484/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.4549 - mean_squared_error: 12.1968 - val_loss: 9.8803 - val_mean_squared_error: 9.6220\n",
      "Epoch 485/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.8181 - mean_squared_error: 12.5597 - val_loss: 9.4260 - val_mean_squared_error: 9.1674\n",
      "Epoch 486/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.8393 - mean_squared_error: 12.5810 - val_loss: 9.6411 - val_mean_squared_error: 9.3825\n",
      "Epoch 487/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.5536 - mean_squared_error: 12.2949 - val_loss: 10.0198 - val_mean_squared_error: 9.7610\n",
      "Epoch 488/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.4499 - mean_squared_error: 12.1912 - val_loss: 9.7904 - val_mean_squared_error: 9.5314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.5877 - mean_squared_error: 12.3284 - val_loss: 10.2102 - val_mean_squared_error: 9.9507\n",
      "Epoch 490/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.6361 - mean_squared_error: 12.3765 - val_loss: 10.4128 - val_mean_squared_error: 10.1530\n",
      "Epoch 491/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.4009 - mean_squared_error: 12.1411 - val_loss: 9.4323 - val_mean_squared_error: 9.1722\n",
      "Epoch 492/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.4920 - mean_squared_error: 12.2317 - val_loss: 10.0112 - val_mean_squared_error: 9.7510\n",
      "Epoch 493/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.3906 - mean_squared_error: 12.1302 - val_loss: 9.8346 - val_mean_squared_error: 9.5741\n",
      "Epoch 494/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.4387 - mean_squared_error: 12.1780 - val_loss: 9.8138 - val_mean_squared_error: 9.5531\n",
      "Epoch 495/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.4800 - mean_squared_error: 12.2191 - val_loss: 9.5962 - val_mean_squared_error: 9.3352\n",
      "Epoch 496/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.6283 - mean_squared_error: 12.3675 - val_loss: 9.4734 - val_mean_squared_error: 9.2125\n",
      "Epoch 497/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.4883 - mean_squared_error: 12.2273 - val_loss: 9.7182 - val_mean_squared_error: 9.4569\n",
      "Epoch 498/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.4667 - mean_squared_error: 12.2053 - val_loss: 9.9040 - val_mean_squared_error: 9.6425\n",
      "Epoch 499/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.4116 - mean_squared_error: 12.1501 - val_loss: 9.9234 - val_mean_squared_error: 9.6617\n",
      "Epoch 500/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.4297 - mean_squared_error: 12.1680 - val_loss: 9.4864 - val_mean_squared_error: 9.2245\n",
      "Epoch 501/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.5287 - mean_squared_error: 12.2667 - val_loss: 9.6777 - val_mean_squared_error: 9.4157\n",
      "Epoch 502/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.3079 - mean_squared_error: 12.0456 - val_loss: 9.6390 - val_mean_squared_error: 9.3766\n",
      "Epoch 503/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.1736 - mean_squared_error: 11.9112 - val_loss: 9.5226 - val_mean_squared_error: 9.2602\n",
      "Epoch 504/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.3408 - mean_squared_error: 12.0779 - val_loss: 9.8782 - val_mean_squared_error: 9.6152\n",
      "Epoch 505/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.1919 - mean_squared_error: 11.9287 - val_loss: 10.5177 - val_mean_squared_error: 10.2543\n",
      "Epoch 506/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.3234 - mean_squared_error: 12.0598 - val_loss: 9.7972 - val_mean_squared_error: 9.5332\n",
      "Epoch 507/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.3420 - mean_squared_error: 12.0777 - val_loss: 9.3383 - val_mean_squared_error: 9.0738\n",
      "Epoch 508/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.0737 - mean_squared_error: 11.8089 - val_loss: 9.6227 - val_mean_squared_error: 9.3577\n",
      "Epoch 509/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.2027 - mean_squared_error: 11.9377 - val_loss: 9.8672 - val_mean_squared_error: 9.6019\n",
      "Epoch 510/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.3911 - mean_squared_error: 12.1258 - val_loss: 9.4883 - val_mean_squared_error: 9.2231\n",
      "Epoch 511/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.5742 - mean_squared_error: 12.3091 - val_loss: 9.7502 - val_mean_squared_error: 9.4850\n",
      "Epoch 512/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.4992 - mean_squared_error: 12.2337 - val_loss: 9.3340 - val_mean_squared_error: 9.0683\n",
      "Epoch 513/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.3241 - mean_squared_error: 12.0586 - val_loss: 9.4684 - val_mean_squared_error: 9.2029\n",
      "Epoch 514/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.1212 - mean_squared_error: 11.8555 - val_loss: 10.1737 - val_mean_squared_error: 9.9077\n",
      "Epoch 515/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.3610 - mean_squared_error: 12.0950 - val_loss: 9.8290 - val_mean_squared_error: 9.5630\n",
      "Epoch 516/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.1535 - mean_squared_error: 11.8875 - val_loss: 9.9787 - val_mean_squared_error: 9.7126\n",
      "Epoch 517/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.0297 - mean_squared_error: 11.7638 - val_loss: 9.4497 - val_mean_squared_error: 9.1839\n",
      "Epoch 518/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.1234 - mean_squared_error: 11.8573 - val_loss: 9.8662 - val_mean_squared_error: 9.6001\n",
      "Epoch 519/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.1281 - mean_squared_error: 11.8619 - val_loss: 9.9384 - val_mean_squared_error: 9.6723\n",
      "Epoch 520/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.1250 - mean_squared_error: 11.8588 - val_loss: 9.8637 - val_mean_squared_error: 9.5975\n",
      "Epoch 521/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.8882 - mean_squared_error: 11.6220 - val_loss: 10.0047 - val_mean_squared_error: 9.7384\n",
      "Epoch 522/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.5945 - mean_squared_error: 12.3281 - val_loss: 10.1183 - val_mean_squared_error: 9.8518\n",
      "Epoch 523/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.0741 - mean_squared_error: 11.8073 - val_loss: 9.9709 - val_mean_squared_error: 9.7038\n",
      "Epoch 524/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.9229 - mean_squared_error: 11.6553 - val_loss: 9.8589 - val_mean_squared_error: 9.5909\n",
      "Epoch 525/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.5849 - mean_squared_error: 11.3169 - val_loss: 9.5187 - val_mean_squared_error: 9.2506\n",
      "Epoch 526/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.9548 - mean_squared_error: 11.6865 - val_loss: 9.9806 - val_mean_squared_error: 9.7123\n",
      "Epoch 527/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.9764 - mean_squared_error: 11.7080 - val_loss: 9.8809 - val_mean_squared_error: 9.6128\n",
      "Epoch 528/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.9441 - mean_squared_error: 11.6757 - val_loss: 9.6673 - val_mean_squared_error: 9.3987\n",
      "Epoch 529/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.9741 - mean_squared_error: 11.7054 - val_loss: 9.7182 - val_mean_squared_error: 9.4493\n",
      "Epoch 530/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.9838 - mean_squared_error: 11.7149 - val_loss: 10.1331 - val_mean_squared_error: 9.8644\n",
      "Epoch 531/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.5690 - mean_squared_error: 11.3000 - val_loss: 10.1128 - val_mean_squared_error: 9.8436\n",
      "Epoch 532/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.7578 - mean_squared_error: 11.4884 - val_loss: 10.1267 - val_mean_squared_error: 9.8568\n",
      "Epoch 533/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.7553 - mean_squared_error: 11.4853 - val_loss: 10.0969 - val_mean_squared_error: 9.8268\n",
      "Epoch 534/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.0715 - mean_squared_error: 11.8013 - val_loss: 10.0201 - val_mean_squared_error: 9.7498\n",
      "Epoch 535/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.9591 - mean_squared_error: 11.6888 - val_loss: 10.1173 - val_mean_squared_error: 9.8469\n",
      "Epoch 536/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.6919 - mean_squared_error: 11.4214 - val_loss: 10.5533 - val_mean_squared_error: 10.2829\n",
      "Epoch 537/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.6423 - mean_squared_error: 11.3719 - val_loss: 9.6441 - val_mean_squared_error: 9.3736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 538/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.9788 - mean_squared_error: 11.7082 - val_loss: 9.9884 - val_mean_squared_error: 9.7176\n",
      "Epoch 539/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.9392 - mean_squared_error: 11.6683 - val_loss: 9.5999 - val_mean_squared_error: 9.3290\n",
      "Epoch 540/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.2911 - mean_squared_error: 12.0199 - val_loss: 10.1980 - val_mean_squared_error: 9.9264\n",
      "Epoch 541/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.9281 - mean_squared_error: 11.6566 - val_loss: 9.5621 - val_mean_squared_error: 9.2906\n",
      "Epoch 542/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.8335 - mean_squared_error: 11.5616 - val_loss: 10.1129 - val_mean_squared_error: 9.8409\n",
      "Epoch 543/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.8673 - mean_squared_error: 11.5954 - val_loss: 9.8988 - val_mean_squared_error: 9.6267\n",
      "Epoch 544/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.5007 - mean_squared_error: 11.2284 - val_loss: 9.4295 - val_mean_squared_error: 9.1572\n",
      "Epoch 545/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.6351 - mean_squared_error: 11.3628 - val_loss: 9.8959 - val_mean_squared_error: 9.6236\n",
      "Epoch 546/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.4942 - mean_squared_error: 11.2219 - val_loss: 10.5312 - val_mean_squared_error: 10.2589\n",
      "Epoch 547/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.8103 - mean_squared_error: 11.5378 - val_loss: 10.3283 - val_mean_squared_error: 10.0559\n",
      "Epoch 548/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.7594 - mean_squared_error: 11.4868 - val_loss: 9.8627 - val_mean_squared_error: 9.5900\n",
      "Epoch 549/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.8103 - mean_squared_error: 11.5376 - val_loss: 9.8444 - val_mean_squared_error: 9.5716\n",
      "Epoch 550/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.5454 - mean_squared_error: 11.2725 - val_loss: 9.4239 - val_mean_squared_error: 9.1510\n",
      "Epoch 551/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.5704 - mean_squared_error: 11.2976 - val_loss: 9.5555 - val_mean_squared_error: 9.2829\n",
      "Epoch 552/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.9550 - mean_squared_error: 11.6819 - val_loss: 10.1270 - val_mean_squared_error: 9.8537\n",
      "Epoch 553/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.8706 - mean_squared_error: 11.5973 - val_loss: 10.2612 - val_mean_squared_error: 9.9875\n",
      "Epoch 554/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 12.0136 - mean_squared_error: 11.7396 - val_loss: 10.4136 - val_mean_squared_error: 10.1392\n",
      "Epoch 555/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.8274 - mean_squared_error: 11.5529 - val_loss: 10.2092 - val_mean_squared_error: 9.9346\n",
      "Epoch 556/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.5261 - mean_squared_error: 11.2515 - val_loss: 10.0372 - val_mean_squared_error: 9.7625\n",
      "Epoch 557/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.4663 - mean_squared_error: 11.1915 - val_loss: 10.0569 - val_mean_squared_error: 9.7819\n",
      "Epoch 558/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.8949 - mean_squared_error: 11.6200 - val_loss: 10.2219 - val_mean_squared_error: 9.9468\n",
      "Epoch 559/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.1549 - mean_squared_error: 10.8795 - val_loss: 10.1439 - val_mean_squared_error: 9.8685\n",
      "Epoch 560/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.7718 - mean_squared_error: 11.4963 - val_loss: 9.7886 - val_mean_squared_error: 9.5130\n",
      "Epoch 561/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.2868 - mean_squared_error: 11.0108 - val_loss: 9.9506 - val_mean_squared_error: 9.6745\n",
      "Epoch 562/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.4047 - mean_squared_error: 11.1283 - val_loss: 9.9751 - val_mean_squared_error: 9.6989\n",
      "Epoch 563/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.5426 - mean_squared_error: 11.2662 - val_loss: 9.8309 - val_mean_squared_error: 9.5546\n",
      "Epoch 564/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.3270 - mean_squared_error: 11.0506 - val_loss: 9.7405 - val_mean_squared_error: 9.4640\n",
      "Epoch 565/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.6613 - mean_squared_error: 11.3844 - val_loss: 10.4957 - val_mean_squared_error: 10.2185\n",
      "Epoch 566/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.4868 - mean_squared_error: 11.2095 - val_loss: 9.9918 - val_mean_squared_error: 9.7143\n",
      "Epoch 567/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.6185 - mean_squared_error: 11.3411 - val_loss: 9.9770 - val_mean_squared_error: 9.6994\n",
      "Epoch 568/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.3615 - mean_squared_error: 11.0838 - val_loss: 10.0264 - val_mean_squared_error: 9.7486\n",
      "Epoch 569/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.4727 - mean_squared_error: 11.1949 - val_loss: 10.4186 - val_mean_squared_error: 10.1407\n",
      "Epoch 570/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.3707 - mean_squared_error: 11.0929 - val_loss: 9.6852 - val_mean_squared_error: 9.4076\n",
      "Epoch 571/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.2252 - mean_squared_error: 10.9472 - val_loss: 9.8325 - val_mean_squared_error: 9.5544\n",
      "Epoch 572/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.7236 - mean_squared_error: 11.4456 - val_loss: 9.8904 - val_mean_squared_error: 9.6124\n",
      "Epoch 573/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.5831 - mean_squared_error: 11.3048 - val_loss: 9.8821 - val_mean_squared_error: 9.6040\n",
      "Epoch 574/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.1256 - mean_squared_error: 10.8473 - val_loss: 9.4584 - val_mean_squared_error: 9.1797\n",
      "Epoch 575/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.3555 - mean_squared_error: 11.0767 - val_loss: 9.6588 - val_mean_squared_error: 9.3798\n",
      "Epoch 576/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.4251 - mean_squared_error: 11.1463 - val_loss: 9.4764 - val_mean_squared_error: 9.1975\n",
      "Epoch 577/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.1126 - mean_squared_error: 10.8336 - val_loss: 9.9363 - val_mean_squared_error: 9.6570\n",
      "Epoch 578/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.2147 - mean_squared_error: 10.9352 - val_loss: 10.1785 - val_mean_squared_error: 9.8987\n",
      "Epoch 579/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.2851 - mean_squared_error: 11.0054 - val_loss: 9.7890 - val_mean_squared_error: 9.5090\n",
      "Epoch 580/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.3154 - mean_squared_error: 11.0352 - val_loss: 9.7439 - val_mean_squared_error: 9.4636\n",
      "Epoch 581/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.2235 - mean_squared_error: 10.9429 - val_loss: 9.6210 - val_mean_squared_error: 9.3404\n",
      "Epoch 582/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.6026 - mean_squared_error: 11.3220 - val_loss: 10.0890 - val_mean_squared_error: 9.8082\n",
      "Epoch 583/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.2380 - mean_squared_error: 10.9569 - val_loss: 9.6157 - val_mean_squared_error: 9.3344\n",
      "Epoch 584/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.2024 - mean_squared_error: 10.9211 - val_loss: 9.7634 - val_mean_squared_error: 9.4823\n",
      "Epoch 585/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.3379 - mean_squared_error: 11.0568 - val_loss: 9.6440 - val_mean_squared_error: 9.3628\n",
      "Epoch 586/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.4102 - mean_squared_error: 11.1288 - val_loss: 10.1883 - val_mean_squared_error: 9.9069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 587/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.2071 - mean_squared_error: 10.9257 - val_loss: 9.9621 - val_mean_squared_error: 9.6805\n",
      "Epoch 588/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.9961 - mean_squared_error: 10.7144 - val_loss: 10.3331 - val_mean_squared_error: 10.0511\n",
      "Epoch 589/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.3683 - mean_squared_error: 11.0864 - val_loss: 9.7344 - val_mean_squared_error: 9.4526\n",
      "Epoch 590/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.3837 - mean_squared_error: 11.1016 - val_loss: 9.9832 - val_mean_squared_error: 9.7006\n",
      "Epoch 591/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.0675 - mean_squared_error: 10.7849 - val_loss: 9.7291 - val_mean_squared_error: 9.4465\n",
      "Epoch 592/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.3030 - mean_squared_error: 11.0202 - val_loss: 9.8643 - val_mean_squared_error: 9.5816\n",
      "Epoch 593/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.1645 - mean_squared_error: 10.8817 - val_loss: 9.6289 - val_mean_squared_error: 9.3462\n",
      "Epoch 594/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.0023 - mean_squared_error: 10.7195 - val_loss: 9.7284 - val_mean_squared_error: 9.4458\n",
      "Epoch 595/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.0083 - mean_squared_error: 10.7255 - val_loss: 10.2895 - val_mean_squared_error: 10.0065\n",
      "Epoch 596/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.0243 - mean_squared_error: 10.7411 - val_loss: 10.4905 - val_mean_squared_error: 10.2072\n",
      "Epoch 597/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.6312 - mean_squared_error: 10.3477 - val_loss: 9.6181 - val_mean_squared_error: 9.3344\n",
      "Epoch 598/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.8799 - mean_squared_error: 10.5963 - val_loss: 9.7409 - val_mean_squared_error: 9.4575\n",
      "Epoch 599/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.1982 - mean_squared_error: 10.9148 - val_loss: 9.3742 - val_mean_squared_error: 9.0909\n",
      "Epoch 600/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.0816 - mean_squared_error: 10.7983 - val_loss: 10.2369 - val_mean_squared_error: 9.9535\n",
      "Epoch 601/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.9678 - mean_squared_error: 10.6845 - val_loss: 9.7078 - val_mean_squared_error: 9.4243\n",
      "Epoch 602/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.0244 - mean_squared_error: 10.7409 - val_loss: 9.4097 - val_mean_squared_error: 9.1261\n",
      "Epoch 603/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.1040 - mean_squared_error: 10.8204 - val_loss: 9.2871 - val_mean_squared_error: 9.0031\n",
      "Epoch 604/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.1163 - mean_squared_error: 10.8325 - val_loss: 9.6668 - val_mean_squared_error: 9.3828\n",
      "Epoch 605/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.0566 - mean_squared_error: 10.7724 - val_loss: 9.4798 - val_mean_squared_error: 9.1955\n",
      "Epoch 606/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.0511 - mean_squared_error: 10.7665 - val_loss: 9.3091 - val_mean_squared_error: 9.0243\n",
      "Epoch 607/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.8738 - mean_squared_error: 10.5889 - val_loss: 10.0808 - val_mean_squared_error: 9.7959\n",
      "Epoch 608/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.0135 - mean_squared_error: 10.7282 - val_loss: 9.7283 - val_mean_squared_error: 9.4428\n",
      "Epoch 609/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.8779 - mean_squared_error: 10.5923 - val_loss: 10.0941 - val_mean_squared_error: 9.8085\n",
      "Epoch 610/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.4885 - mean_squared_error: 10.2027 - val_loss: 9.7929 - val_mean_squared_error: 9.5072\n",
      "Epoch 611/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.1212 - mean_squared_error: 10.8357 - val_loss: 9.8904 - val_mean_squared_error: 9.6047\n",
      "Epoch 612/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.1187 - mean_squared_error: 10.8327 - val_loss: 10.1232 - val_mean_squared_error: 9.8371\n",
      "Epoch 613/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.8528 - mean_squared_error: 10.5668 - val_loss: 10.2093 - val_mean_squared_error: 9.9232\n",
      "Epoch 614/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.8695 - mean_squared_error: 10.5832 - val_loss: 9.9207 - val_mean_squared_error: 9.6343\n",
      "Epoch 615/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.0141 - mean_squared_error: 10.7276 - val_loss: 9.8340 - val_mean_squared_error: 9.5473\n",
      "Epoch 616/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.0497 - mean_squared_error: 10.7628 - val_loss: 9.9883 - val_mean_squared_error: 9.7011\n",
      "Epoch 617/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.4825 - mean_squared_error: 10.1950 - val_loss: 10.2676 - val_mean_squared_error: 9.9797\n",
      "Epoch 618/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.4442 - mean_squared_error: 10.1562 - val_loss: 9.7510 - val_mean_squared_error: 9.4629\n",
      "Epoch 619/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.6408 - mean_squared_error: 10.3526 - val_loss: 10.0927 - val_mean_squared_error: 9.8042\n",
      "Epoch 620/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.6058 - mean_squared_error: 10.3170 - val_loss: 10.0457 - val_mean_squared_error: 9.7570\n",
      "Epoch 621/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 11.0562 - mean_squared_error: 10.7673 - val_loss: 9.9438 - val_mean_squared_error: 9.6546\n",
      "Epoch 622/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.7481 - mean_squared_error: 10.4589 - val_loss: 10.0117 - val_mean_squared_error: 9.7224\n",
      "Epoch 623/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.8486 - mean_squared_error: 10.5593 - val_loss: 10.8763 - val_mean_squared_error: 10.5871\n",
      "Epoch 624/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.8161 - mean_squared_error: 10.5269 - val_loss: 9.9613 - val_mean_squared_error: 9.6720\n",
      "Epoch 625/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.9329 - mean_squared_error: 10.6436 - val_loss: 10.3870 - val_mean_squared_error: 10.0979\n",
      "Epoch 626/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.8300 - mean_squared_error: 10.5405 - val_loss: 9.5860 - val_mean_squared_error: 9.2961\n",
      "Epoch 627/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.6273 - mean_squared_error: 10.3375 - val_loss: 10.1600 - val_mean_squared_error: 9.8700\n",
      "Epoch 628/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.8028 - mean_squared_error: 10.5124 - val_loss: 9.7089 - val_mean_squared_error: 9.4180\n",
      "Epoch 629/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.7322 - mean_squared_error: 10.4412 - val_loss: 9.9402 - val_mean_squared_error: 9.6491\n",
      "Epoch 630/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.2769 - mean_squared_error: 9.9858 - val_loss: 10.0932 - val_mean_squared_error: 9.8021\n",
      "Epoch 631/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.3509 - mean_squared_error: 10.0597 - val_loss: 9.9737 - val_mean_squared_error: 9.6822\n",
      "Epoch 632/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.8234 - mean_squared_error: 10.5319 - val_loss: 9.9771 - val_mean_squared_error: 9.6857\n",
      "Epoch 633/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.7108 - mean_squared_error: 10.4191 - val_loss: 9.2656 - val_mean_squared_error: 8.9736\n",
      "Epoch 634/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.4768 - mean_squared_error: 10.1846 - val_loss: 9.9017 - val_mean_squared_error: 9.6093\n",
      "Epoch 635/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.9600 - mean_squared_error: 10.6675 - val_loss: 10.3412 - val_mean_squared_error: 10.0485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 636/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.4167 - mean_squared_error: 10.1239 - val_loss: 9.6639 - val_mean_squared_error: 9.3709\n",
      "Epoch 637/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.6168 - mean_squared_error: 10.3237 - val_loss: 9.9457 - val_mean_squared_error: 9.6525\n",
      "Epoch 638/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.6798 - mean_squared_error: 10.3864 - val_loss: 10.4066 - val_mean_squared_error: 10.1130\n",
      "Epoch 639/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.6970 - mean_squared_error: 10.4037 - val_loss: 10.2688 - val_mean_squared_error: 9.9758\n",
      "Epoch 640/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.4318 - mean_squared_error: 10.1388 - val_loss: 9.7000 - val_mean_squared_error: 9.4069\n",
      "Epoch 641/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.4128 - mean_squared_error: 10.1197 - val_loss: 10.1241 - val_mean_squared_error: 9.8308\n",
      "Epoch 642/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.5082 - mean_squared_error: 10.2148 - val_loss: 10.2434 - val_mean_squared_error: 9.9499\n",
      "Epoch 643/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.7929 - mean_squared_error: 10.4992 - val_loss: 10.0895 - val_mean_squared_error: 9.7958\n",
      "Epoch 644/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.2963 - mean_squared_error: 10.0025 - val_loss: 9.7884 - val_mean_squared_error: 9.4943\n",
      "Epoch 645/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.5881 - mean_squared_error: 10.2939 - val_loss: 10.1388 - val_mean_squared_error: 9.8446\n",
      "Epoch 646/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.6357 - mean_squared_error: 10.3415 - val_loss: 10.8906 - val_mean_squared_error: 10.5965\n",
      "Epoch 647/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.7324 - mean_squared_error: 10.4383 - val_loss: 10.1958 - val_mean_squared_error: 9.9014\n",
      "Epoch 648/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.2528 - mean_squared_error: 9.9581 - val_loss: 9.7905 - val_mean_squared_error: 9.4956\n",
      "Epoch 649/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.6360 - mean_squared_error: 10.3410 - val_loss: 9.9084 - val_mean_squared_error: 9.6134\n",
      "Epoch 650/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.3941 - mean_squared_error: 10.0992 - val_loss: 10.1379 - val_mean_squared_error: 9.8430\n",
      "Epoch 651/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.3082 - mean_squared_error: 10.0133 - val_loss: 10.5271 - val_mean_squared_error: 10.2321\n",
      "Epoch 652/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.4980 - mean_squared_error: 10.2029 - val_loss: 9.9558 - val_mean_squared_error: 9.6608\n",
      "Epoch 653/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.6493 - mean_squared_error: 10.3542 - val_loss: 9.6940 - val_mean_squared_error: 9.3987\n",
      "Epoch 654/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.2465 - mean_squared_error: 9.9509 - val_loss: 10.0990 - val_mean_squared_error: 9.8032\n",
      "Epoch 655/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.4081 - mean_squared_error: 10.1123 - val_loss: 10.2352 - val_mean_squared_error: 9.9392\n",
      "Epoch 656/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.2466 - mean_squared_error: 9.9505 - val_loss: 9.7686 - val_mean_squared_error: 9.4725\n",
      "Epoch 657/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.1900 - mean_squared_error: 9.8939 - val_loss: 9.5617 - val_mean_squared_error: 9.2657\n",
      "Epoch 658/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.2230 - mean_squared_error: 9.9269 - val_loss: 10.5466 - val_mean_squared_error: 10.2504\n",
      "Epoch 659/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.1362 - mean_squared_error: 9.8399 - val_loss: 10.1660 - val_mean_squared_error: 9.8696\n",
      "Epoch 660/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.5566 - mean_squared_error: 10.2602 - val_loss: 9.8910 - val_mean_squared_error: 9.5946\n",
      "Epoch 661/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.1755 - mean_squared_error: 9.8789 - val_loss: 9.6505 - val_mean_squared_error: 9.3538\n",
      "Epoch 662/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 9.9326 - mean_squared_error: 9.6357 - val_loss: 9.5510 - val_mean_squared_error: 9.2539\n",
      "Epoch 663/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.1132 - mean_squared_error: 9.8158 - val_loss: 9.6011 - val_mean_squared_error: 9.3036\n",
      "Epoch 664/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.5054 - mean_squared_error: 10.2076 - val_loss: 10.0270 - val_mean_squared_error: 9.7290\n",
      "Epoch 665/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.3743 - mean_squared_error: 10.0762 - val_loss: 10.6004 - val_mean_squared_error: 10.3025\n",
      "Epoch 666/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.3454 - mean_squared_error: 10.0471 - val_loss: 9.6945 - val_mean_squared_error: 9.3959\n",
      "Epoch 667/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.1797 - mean_squared_error: 9.8812 - val_loss: 9.7660 - val_mean_squared_error: 9.4673\n",
      "Epoch 668/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 9.9038 - mean_squared_error: 9.6051 - val_loss: 10.0404 - val_mean_squared_error: 9.7414\n",
      "Epoch 669/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.3665 - mean_squared_error: 10.0675 - val_loss: 10.3531 - val_mean_squared_error: 10.0543\n",
      "Epoch 670/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.4359 - mean_squared_error: 10.1368 - val_loss: 10.4286 - val_mean_squared_error: 10.1295\n",
      "Epoch 671/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.3368 - mean_squared_error: 10.0374 - val_loss: 10.3986 - val_mean_squared_error: 10.0990\n",
      "Epoch 672/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 9.9019 - mean_squared_error: 9.6021 - val_loss: 9.8694 - val_mean_squared_error: 9.5694\n",
      "Epoch 673/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.1339 - mean_squared_error: 9.8340 - val_loss: 10.2283 - val_mean_squared_error: 9.9285\n",
      "Epoch 674/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.2724 - mean_squared_error: 9.9726 - val_loss: 9.8293 - val_mean_squared_error: 9.5294\n",
      "Epoch 675/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.5904 - mean_squared_error: 10.2902 - val_loss: 9.9788 - val_mean_squared_error: 9.6783\n",
      "Epoch 676/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.2813 - mean_squared_error: 9.9808 - val_loss: 9.7058 - val_mean_squared_error: 9.4052\n",
      "Epoch 677/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.1487 - mean_squared_error: 9.8481 - val_loss: 10.0079 - val_mean_squared_error: 9.7072\n",
      "Epoch 678/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.4499 - mean_squared_error: 10.1490 - val_loss: 9.7368 - val_mean_squared_error: 9.4358\n",
      "Epoch 679/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.4664 - mean_squared_error: 10.1652 - val_loss: 9.8318 - val_mean_squared_error: 9.5305\n",
      "Epoch 680/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.2084 - mean_squared_error: 9.9071 - val_loss: 10.4700 - val_mean_squared_error: 10.1687\n",
      "Epoch 681/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.1129 - mean_squared_error: 9.8114 - val_loss: 9.7058 - val_mean_squared_error: 9.4043\n",
      "Epoch 682/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.2049 - mean_squared_error: 9.9035 - val_loss: 10.2999 - val_mean_squared_error: 9.9986\n",
      "Epoch 683/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.2419 - mean_squared_error: 9.9405 - val_loss: 10.4252 - val_mean_squared_error: 10.1237\n",
      "Epoch 684/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.3612 - mean_squared_error: 10.0596 - val_loss: 10.0659 - val_mean_squared_error: 9.7639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 9.9382 - mean_squared_error: 9.6363 - val_loss: 9.4854 - val_mean_squared_error: 9.1836\n",
      "Epoch 686/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.4425 - mean_squared_error: 10.1404 - val_loss: 10.1147 - val_mean_squared_error: 9.8123\n",
      "Epoch 687/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 9.8767 - mean_squared_error: 9.5743 - val_loss: 10.2922 - val_mean_squared_error: 9.9897\n",
      "Epoch 688/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.0112 - mean_squared_error: 9.7087 - val_loss: 10.0288 - val_mean_squared_error: 9.7262\n",
      "Epoch 689/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.6032 - mean_squared_error: 10.3004 - val_loss: 10.0987 - val_mean_squared_error: 9.7954\n",
      "Epoch 690/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 9.9778 - mean_squared_error: 9.6744 - val_loss: 10.3993 - val_mean_squared_error: 10.0956\n",
      "Epoch 691/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.6771 - mean_squared_error: 10.3734 - val_loss: 9.7426 - val_mean_squared_error: 9.4390\n",
      "Epoch 692/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.2369 - mean_squared_error: 9.9330 - val_loss: 9.7750 - val_mean_squared_error: 9.4708\n",
      "Epoch 693/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.0632 - mean_squared_error: 9.7589 - val_loss: 10.3966 - val_mean_squared_error: 10.0921\n",
      "Epoch 694/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.1130 - mean_squared_error: 9.8084 - val_loss: 10.7928 - val_mean_squared_error: 10.4878\n",
      "Epoch 695/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.1768 - mean_squared_error: 9.8719 - val_loss: 9.7049 - val_mean_squared_error: 9.4002\n",
      "Epoch 696/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 9.9837 - mean_squared_error: 9.6789 - val_loss: 9.5490 - val_mean_squared_error: 9.2443\n",
      "Epoch 697/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.1084 - mean_squared_error: 9.8036 - val_loss: 9.9074 - val_mean_squared_error: 9.6026\n",
      "Epoch 698/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 9.7068 - mean_squared_error: 9.4018 - val_loss: 10.3740 - val_mean_squared_error: 10.0687\n",
      "Epoch 699/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.0072 - mean_squared_error: 9.7017 - val_loss: 10.2641 - val_mean_squared_error: 9.9588\n",
      "Epoch 700/700\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 10.1091 - mean_squared_error: 9.8036 - val_loss: 10.5688 - val_mean_squared_error: 10.2634\n"
     ]
    }
   ],
   "source": [
    "print(x_train_reg.shape)\n",
    "model = tf.keras.Sequential()\n",
    "# kernel_regularizer=regularizers.l2(0.0005)\n",
    "model.add(Dense(128, input_dim=8, activation='relu', kernel_regularizer=regularizers.l2(0.00005)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.00005)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.00005)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.00005)))\n",
    "model.add(Dropout(0.1))\n",
    "# model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.00002)))\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# learning_rate = 0.1\n",
    "# global_step = tf.Variable(0, trainable=False)\n",
    "# decayed_lr = tf.train.exponential_decay(learning_rate, global_step, 2, 0.99, staircase=True)\n",
    "optim = tf.keras.optimizers.Adam(0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer=optim, metrics=['mean_squared_error'])\n",
    "history = model.fit(x_train_reg, y_train_reg.values.ravel(), epochs=700, batch_size=100, validation_data = (x_val_reg, y_val_reg.values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "early-bacon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(history.history['loss'], label='MAE (training data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('MAE for RPC efficiency prediction')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "expected-health",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error Validation: 10.26\n",
      "Root mean squared error Validation: 3.20\n",
      "Coefficient of determination (R2) Validation: 0.8238\n"
     ]
    }
   ],
   "source": [
    "val_y_pred = model.predict(x_val_reg)\n",
    "print('Mean squared error Validation: %.2f' % mean_squared_error(y_val_reg, val_y_pred))\n",
    "print('Root mean squared error Validation: %.2f' % sqrt(mean_squared_error(y_val_reg, val_y_pred)))\n",
    "# print('Coefficient of determination Validation: %.2f' % r2_score(y_val_reg, val_y_pred))\n",
    "print('Coefficient of determination (R2) Validation: %.4f' % r2_score(y_val_reg,val_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dee099f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "difference = (y_val_reg-val_y_pred).abs()\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.hist(difference, bins=50, range=[0, 60])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c8e5688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58038, 16)\n",
      "      run         chamber  wheel  sector  station  avg_cluster_size  \\\n",
      "0  321475   W-2_RB1in_S01     -2       1        1           1.88926   \n",
      "1  321475  W-2_RB1out_S01     -2       1        1           1.83989   \n",
      "2  321475   W-2_RB2in_S01     -2       1        2           1.99387   \n",
      "3  321475  W-2_RB2out_S01     -2       1        2           1.85097   \n",
      "4  321475    W-2_RB3+_S01     -2       1        3           1.86637   \n",
      "\n",
      "   occupancy  avg_bx_dist  avg_no_of_clusters  avg_multiplicity  lumisections  \\\n",
      "0      85729     0.006567             1.00394           1.89670          2091   \n",
      "1      75899     0.006860             1.00387           1.84701          2091   \n",
      "2      91026     0.006966             1.00391           2.00167          2091   \n",
      "3      78148     0.011014             1.00278           1.85611          2091   \n",
      "4      36803     0.004361             1.00107           1.86836          2091   \n",
      "\n",
      "  type  avg_efficiency  contains_zero_roll  rolls_count  fid_eff_ch_level  \n",
      "0  Col       53.435921                   0            2         96.271114  \n",
      "1  Col       58.874134                   0            2         97.754410  \n",
      "2  Col       81.179764                   0            2         98.231281  \n",
      "3  Col       84.280207                   0            3         98.210457  \n",
      "4  Col       92.292915                   0            2         98.584396  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7IAAAI/CAYAAABK2eVGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgLElEQVR4nO3dfbCmdX3f8c+3bKTmQWNk4xAWuiSStMI0pOxQ2jQZW5JKNBNIR5tlmkgbO0RHp7FNp4XkD9POMKNtEhtnIikRCqapSn2ITNU0VjOxncGHVamASl2VyMoWiFpDm2gCfvvHubY9LIdd3HM453zPvl4z95zr/l3Xde/vdi4W3l4Pp7o7AAAAMMWf2+oJAAAAwNdDyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACj7NrqCZyo0047rffu3bvV0wAAAOAJ8OEPf/gPu3v3WuvGhuzevXtz4MCBrZ4GAAAAT4Cq+oPHWufSYgAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKPs2uoJAAAA8Eh7r3rHMdff/crnbdJMtidnZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRjhuyVXVDVd1fVXesGntTVd22vO6uqtuW8b1V9Ser1v36qn0uqKrbq+pgVb2mqmoZP3X5vINV9YGq2rvxXxMAAICd4vGckb0xySWrB7r7J7r7/O4+P8lbkrx11epPH1nX3S9eNX5tkiuTnLO8jnzmi5J8qbufmeTVSV51Il8EAACAk8NxQ7a735fki2utW86q/t0kbzjWZ1TV6Ume0t23dncneX2Sy5bVlya5aVl+c5KLj5ytBQAAgKOt9x7ZH0hyX3d/atXY2VX10ar6/ar6gWXsjCSHVm1zaBk7su6eJOnuh5J8OcnT1zkvAAAAdqhd69z/8jzybOzhJGd19xeq6oIkv11V5yZZ6wxrLz+Pte4RqurKrFyenLPOOuuEJw0AAMBcJ3xGtqp2Jfk7Sd50ZKy7v9rdX1iWP5zk00m+OytnYPes2n1PknuX5UNJzlz1mU/NY1zK3N3Xdfe+7t63e/fuE506AAAAg63n0uIfSvLJ7v5/lwxX1e6qOmVZ/s6sPNTpM919OMmDVXXRcv/rC5O8fdntliRXLMvPT/Le5T5aAAAAeJTH8+t33pDk1iTfU1WHqupFy6r9efRDnn4wyceq6r9n5cFNL+7uI2dXX5LkdUkOZuVM7buW8euTPL2qDib5J0muWsf3AQAAYIc77j2y3X35Y4z//TXG3pKVX8ez1vYHkpy3xvhXkrzgePMAAACAZP1PLQYAAIBNJWQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYJTjhmxV3VBV91fVHavGfrGqPl9Vty2v565ad3VVHayqu6rqOavGL6iq25d1r6mqWsZPrao3LeMfqKq9G/wdAQAA2EEezxnZG5Ncssb4q7v7/OX1ziSpqmcl2Z/k3GWf11bVKcv21ya5Msk5y+vIZ74oyZe6+5lJXp3kVSf4XQAAADgJHDdku/t9Sb74OD/v0iRv7O6vdvdnkxxMcmFVnZ7kKd19a3d3ktcnuWzVPjcty29OcvGRs7UAAABwtPXcI/uyqvrYcunx05axM5Lcs2qbQ8vYGcvy0eOP2Ke7H0ry5SRPX8e8AAAA2MFONGSvTfJdSc5PcjjJLy/ja51J7WOMH2ufR6mqK6vqQFUdeOCBB76uCQMAALAznFDIdvd93f1wd38tyW8kuXBZdSjJmas23ZPk3mV8zxrjj9inqnYleWoe41Lm7r6uu/d1977du3efyNQBAAAY7oRCdrnn9YgfT3Lkica3JNm/PIn47Kw81OmD3X04yYNVddFy/+sLk7x91T5XLMvPT/Le5T5aAAAAeJRdx9ugqt6Q5NlJTquqQ0lekeTZVXV+Vi4BvjvJzyRJd99ZVTcn+XiSh5K8tLsfXj7qJVl5AvKTk7xreSXJ9Ul+s6oOZuVM7P4N+F4AAADsUMcN2e6+fI3h64+x/TVJrllj/ECS89YY/0qSFxxvHgAAAJCs76nFAAAAsOmELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMctyQraobqur+qrpj1di/rqpPVtXHquptVfWty/jeqvqTqrptef36qn0uqKrbq+pgVb2mqmoZP7Wq3rSMf6Cq9m781wQAAGCneDxnZG9McslRY+9Ocl53/+Uk/yPJ1avWfbq7z19eL141fm2SK5Ocs7yOfOaLknypu5+Z5NVJXvV1fwsAAABOGscN2e5+X5IvHjX2u9390PL2/Un2HOszqur0JE/p7lu7u5O8Pslly+pLk9y0LL85ycVHztYCAADA0TbiHtmfTvKuVe/PrqqPVtXvV9UPLGNnJDm0aptDy9iRdfckyRLHX07y9A2YFwAAADvQrvXsXFW/kOShJL+1DB1OclZ3f6GqLkjy21V1bpK1zrD2kY85xrqj/7wrs3J5cs4666z1TB0AAIChTviMbFVdkeRHk/y95XLhdPdXu/sLy/KHk3w6yXdn5Qzs6suP9yS5d1k+lOTM5TN3JXlqjrqU+Yjuvq6793X3vt27d5/o1AEAABjshEK2qi5J8s+T/Fh3//Gq8d1Vdcqy/J1ZeajTZ7r7cJIHq+qi5f7XFyZ5+7LbLUmuWJafn+S9R8IYAAAAjnbcS4ur6g1Jnp3ktKo6lOQVWXlK8alJ3r08l+n9yxOKfzDJv6yqh5I8nOTF3X3k7OpLsvIE5Cdn5Z7aI/fVXp/kN6vqYFbOxO7fkG8GAADAjnTckO3uy9cYvv4xtn1Lkrc8xroDSc5bY/wrSV5wvHkAAABAsjFPLQYAAIBNI2QBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAo+za6gkAAACcbPZe9Y6tnsJozsgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAoxw3ZKvqhqq6v6ruWDX2bVX17qr61PLzaavWXV1VB6vqrqp6zqrxC6rq9mXda6qqlvFTq+pNy/gHqmrvBn9HAAAAdpDHc0b2xiSXHDV2VZL3dPc5Sd6zvE9VPSvJ/iTnLvu8tqpOWfa5NsmVSc5ZXkc+80VJvtTdz0zy6iSvOtEvAwAAwM533JDt7vcl+eJRw5cmuWlZvinJZavG39jdX+3uzyY5mOTCqjo9yVO6+9bu7iSvP2qfI5/15iQXHzlbCwAAAEc70Xtkn9Hdh5Nk+fnty/gZSe5Ztd2hZeyMZfno8Ufs090PJflykqef4LwAAADY4Tb6YU9rnUntY4wfa59Hf3jVlVV1oKoOPPDAAyc4RQAAACY70ZC9b7lcOMvP+5fxQ0nOXLXdniT3LuN71hh/xD5VtSvJU/PoS5mTJN19XXfv6+59u3fvPsGpAwAAMNmJhuwtSa5Ylq9I8vZV4/uXJxGfnZWHOn1wufz4waq6aLn/9YVH7XPks56f5L3LfbQAAADwKLuOt0FVvSHJs5OcVlWHkrwiySuT3FxVL0ryuSQvSJLuvrOqbk7y8SQPJXlpdz+8fNRLsvIE5CcnedfySpLrk/xmVR3MypnY/RvyzQAAANiRjhuy3X35Y6y6+DG2vybJNWuMH0hy3hrjX8kSwgAAAHA8xw1ZAAAAtpe9V73jmOvvfuXzNmkmW2Ojn1oMAAAATyghCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRTjhkq+p7quq2Va8/qqqXV9UvVtXnV40/d9U+V1fVwaq6q6qes2r8gqq6fVn3mqqq9X4xAAAAdqYTDtnuvqu7z+/u85NckOSPk7xtWf3qI+u6+51JUlXPSrI/yblJLkny2qo6Zdn+2iRXJjlneV1yovMCAABgZ9uoS4svTvLp7v6DY2xzaZI3dvdXu/uzSQ4mubCqTk/ylO6+tbs7yeuTXLZB8wIAAGCH2aiQ3Z/kDavev6yqPlZVN1TV05axM5Lcs2qbQ8vYGcvy0eMAAADwKOsO2ap6UpIfS/Ifl6Frk3xXkvOTHE7yy0c2XWP3Psb4Wn/WlVV1oKoOPPDAA+uZNgAAAENtxBnZH0nyke6+L0m6+77ufri7v5bkN5JcuGx3KMmZq/bbk+TeZXzPGuOP0t3Xdfe+7t63e/fuDZg6AAAA02xEyF6eVZcVL/e8HvHjSe5Ylm9Jsr+qTq2qs7PyUKcPdvfhJA9W1UXL04pfmOTtGzAvAAAAdqBd69m5qr4xyQ8n+ZlVw/+qqs7PyuXBdx9Z1913VtXNST6e5KEkL+3uh5d9XpLkxiRPTvKu5QUAAACPsq6Q7e4/TvL0o8Z+6hjbX5PkmjXGDyQ5bz1zAQAA4OSwUU8tBgAAgE0hZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABglHWFbFXdXVW3V9VtVXVgGfu2qnp3VX1q+fm0VdtfXVUHq+quqnrOqvELls85WFWvqapaz7wAAADYuTbijOzf7O7zu3vf8v6qJO/p7nOSvGd5n6p6VpL9Sc5NckmS11bVKcs+1ya5Msk5y+uSDZgXAAAAO9ATcWnxpUluWpZvSnLZqvE3dvdXu/uzSQ4mubCqTk/ylO6+tbs7yetX7QMAAACPsGud+3eS362qTvJvu/u6JM/o7sNJ0t2Hq+rbl23PSPL+VfseWsb+bFk+ehwAAGCkvVe9Y6unsKOtN2S/v7vvXWL13VX1yWNsu9Z9r32M8Ud/QNWVWbkEOWedddbXO1cAAAB2gHVdWtzd9y4/70/ytiQXJrlvuVw4y8/7l80PJTlz1e57kty7jO9ZY3ytP++67t7X3ft27969nqkDAAAw1AmHbFV9U1V9y5HlJH87yR1JbklyxbLZFUnevizfkmR/VZ1aVWdn5aFOH1wuQ36wqi5anlb8wlX7AAAAwCOs59LiZyR52/KbcnYl+Q/d/TtV9aEkN1fVi5J8LskLkqS776yqm5N8PMlDSV7a3Q8vn/WSJDcmeXKSdy0vAAAAeJQTDtnu/kyS711j/AtJLn6Mfa5Jcs0a4weSnHeicwEAAODk8UT8+h0AAAB4wghZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUXZt9QQAAACm2XvVO7Z6Cic1Z2QBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYJQTDtmqOrOqfq+qPlFVd1bVzy7jv1hVn6+q25bXc1ftc3VVHayqu6rqOavGL6iq25d1r6mqWt/XAgAAYKfatY59H0ryc939kar6liQfrqp3L+te3d2/tHrjqnpWkv1Jzk3yHUn+S1V9d3c/nOTaJFcmeX+Sdya5JMm71jE3AAAAdqgTPiPb3Ye7+yPL8oNJPpHkjGPscmmSN3b3V7v7s0kOJrmwqk5P8pTuvrW7O8nrk1x2ovMCAABgZ9uQe2Sram+S70vygWXoZVX1saq6oaqetoydkeSeVbsdWsbOWJaPHgcAAIBHWXfIVtU3J3lLkpd39x9l5TLh70pyfpLDSX75yKZr7N7HGF/rz7qyqg5U1YEHHnhgvVMHAABgoHWFbFV9Q1Yi9re6+61J0t33dffD3f21JL+R5MJl80NJzly1+54k9y7je9YYf5Tuvq6793X3vt27d69n6gAAAAy1nqcWV5Lrk3yiu39l1fjpqzb78SR3LMu3JNlfVadW1dlJzknywe4+nOTBqrpo+cwXJnn7ic4LAACAnW09Ty3+/iQ/leT2qrptGfv5JJdX1flZuTz47iQ/kyTdfWdV3Zzk41l54vFLlycWJ8lLktyY5MlZeVqxJxYDAACwphMO2e7+b1n7/tZ3HmOfa5Jcs8b4gSTnnehcAAAAOHlsyFOLAQAAYLMIWQAAAEYRsgAAAIwiZAEAABhFyAIAADCKkAUAAGAUIQsAAMAoQhYAAIBRhCwAAACjCFkAAABGEbIAAACMImQBAAAYRcgCAAAwipAFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARhGyAAAAjLJrqycAAACwney96h1bPQWOwxlZAAAARhGyAAAAjCJkAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIwiZAEAABhl11ZPAAAAYDPtveodWz0F1knIAgAAO4pQ3flcWgwAAMAoQhYAAIBRhCwAAACjuEcWAABghznefcJ3v/J5mzSTJ4YzsgAAAIwiZAEAABhFyAIAADCKe2QBAIBR/J5YnJEFAABgFCELAADAKEIWAACAUYQsAAAAowhZAAAARvHUYgAAYFvxVGKOR8gCAACbSqiyXi4tBgAAYBQhCwAAwChCFgAAgFHcIwsAADzC8e5hvfuVz9ukmcDahCwAALChPMyJJ5qQBQCAk4jIZCdwjywAAACjOCMLABvA/WTAZnFGFZyRBQAAYBhnZAFgEzhjCzxeE864TpgjO5szsgAAAIwiZAEAABhl21xaXFWXJPnVJKckeV13v3KLpwQAm8alx7Bz+OcZnnjbImSr6pQkv5bkh5McSvKhqrqluz++tTMDgBXuBwOOWO/fB/4+gfXbFiGb5MIkB7v7M0lSVW9McmkSIQsAsI042whsB9slZM9Ics+q94eS/NUtmgsAwLY04Uzeeud4vBDejJCe8L8znOy2S8jWGmP9qI2qrkxy5fL2f1fVXU/orNbntCR/uNWTgDgW2R4ch+tUr9rqGewYjsVtbr3H+pB/VhyHbLl61Yjj8C881ortErKHkpy56v2eJPcevVF3X5fkus2a1HpU1YHu3rfV8wDHItuB45DtwrHIduA4ZDuYfhxul1+/86Ek51TV2VX1pCT7k9yyxXMCAABgG9oWZ2S7+6GqelmS/5yVX79zQ3ffucXTAgAAYBvaFiGbJN39ziTv3Op5bKARl0BzUnAssh04DtkuHItsB45DtoPRx2F1P+qZSgAAALBtbZd7ZAEAAOBxEbJPgKq6pKruqqqDVXXVVs+Hk0NVnVlVv1dVn6iqO6vqZ5fxb6uqd1fVp5afT9vqubLzVdUpVfXRqvpPy3vHIZuuqr61qt5cVZ9c/m78a45FNltV/ePl38t3VNUbqurPOw7ZDFV1Q1XdX1V3rBp7zGOvqq5e+uWuqnrO1sz68ROyG6yqTknya0l+JMmzklxeVc/a2llxkngoyc91919KclGSly7H3lVJ3tPd5yR5z/Ienmg/m+QTq947DtkKv5rkd7r7Lyb53qwck45FNk1VnZHkHyXZ193nZeWhpvvjOGRz3JjkkqPG1jz2lv9m3J/k3GWf1y5ds20J2Y13YZKD3f2Z7v7TJG9McukWz4mTQHcf7u6PLMsPZuU/2M7IyvF307LZTUku25IJctKoqj1JnpfkdauGHYdsqqp6SpIfTHJ9knT3n3b3/4pjkc23K8mTq2pXkm9Mcm8ch2yC7n5fki8eNfxYx96lSd7Y3V/t7s8mOZiVrtm2hOzGOyPJPaveH1rGYNNU1d4k35fkA0me0d2Hk5XYTfLtWzg1Tg7/Jsk/S/K1VWOOQzbbdyZ5IMm/Wy5zf11VfVMci2yi7v58kl9K8rkkh5N8ubt/N45Dts5jHXvjGkbIbrxaY8yjodk0VfXNSd6S5OXd/UdbPR9OLlX1o0nu7+4Pb/VcOOntSvJXklzb3d+X5P/E5ZtssuX+w0uTnJ3kO5J8U1X95NbOCtY0rmGE7MY7lOTMVe/3ZOUSEnjCVdU3ZCVif6u737oM31dVpy/rT09y/1bNj5PC9yf5saq6Oyu3Vvytqvr3cRyy+Q4lOdTdH1jevzkrYetYZDP9UJLPdvcD3f1nSd6a5K/HccjWeaxjb1zDCNmN96Ek51TV2VX1pKzcNH3LFs+Jk0BVVVbuBftEd//KqlW3JLliWb4iyds3e26cPLr76u7e0917s/L333u7+yfjOGSTdff/THJPVX3PMnRxko/Hscjm+lySi6rqG5d/T1+clWdYOA7ZKo917N2SZH9VnVpVZyc5J8kHt2B+j1t1b+szxiNV1XOzco/YKUlu6O5rtnZGnAyq6m8k+a9Jbs//vzfx57Nyn+zNSc7Kyr9QX9DdR9/4Dxuuqp6d5J92949W1dPjOGSTVdX5WXno2JOSfCbJP8jK/4nvWGTTVNW/SPITWfntAh9N8g+TfHMchzzBquoNSZ6d5LQk9yV5RZLfzmMce1X1C0l+OivH6su7+12bP+vHT8gCAAAwikuLAQAAGEXIAgAAMIqQBQAAYBQhCwAAwChCFgAAgFGELAAAAKMIWQAAAEYRsgAAAIzyfwFCN2wiHU45nQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df_in_list = []\n",
    "df_in_list.append(pd.read_csv('Collisions/'+\"324209\"+'/'+\"324209\"+'_final2.csv'))\n",
    "    \n",
    "run324209 = pd.concat(list_of_df)\n",
    "run324209 = run324209.reset_index(drop=True)\n",
    "run324209 = run324209.loc[run324209['fid_eff_ch_level'] > 0]\n",
    "print(run324209.shape)\n",
    "print(run324209.head(5))\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.hist(run324209['fid_eff_ch_level'], bins=100)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# preparing dataset for testing predictions.\n",
    "run324209['occupancy_per_LS'] = run324209['occupancy'] / run324209['lumisections']\n",
    "run324209.drop(['run', 'chamber', 'type', 'contains_zero_roll', 'rolls_count', 'avg_efficiency', 'occupancy', 'lumisections', 'fid_eff_ch_level'], axis=1, inplace=True)\n",
    "run324209=scaler.transform(run324209)\n",
    "fid_eff_prediction = model.predict(run324209)\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.hist(fid_eff_prediction, bins=100, range=[0, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc99ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
